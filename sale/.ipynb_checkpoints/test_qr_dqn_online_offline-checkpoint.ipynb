{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from utils.epsilon_decay import linearly_decaying_epsilon\n",
    "from models.box2d_models import DQNNetwork, QuantileNetwork\n",
    "from replay_buffers.replay_buffer import ReplayBuffer, PrioritizedReplayBuffer\n",
    "\n",
    "from default_config import DEFAULT_CONFIG as config\n",
    "from dqn import DQNAgent\n",
    "from qr_dqn import QuantileAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online QR-DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/Prophet/sluo/software/anaconda3/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save buffer every 100 episodes!\n",
      "------------------------------------------------\n",
      "episodes 9\n",
      "timestep 1000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000500\n",
      "mean reward (100 episodes) -833.750613\n",
      "max reward (100 episodes) -376.758147\n",
      "mean step (100 episodes) 125.600000\n",
      "max step (100 episodes) 272.000000\n",
      "------------------------------------------------\n",
      "episodes 19\n",
      "timestep 2000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000499\n",
      "mean reward (100 episodes) -470.059864\n",
      "max reward (100 episodes) -6.214003\n",
      "mean step (100 episodes) 198.600000\n",
      "max step (100 episodes) 345.000000\n",
      "------------------------------------------------\n",
      "episodes 23\n",
      "timestep 3000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000499\n",
      "mean reward (100 episodes) -391.988927\n",
      "max reward (100 episodes) -6.214003\n",
      "mean step (100 episodes) 234.400000\n",
      "max step (100 episodes) 412.000000\n",
      "------------------------------------------------\n",
      "episodes 28\n",
      "timestep 4000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000498\n",
      "mean reward (100 episodes) -354.519453\n",
      "max reward (100 episodes) -6.214003\n",
      "mean step (100 episodes) 259.650000\n",
      "max step (100 episodes) 412.000000\n",
      "------------------------------------------------\n",
      "episodes 30\n",
      "timestep 5000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000498\n",
      "mean reward (100 episodes) -320.558223\n",
      "max reward (100 episodes) -6.214003\n",
      "mean step (100 episodes) 407.720000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 33\n",
      "timestep 6000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000497\n",
      "mean reward (100 episodes) -285.427151\n",
      "max reward (100 episodes) -6.214003\n",
      "mean step (100 episodes) 495.166667\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 35\n",
      "timestep 7000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000497\n",
      "mean reward (100 episodes) -259.783492\n",
      "max reward (100 episodes) 46.591426\n",
      "mean step (100 episodes) 509.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 37\n",
      "timestep 8000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000496\n",
      "mean reward (100 episodes) -226.696620\n",
      "max reward (100 episodes) 104.768758\n",
      "mean step (100 episodes) 552.425000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 39\n",
      "timestep 9000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000496\n",
      "mean reward (100 episodes) -219.207773\n",
      "max reward (100 episodes) 104.768758\n",
      "mean step (100 episodes) 562.800000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_10000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 41\n",
      "timestep 10000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000495\n",
      "mean reward (100 episodes) -215.700007\n",
      "max reward (100 episodes) 104.768758\n",
      "mean step (100 episodes) 584.560000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 43\n",
      "timestep 11000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000495\n",
      "mean reward (100 episodes) -208.053400\n",
      "max reward (100 episodes) 104.768758\n",
      "mean step (100 episodes) 622.327273\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 45\n",
      "timestep 12000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000494\n",
      "mean reward (100 episodes) -207.362515\n",
      "max reward (100 episodes) 104.768758\n",
      "mean step (100 episodes) 649.050000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 47\n",
      "timestep 13000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000494\n",
      "mean reward (100 episodes) -202.260738\n",
      "max reward (100 episodes) 104.768758\n",
      "mean step (100 episodes) 673.446154\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 49\n",
      "timestep 14000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000493\n",
      "mean reward (100 episodes) -200.007363\n",
      "max reward (100 episodes) 104.768758\n",
      "mean step (100 episodes) 695.542857\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 51\n",
      "timestep 15000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000493\n",
      "mean reward (100 episodes) -196.471074\n",
      "max reward (100 episodes) 104.768758\n",
      "mean step (100 episodes) 715.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 53\n",
      "timestep 16000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000492\n",
      "mean reward (100 episodes) -193.638331\n",
      "max reward (100 episodes) 104.768758\n",
      "mean step (100 episodes) 733.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 55\n",
      "timestep 17000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000492\n",
      "mean reward (100 episodes) -190.519516\n",
      "max reward (100 episodes) 104.768758\n",
      "mean step (100 episodes) 738.882353\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 57\n",
      "timestep 18000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000491\n",
      "mean reward (100 episodes) -184.899612\n",
      "max reward (100 episodes) 104.768758\n",
      "mean step (100 episodes) 742.900000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 59\n",
      "timestep 19000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000491\n",
      "mean reward (100 episodes) -182.565323\n",
      "max reward (100 episodes) 104.768758\n",
      "mean step (100 episodes) 745.221053\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_20000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 61\n",
      "timestep 20000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000490\n",
      "mean reward (100 episodes) -180.741090\n",
      "max reward (100 episodes) 104.768758\n",
      "mean step (100 episodes) 755.530000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 63\n",
      "timestep 21000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000490\n",
      "mean reward (100 episodes) -146.227220\n",
      "max reward (100 episodes) 104.768758\n",
      "mean step (100 episodes) 780.060000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 65\n",
      "timestep 22000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000489\n",
      "mean reward (100 episodes) -147.828072\n",
      "max reward (100 episodes) 104.768758\n",
      "mean step (100 episodes) 796.610000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 68\n",
      "timestep 23000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000489\n",
      "mean reward (100 episodes) -146.619987\n",
      "max reward (100 episodes) 104.768758\n",
      "mean step (100 episodes) 816.910000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 70\n",
      "timestep 24000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000488\n",
      "mean reward (100 episodes) -140.484326\n",
      "max reward (100 episodes) 104.768758\n",
      "mean step (100 episodes) 833.720000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 73\n",
      "timestep 25000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000488\n",
      "mean reward (100 episodes) -137.870293\n",
      "max reward (100 episodes) 104.768758\n",
      "mean step (100 episodes) 819.190000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 75\n",
      "timestep 26000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000487\n",
      "mean reward (100 episodes) -141.756604\n",
      "max reward (100 episodes) 104.768758\n",
      "mean step (100 episodes) 812.370000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 77\n",
      "timestep 27000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000487\n",
      "mean reward (100 episodes) -143.730067\n",
      "max reward (100 episodes) 104.768758\n",
      "mean step (100 episodes) 822.070000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 81\n",
      "timestep 28000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000486\n",
      "mean reward (100 episodes) -151.721812\n",
      "max reward (100 episodes) 20.854501\n",
      "mean step (100 episodes) 817.680000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 83\n",
      "timestep 29000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000486\n",
      "mean reward (100 episodes) -152.241281\n",
      "max reward (100 episodes) 20.854501\n",
      "mean step (100 episodes) 821.560000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_30000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 87\n",
      "timestep 30000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000485\n",
      "mean reward (100 episodes) -153.279439\n",
      "max reward (100 episodes) -32.559864\n",
      "mean step (100 episodes) 807.620000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 89\n",
      "timestep 31000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000485\n",
      "mean reward (100 episodes) -154.511353\n",
      "max reward (100 episodes) -32.559864\n",
      "mean step (100 episodes) 783.460000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 91\n",
      "timestep 32000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000484\n",
      "mean reward (100 episodes) -152.012251\n",
      "max reward (100 episodes) -32.559864\n",
      "mean step (100 episodes) 771.690000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 94\n",
      "timestep 33000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000484\n",
      "mean reward (100 episodes) -151.809906\n",
      "max reward (100 episodes) -32.559864\n",
      "mean step (100 episodes) 757.440000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 96\n",
      "timestep 34000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000484\n",
      "mean reward (100 episodes) -156.412637\n",
      "max reward (100 episodes) -32.559864\n",
      "mean step (100 episodes) 728.210000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 98\n",
      "timestep 35000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000483\n",
      "mean reward (100 episodes) -154.445142\n",
      "max reward (100 episodes) -32.559864\n",
      "mean step (100 episodes) 728.210000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 101\n",
      "timestep 36000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000483\n",
      "mean reward (100 episodes) -156.667041\n",
      "max reward (100 episodes) -32.559864\n",
      "mean step (100 episodes) 719.900000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 103\n",
      "timestep 37000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000482\n",
      "mean reward (100 episodes) -160.983485\n",
      "max reward (100 episodes) -32.559864\n",
      "mean step (100 episodes) 701.500000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 105\n",
      "timestep 38000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000482\n",
      "mean reward (100 episodes) -165.834858\n",
      "max reward (100 episodes) -32.559864\n",
      "mean step (100 episodes) 684.240000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 110\n",
      "timestep 39000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000481\n",
      "mean reward (100 episodes) -167.449359\n",
      "max reward (100 episodes) -32.559864\n",
      "mean step (100 episodes) 683.780000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_40000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 112\n",
      "timestep 40000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000481\n",
      "mean reward (100 episodes) -170.503471\n",
      "max reward (100 episodes) -32.559864\n",
      "mean step (100 episodes) 682.060000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 115\n",
      "timestep 41000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000480\n",
      "mean reward (100 episodes) -172.480509\n",
      "max reward (100 episodes) -53.571492\n",
      "mean step (100 episodes) 685.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 117\n",
      "timestep 42000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000480\n",
      "mean reward (100 episodes) -171.191590\n",
      "max reward (100 episodes) -53.571492\n",
      "mean step (100 episodes) 689.380000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 119\n",
      "timestep 43000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000479\n",
      "mean reward (100 episodes) -165.656017\n",
      "max reward (100 episodes) -53.571492\n",
      "mean step (100 episodes) 703.780000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 121\n",
      "timestep 44000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000479\n",
      "mean reward (100 episodes) -168.665625\n",
      "max reward (100 episodes) -53.571492\n",
      "mean step (100 episodes) 700.440000\n",
      "max step (100 episodes) 1000.000000\n",
      "Saved trajectories to save path: /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/trajs_0.pkl!\n",
      "------------------------------------------------\n",
      "episodes 123\n",
      "timestep 45000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000478\n",
      "mean reward (100 episodes) -166.014425\n",
      "max reward (100 episodes) -53.571492\n",
      "mean step (100 episodes) 714.970000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 125\n",
      "timestep 46000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000478\n",
      "mean reward (100 episodes) -161.131754\n",
      "max reward (100 episodes) -38.006563\n",
      "mean step (100 episodes) 700.150000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 446\n",
      "timestep 191000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000420\n",
      "mean reward (100 episodes) 150.813343\n",
      "max reward (100 episodes) 301.312265\n",
      "mean step (100 episodes) 669.470000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 449\n",
      "timestep 192000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000419\n",
      "mean reward (100 episodes) 150.119548\n",
      "max reward (100 episodes) 301.312265\n",
      "mean step (100 episodes) 665.090000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 451\n",
      "timestep 193000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000419\n",
      "mean reward (100 episodes) 152.846820\n",
      "max reward (100 episodes) 272.194906\n",
      "mean step (100 episodes) 669.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 453\n",
      "timestep 194000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000419\n",
      "mean reward (100 episodes) 152.939794\n",
      "max reward (100 episodes) 272.194906\n",
      "mean step (100 episodes) 693.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 455\n",
      "timestep 195000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000418\n",
      "mean reward (100 episodes) 150.405516\n",
      "max reward (100 episodes) 272.194906\n",
      "mean step (100 episodes) 703.460000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 458\n",
      "timestep 196000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000418\n",
      "mean reward (100 episodes) 149.712505\n",
      "max reward (100 episodes) 272.194906\n",
      "mean step (100 episodes) 685.740000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 461\n",
      "timestep 197000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000418\n",
      "mean reward (100 episodes) 151.730942\n",
      "max reward (100 episodes) 272.194906\n",
      "mean step (100 episodes) 680.130000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 463\n",
      "timestep 198000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000417\n",
      "mean reward (100 episodes) 150.414842\n",
      "max reward (100 episodes) 280.859848\n",
      "mean step (100 episodes) 691.590000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 466\n",
      "timestep 199000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000417\n",
      "mean reward (100 episodes) 146.367226\n",
      "max reward (100 episodes) 280.859848\n",
      "mean step (100 episodes) 682.550000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_200000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 468\n",
      "timestep 200000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000417\n",
      "mean reward (100 episodes) 148.519942\n",
      "max reward (100 episodes) 280.859848\n",
      "mean step (100 episodes) 674.880000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 470\n",
      "timestep 201000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000416\n",
      "mean reward (100 episodes) 151.362893\n",
      "max reward (100 episodes) 280.859848\n",
      "mean step (100 episodes) 666.750000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 472\n",
      "timestep 202000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000416\n",
      "mean reward (100 episodes) 149.728476\n",
      "max reward (100 episodes) 280.859848\n",
      "mean step (100 episodes) 667.050000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 474\n",
      "timestep 203000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000416\n",
      "mean reward (100 episodes) 147.220293\n",
      "max reward (100 episodes) 280.859848\n",
      "mean step (100 episodes) 648.710000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 478\n",
      "timestep 204000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000415\n",
      "mean reward (100 episodes) 151.697087\n",
      "max reward (100 episodes) 280.859848\n",
      "mean step (100 episodes) 642.650000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 480\n",
      "timestep 205000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000415\n",
      "mean reward (100 episodes) 153.708892\n",
      "max reward (100 episodes) 280.859848\n",
      "mean step (100 episodes) 635.210000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 482\n",
      "timestep 206000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000415\n",
      "mean reward (100 episodes) 155.844374\n",
      "max reward (100 episodes) 280.859848\n",
      "mean step (100 episodes) 611.890000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 485\n",
      "timestep 207000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000414\n",
      "mean reward (100 episodes) 155.373516\n",
      "max reward (100 episodes) 280.859848\n",
      "mean step (100 episodes) 613.200000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 487\n",
      "timestep 208000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000414\n",
      "mean reward (100 episodes) 157.369670\n",
      "max reward (100 episodes) 280.859848\n",
      "mean step (100 episodes) 606.310000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 489\n",
      "timestep 209000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000414\n",
      "mean reward (100 episodes) 161.618696\n",
      "max reward (100 episodes) 280.859848\n",
      "mean step (100 episodes) 618.240000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_210000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 491\n",
      "timestep 210000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000413\n",
      "mean reward (100 episodes) 166.116103\n",
      "max reward (100 episodes) 280.859848\n",
      "mean step (100 episodes) 594.340000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 493\n",
      "timestep 211000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000413\n",
      "mean reward (100 episodes) 169.676674\n",
      "max reward (100 episodes) 280.859848\n",
      "mean step (100 episodes) 566.500000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 495\n",
      "timestep 212000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000413\n",
      "mean reward (100 episodes) 166.779724\n",
      "max reward (100 episodes) 280.859848\n",
      "mean step (100 episodes) 583.800000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 497\n",
      "timestep 213000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000412\n",
      "mean reward (100 episodes) 164.663811\n",
      "max reward (100 episodes) 280.859848\n",
      "mean step (100 episodes) 577.480000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 500\n",
      "timestep 214000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000412\n",
      "mean reward (100 episodes) 165.385438\n",
      "max reward (100 episodes) 280.859848\n",
      "mean step (100 episodes) 558.830000\n",
      "max step (100 episodes) 1000.000000\n",
      "Saved trajectories to save path: /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/trajs_3.pkl!\n",
      "------------------------------------------------\n",
      "episodes 502\n",
      "timestep 215000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000412\n",
      "mean reward (100 episodes) 167.465949\n",
      "max reward (100 episodes) 280.859848\n",
      "mean step (100 episodes) 535.070000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 504\n",
      "timestep 216000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000411\n",
      "mean reward (100 episodes) 168.974044\n",
      "max reward (100 episodes) 280.859848\n",
      "mean step (100 episodes) 552.730000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 506\n",
      "timestep 217000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000411\n",
      "mean reward (100 episodes) 164.792840\n",
      "max reward (100 episodes) 280.859848\n",
      "mean step (100 episodes) 568.900000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 509\n",
      "timestep 218000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000411\n",
      "mean reward (100 episodes) 165.338996\n",
      "max reward (100 episodes) 279.950915\n",
      "mean step (100 episodes) 551.930000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 511\n",
      "timestep 219000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000410\n",
      "mean reward (100 episodes) 169.854054\n",
      "max reward (100 episodes) 279.950915\n",
      "mean step (100 episodes) 551.830000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_220000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 513\n",
      "timestep 220000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000410\n",
      "mean reward (100 episodes) 165.111588\n",
      "max reward (100 episodes) 279.950915\n",
      "mean step (100 episodes) 572.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 515\n",
      "timestep 221000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000410\n",
      "mean reward (100 episodes) 166.577724\n",
      "max reward (100 episodes) 279.950915\n",
      "mean step (100 episodes) 551.710000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 517\n",
      "timestep 222000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000409\n",
      "mean reward (100 episodes) 167.348867\n",
      "max reward (100 episodes) 279.950915\n",
      "mean step (100 episodes) 554.290000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 519\n",
      "timestep 223000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000409\n",
      "mean reward (100 episodes) 168.233751\n",
      "max reward (100 episodes) 279.950915\n",
      "mean step (100 episodes) 552.080000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 521\n",
      "timestep 224000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000408\n",
      "mean reward (100 episodes) 167.868944\n",
      "max reward (100 episodes) 279.950915\n",
      "mean step (100 episodes) 555.850000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 524\n",
      "timestep 225000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000408\n",
      "mean reward (100 episodes) 165.894805\n",
      "max reward (100 episodes) 279.950915\n",
      "mean step (100 episodes) 543.620000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 526\n",
      "timestep 226000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000408\n",
      "mean reward (100 episodes) 165.799831\n",
      "max reward (100 episodes) 279.950915\n",
      "mean step (100 episodes) 531.320000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 528\n",
      "timestep 227000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000407\n",
      "mean reward (100 episodes) 167.489510\n",
      "max reward (100 episodes) 279.950915\n",
      "mean step (100 episodes) 515.280000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 531\n",
      "timestep 228000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000407\n",
      "mean reward (100 episodes) 163.163517\n",
      "max reward (100 episodes) 278.911131\n",
      "mean step (100 episodes) 533.240000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 533\n",
      "timestep 229000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000407\n",
      "mean reward (100 episodes) 167.173065\n",
      "max reward (100 episodes) 278.911131\n",
      "mean step (100 episodes) 510.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_230000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 536\n",
      "timestep 230000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000407\n",
      "mean reward (100 episodes) 162.148790\n",
      "max reward (100 episodes) 278.911131\n",
      "mean step (100 episodes) 506.400000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 539\n",
      "timestep 231000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000406\n",
      "mean reward (100 episodes) 163.737219\n",
      "max reward (100 episodes) 278.911131\n",
      "mean step (100 episodes) 514.430000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 542\n",
      "timestep 232000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000406\n",
      "mean reward (100 episodes) 167.991474\n",
      "max reward (100 episodes) 278.911131\n",
      "mean step (100 episodes) 480.110000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 544\n",
      "timestep 233000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000406\n",
      "mean reward (100 episodes) 164.568689\n",
      "max reward (100 episodes) 278.911131\n",
      "mean step (100 episodes) 504.620000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 546\n",
      "timestep 234000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000405\n",
      "mean reward (100 episodes) 168.199061\n",
      "max reward (100 episodes) 278.911131\n",
      "mean step (100 episodes) 501.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 548\n",
      "timestep 235000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000405\n",
      "mean reward (100 episodes) 168.141797\n",
      "max reward (100 episodes) 278.911131\n",
      "mean step (100 episodes) 505.620000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 550\n",
      "timestep 236000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000405\n",
      "mean reward (100 episodes) 170.212930\n",
      "max reward (100 episodes) 278.911131\n",
      "mean step (100 episodes) 515.590000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 552\n",
      "timestep 237000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000404\n",
      "mean reward (100 episodes) 177.217181\n",
      "max reward (100 episodes) 278.911131\n",
      "mean step (100 episodes) 491.140000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 555\n",
      "timestep 238000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000404\n",
      "mean reward (100 episodes) 175.039173\n",
      "max reward (100 episodes) 278.911131\n",
      "mean step (100 episodes) 514.020000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 557\n",
      "timestep 239000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000404\n",
      "mean reward (100 episodes) 175.652888\n",
      "max reward (100 episodes) 278.911131\n",
      "mean step (100 episodes) 518.660000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_240000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 560\n",
      "timestep 240000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000403\n",
      "mean reward (100 episodes) 179.659106\n",
      "max reward (100 episodes) 278.911131\n",
      "mean step (100 episodes) 502.160000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 562\n",
      "timestep 241000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000403\n",
      "mean reward (100 episodes) 182.640875\n",
      "max reward (100 episodes) 306.072503\n",
      "mean step (100 episodes) 503.640000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 564\n",
      "timestep 242000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000403\n",
      "mean reward (100 episodes) 185.741025\n",
      "max reward (100 episodes) 306.072503\n",
      "mean step (100 episodes) 502.030000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 566\n",
      "timestep 243000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000402\n",
      "mean reward (100 episodes) 190.089015\n",
      "max reward (100 episodes) 306.072503\n",
      "mean step (100 episodes) 507.830000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 568\n",
      "timestep 244000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000402\n",
      "mean reward (100 episodes) 189.515416\n",
      "max reward (100 episodes) 306.072503\n",
      "mean step (100 episodes) 517.960000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 571\n",
      "timestep 245000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000402\n",
      "mean reward (100 episodes) 190.212639\n",
      "max reward (100 episodes) 306.072503\n",
      "mean step (100 episodes) 549.080000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 573\n",
      "timestep 246000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000401\n",
      "mean reward (100 episodes) 191.388134\n",
      "max reward (100 episodes) 306.072503\n",
      "mean step (100 episodes) 573.010000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 575\n",
      "timestep 247000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000401\n",
      "mean reward (100 episodes) 195.885005\n",
      "max reward (100 episodes) 306.072503\n",
      "mean step (100 episodes) 579.500000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 578\n",
      "timestep 248000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000401\n",
      "mean reward (100 episodes) 199.370392\n",
      "max reward (100 episodes) 306.072503\n",
      "mean step (100 episodes) 562.460000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 581\n",
      "timestep 249000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000400\n",
      "mean reward (100 episodes) 196.833697\n",
      "max reward (100 episodes) 306.072503\n",
      "mean step (100 episodes) 578.550000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_250000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 583\n",
      "timestep 250000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000400\n",
      "mean reward (100 episodes) 197.902115\n",
      "max reward (100 episodes) 306.072503\n",
      "mean step (100 episodes) 602.120000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 585\n",
      "timestep 251000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000400\n",
      "mean reward (100 episodes) 197.301100\n",
      "max reward (100 episodes) 306.072503\n",
      "mean step (100 episodes) 603.150000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 587\n",
      "timestep 252000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000399\n",
      "mean reward (100 episodes) 199.027302\n",
      "max reward (100 episodes) 306.072503\n",
      "mean step (100 episodes) 611.430000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 589\n",
      "timestep 253000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000399\n",
      "mean reward (100 episodes) 203.868554\n",
      "max reward (100 episodes) 306.072503\n",
      "mean step (100 episodes) 599.170000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 591\n",
      "timestep 254000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000399\n",
      "mean reward (100 episodes) 202.464405\n",
      "max reward (100 episodes) 306.072503\n",
      "mean step (100 episodes) 604.050000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 594\n",
      "timestep 255000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000398\n",
      "mean reward (100 episodes) 205.285286\n",
      "max reward (100 episodes) 306.072503\n",
      "mean step (100 episodes) 601.760000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 596\n",
      "timestep 256000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000398\n",
      "mean reward (100 episodes) 208.016875\n",
      "max reward (100 episodes) 306.072503\n",
      "mean step (100 episodes) 581.040000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 598\n",
      "timestep 257000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000398\n",
      "mean reward (100 episodes) 204.407002\n",
      "max reward (100 episodes) 306.072503\n",
      "mean step (100 episodes) 599.460000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 600\n",
      "timestep 258000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000397\n",
      "mean reward (100 episodes) 208.239784\n",
      "max reward (100 episodes) 306.072503\n",
      "mean step (100 episodes) 582.540000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 602\n",
      "timestep 259000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000397\n",
      "mean reward (100 episodes) 208.911599\n",
      "max reward (100 episodes) 306.072503\n",
      "mean step (100 episodes) 581.910000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_260000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 604\n",
      "timestep 260000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000397\n",
      "mean reward (100 episodes) 209.404877\n",
      "max reward (100 episodes) 306.072503\n",
      "mean step (100 episodes) 576.940000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 606\n",
      "timestep 261000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000397\n",
      "mean reward (100 episodes) 206.878266\n",
      "max reward (100 episodes) 276.738350\n",
      "mean step (100 episodes) 583.130000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 608\n",
      "timestep 262000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000396\n",
      "mean reward (100 episodes) 203.665052\n",
      "max reward (100 episodes) 276.738350\n",
      "mean step (100 episodes) 598.560000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 610\n",
      "timestep 263000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000396\n",
      "mean reward (100 episodes) 199.406892\n",
      "max reward (100 episodes) 276.738350\n",
      "mean step (100 episodes) 616.820000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trajectories to save path: /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/trajs_4.pkl!\n",
      "------------------------------------------------\n",
      "episodes 612\n",
      "timestep 264000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000396\n",
      "mean reward (100 episodes) 200.150440\n",
      "max reward (100 episodes) 276.738350\n",
      "mean step (100 episodes) 602.210000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 615\n",
      "timestep 265000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000395\n",
      "mean reward (100 episodes) 202.799665\n",
      "max reward (100 episodes) 276.738350\n",
      "mean step (100 episodes) 580.990000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 617\n",
      "timestep 266000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000395\n",
      "mean reward (100 episodes) 203.966237\n",
      "max reward (100 episodes) 276.738350\n",
      "mean step (100 episodes) 559.830000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 619\n",
      "timestep 267000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000395\n",
      "mean reward (100 episodes) 204.176576\n",
      "max reward (100 episodes) 276.738350\n",
      "mean step (100 episodes) 556.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 622\n",
      "timestep 268000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000394\n",
      "mean reward (100 episodes) 202.629506\n",
      "max reward (100 episodes) 276.738350\n",
      "mean step (100 episodes) 566.720000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 625\n",
      "timestep 269000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000394\n",
      "mean reward (100 episodes) 203.690851\n",
      "max reward (100 episodes) 276.738350\n",
      "mean step (100 episodes) 567.540000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_270000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 627\n",
      "timestep 270000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000394\n",
      "mean reward (100 episodes) 209.499552\n",
      "max reward (100 episodes) 276.738350\n",
      "mean step (100 episodes) 545.030000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 630\n",
      "timestep 271000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000393\n",
      "mean reward (100 episodes) 208.818698\n",
      "max reward (100 episodes) 276.738350\n",
      "mean step (100 episodes) 556.350000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 633\n",
      "timestep 272000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000393\n",
      "mean reward (100 episodes) 206.990082\n",
      "max reward (100 episodes) 276.738350\n",
      "mean step (100 episodes) 562.910000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 635\n",
      "timestep 273000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000393\n",
      "mean reward (100 episodes) 205.401734\n",
      "max reward (100 episodes) 276.738350\n",
      "mean step (100 episodes) 572.160000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 637\n",
      "timestep 274000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000392\n",
      "mean reward (100 episodes) 207.225089\n",
      "max reward (100 episodes) 276.738350\n",
      "mean step (100 episodes) 564.850000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 640\n",
      "timestep 275000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000392\n",
      "mean reward (100 episodes) 203.918551\n",
      "max reward (100 episodes) 275.353553\n",
      "mean step (100 episodes) 591.350000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 643\n",
      "timestep 276000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000392\n",
      "mean reward (100 episodes) 203.453506\n",
      "max reward (100 episodes) 275.353553\n",
      "mean step (100 episodes) 593.750000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 645\n",
      "timestep 277000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000392\n",
      "mean reward (100 episodes) 201.083964\n",
      "max reward (100 episodes) 275.353553\n",
      "mean step (100 episodes) 606.030000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 647\n",
      "timestep 278000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000391\n",
      "mean reward (100 episodes) 200.957504\n",
      "max reward (100 episodes) 275.353553\n",
      "mean step (100 episodes) 609.410000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 650\n",
      "timestep 279000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000391\n",
      "mean reward (100 episodes) 199.961510\n",
      "max reward (100 episodes) 283.562796\n",
      "mean step (100 episodes) 615.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_280000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 653\n",
      "timestep 280000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000391\n",
      "mean reward (100 episodes) 202.832971\n",
      "max reward (100 episodes) 284.732725\n",
      "mean step (100 episodes) 608.090000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 655\n",
      "timestep 281000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000390\n",
      "mean reward (100 episodes) 204.273367\n",
      "max reward (100 episodes) 284.732725\n",
      "mean step (100 episodes) 599.340000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 657\n",
      "timestep 282000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000390\n",
      "mean reward (100 episodes) 202.929331\n",
      "max reward (100 episodes) 284.732725\n",
      "mean step (100 episodes) 585.130000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 660\n",
      "timestep 283000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000390\n",
      "mean reward (100 episodes) 203.084774\n",
      "max reward (100 episodes) 284.732725\n",
      "mean step (100 episodes) 570.890000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 662\n",
      "timestep 284000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000389\n",
      "mean reward (100 episodes) 203.661042\n",
      "max reward (100 episodes) 284.732725\n",
      "mean step (100 episodes) 571.700000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 664\n",
      "timestep 285000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000389\n",
      "mean reward (100 episodes) 204.560269\n",
      "max reward (100 episodes) 292.197415\n",
      "mean step (100 episodes) 564.470000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 666\n",
      "timestep 286000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000389\n",
      "mean reward (100 episodes) 206.747677\n",
      "max reward (100 episodes) 292.197415\n",
      "mean step (100 episodes) 563.550000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 668\n",
      "timestep 287000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000389\n",
      "mean reward (100 episodes) 205.098805\n",
      "max reward (100 episodes) 292.197415\n",
      "mean step (100 episodes) 561.730000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 670\n",
      "timestep 288000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000388\n",
      "mean reward (100 episodes) 205.733881\n",
      "max reward (100 episodes) 292.197415\n",
      "mean step (100 episodes) 549.920000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 672\n",
      "timestep 289000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000388\n",
      "mean reward (100 episodes) 206.795863\n",
      "max reward (100 episodes) 292.197415\n",
      "mean step (100 episodes) 532.210000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_290000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 675\n",
      "timestep 290000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000388\n",
      "mean reward (100 episodes) 205.566120\n",
      "max reward (100 episodes) 292.197415\n",
      "mean step (100 episodes) 530.810000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 677\n",
      "timestep 291000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000387\n",
      "mean reward (100 episodes) 207.248012\n",
      "max reward (100 episodes) 292.197415\n",
      "mean step (100 episodes) 513.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 680\n",
      "timestep 292000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000387\n",
      "mean reward (100 episodes) 207.894264\n",
      "max reward (100 episodes) 292.197415\n",
      "mean step (100 episodes) 513.370000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 683\n",
      "timestep 293000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000387\n",
      "mean reward (100 episodes) 208.253038\n",
      "max reward (100 episodes) 292.197415\n",
      "mean step (100 episodes) 500.300000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 685\n",
      "timestep 294000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000386\n",
      "mean reward (100 episodes) 208.549505\n",
      "max reward (100 episodes) 292.197415\n",
      "mean step (100 episodes) 496.650000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 687\n",
      "timestep 295000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000386\n",
      "mean reward (100 episodes) 206.556701\n",
      "max reward (100 episodes) 292.197415\n",
      "mean step (100 episodes) 474.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 689\n",
      "timestep 296000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000386\n",
      "mean reward (100 episodes) 208.603158\n",
      "max reward (100 episodes) 292.197415\n",
      "mean step (100 episodes) 466.900000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 692\n",
      "timestep 297000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000386\n",
      "mean reward (100 episodes) 214.425102\n",
      "max reward (100 episodes) 292.197415\n",
      "mean step (100 episodes) 437.880000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 694\n",
      "timestep 298000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000385\n",
      "mean reward (100 episodes) 215.607070\n",
      "max reward (100 episodes) 292.197415\n",
      "mean step (100 episodes) 429.230000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 696\n",
      "timestep 299000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000385\n",
      "mean reward (100 episodes) 214.316923\n",
      "max reward (100 episodes) 292.197415\n",
      "mean step (100 episodes) 423.920000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_300000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 699\n",
      "timestep 300000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000385\n",
      "mean reward (100 episodes) 204.915211\n",
      "max reward (100 episodes) 292.197415\n",
      "mean step (100 episodes) 452.250000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 701\n",
      "timestep 301000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000384\n",
      "mean reward (100 episodes) 201.712116\n",
      "max reward (100 episodes) 292.197415\n",
      "mean step (100 episodes) 469.090000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 703\n",
      "timestep 302000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000384\n",
      "mean reward (100 episodes) 205.077959\n",
      "max reward (100 episodes) 292.197415\n",
      "mean step (100 episodes) 465.250000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 705\n",
      "timestep 303000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000384\n",
      "mean reward (100 episodes) 206.070305\n",
      "max reward (100 episodes) 292.197415\n",
      "mean step (100 episodes) 483.530000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 707\n",
      "timestep 304000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000383\n",
      "mean reward (100 episodes) 203.043999\n",
      "max reward (100 episodes) 292.197415\n",
      "mean step (100 episodes) 499.670000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 709\n",
      "timestep 305000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000383\n",
      "mean reward (100 episodes) 200.775537\n",
      "max reward (100 episodes) 290.898509\n",
      "mean step (100 episodes) 518.080000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 712\n",
      "timestep 306000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000383\n",
      "mean reward (100 episodes) 200.050553\n",
      "max reward (100 episodes) 290.898509\n",
      "mean step (100 episodes) 525.220000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 714\n",
      "timestep 307000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000383\n",
      "mean reward (100 episodes) 198.295508\n",
      "max reward (100 episodes) 290.898509\n",
      "mean step (100 episodes) 535.020000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 716\n",
      "timestep 308000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000382\n",
      "mean reward (100 episodes) 196.524647\n",
      "max reward (100 episodes) 290.898509\n",
      "mean step (100 episodes) 545.780000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 718\n",
      "timestep 309000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000382\n",
      "mean reward (100 episodes) 194.380066\n",
      "max reward (100 episodes) 290.898509\n",
      "mean step (100 episodes) 557.740000\n",
      "max step (100 episodes) 1000.000000\n",
      "Saved trajectories to save path: /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/trajs_5.pkl!\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_310000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 720\n",
      "timestep 310000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000382\n",
      "mean reward (100 episodes) 191.225339\n",
      "max reward (100 episodes) 290.898509\n",
      "mean step (100 episodes) 561.010000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 722\n",
      "timestep 311000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000381\n",
      "mean reward (100 episodes) 193.417060\n",
      "max reward (100 episodes) 311.228043\n",
      "mean step (100 episodes) 555.310000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 725\n",
      "timestep 312000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000381\n",
      "mean reward (100 episodes) 191.871386\n",
      "max reward (100 episodes) 311.228043\n",
      "mean step (100 episodes) 556.560000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 727\n",
      "timestep 313000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000381\n",
      "mean reward (100 episodes) 192.334451\n",
      "max reward (100 episodes) 311.228043\n",
      "mean step (100 episodes) 558.350000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 729\n",
      "timestep 314000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000381\n",
      "mean reward (100 episodes) 186.023855\n",
      "max reward (100 episodes) 311.228043\n",
      "mean step (100 episodes) 575.490000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 731\n",
      "timestep 315000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000380\n",
      "mean reward (100 episodes) 185.406200\n",
      "max reward (100 episodes) 311.228043\n",
      "mean step (100 episodes) 590.220000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 733\n",
      "timestep 316000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000380\n",
      "mean reward (100 episodes) 184.612968\n",
      "max reward (100 episodes) 311.228043\n",
      "mean step (100 episodes) 589.230000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 736\n",
      "timestep 317000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000380\n",
      "mean reward (100 episodes) 184.584489\n",
      "max reward (100 episodes) 311.228043\n",
      "mean step (100 episodes) 591.350000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 739\n",
      "timestep 318000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000379\n",
      "mean reward (100 episodes) 181.094635\n",
      "max reward (100 episodes) 311.228043\n",
      "mean step (100 episodes) 595.820000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 742\n",
      "timestep 319000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000379\n",
      "mean reward (100 episodes) 186.227696\n",
      "max reward (100 episodes) 311.228043\n",
      "mean step (100 episodes) 588.920000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_320000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 745\n",
      "timestep 320000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000379\n",
      "mean reward (100 episodes) 191.649603\n",
      "max reward (100 episodes) 311.228043\n",
      "mean step (100 episodes) 575.180000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 748\n",
      "timestep 321000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000379\n",
      "mean reward (100 episodes) 193.676388\n",
      "max reward (100 episodes) 311.228043\n",
      "mean step (100 episodes) 570.970000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 751\n",
      "timestep 322000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000378\n",
      "mean reward (100 episodes) 194.237794\n",
      "max reward (100 episodes) 311.466054\n",
      "mean step (100 episodes) 570.150000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 753\n",
      "timestep 323000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000378\n",
      "mean reward (100 episodes) 195.575436\n",
      "max reward (100 episodes) 311.466054\n",
      "mean step (100 episodes) 552.440000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 755\n",
      "timestep 324000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000378\n",
      "mean reward (100 episodes) 197.308721\n",
      "max reward (100 episodes) 311.466054\n",
      "mean step (100 episodes) 552.080000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 757\n",
      "timestep 325000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000377\n",
      "mean reward (100 episodes) 193.533352\n",
      "max reward (100 episodes) 311.466054\n",
      "mean step (100 episodes) 548.560000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 760\n",
      "timestep 326000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000377\n",
      "mean reward (100 episodes) 193.297662\n",
      "max reward (100 episodes) 311.466054\n",
      "mean step (100 episodes) 546.360000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 763\n",
      "timestep 327000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000377\n",
      "mean reward (100 episodes) 195.588996\n",
      "max reward (100 episodes) 311.466054\n",
      "mean step (100 episodes) 540.300000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 765\n",
      "timestep 328000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000377\n",
      "mean reward (100 episodes) 198.125640\n",
      "max reward (100 episodes) 311.466054\n",
      "mean step (100 episodes) 526.980000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 767\n",
      "timestep 329000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000376\n",
      "mean reward (100 episodes) 199.639470\n",
      "max reward (100 episodes) 311.466054\n",
      "mean step (100 episodes) 525.900000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_330000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 770\n",
      "timestep 330000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000376\n",
      "mean reward (100 episodes) 199.301656\n",
      "max reward (100 episodes) 311.466054\n",
      "mean step (100 episodes) 545.210000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 772\n",
      "timestep 331000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000376\n",
      "mean reward (100 episodes) 197.510196\n",
      "max reward (100 episodes) 311.466054\n",
      "mean step (100 episodes) 547.200000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 774\n",
      "timestep 332000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000375\n",
      "mean reward (100 episodes) 197.894880\n",
      "max reward (100 episodes) 311.466054\n",
      "mean step (100 episodes) 553.370000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 777\n",
      "timestep 333000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000375\n",
      "mean reward (100 episodes) 198.428889\n",
      "max reward (100 episodes) 311.466054\n",
      "mean step (100 episodes) 555.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 779\n",
      "timestep 334000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000375\n",
      "mean reward (100 episodes) 207.033207\n",
      "max reward (100 episodes) 311.466054\n",
      "mean step (100 episodes) 530.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 781\n",
      "timestep 335000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000375\n",
      "mean reward (100 episodes) 213.240284\n",
      "max reward (100 episodes) 311.466054\n",
      "mean step (100 episodes) 508.820000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 784\n",
      "timestep 336000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000374\n",
      "mean reward (100 episodes) 202.381674\n",
      "max reward (100 episodes) 311.466054\n",
      "mean step (100 episodes) 542.430000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 786\n",
      "timestep 337000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000374\n",
      "mean reward (100 episodes) 200.408343\n",
      "max reward (100 episodes) 311.466054\n",
      "mean step (100 episodes) 548.310000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 789\n",
      "timestep 338000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000374\n",
      "mean reward (100 episodes) 203.886674\n",
      "max reward (100 episodes) 311.466054\n",
      "mean step (100 episodes) 544.920000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 792\n",
      "timestep 339000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000373\n",
      "mean reward (100 episodes) 202.948991\n",
      "max reward (100 episodes) 311.466054\n",
      "mean step (100 episodes) 540.910000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_340000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 794\n",
      "timestep 340000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000373\n",
      "mean reward (100 episodes) 204.694795\n",
      "max reward (100 episodes) 311.466054\n",
      "mean step (100 episodes) 530.190000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 796\n",
      "timestep 341000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000373\n",
      "mean reward (100 episodes) 203.601147\n",
      "max reward (100 episodes) 311.466054\n",
      "mean step (100 episodes) 533.820000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 799\n",
      "timestep 342000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000373\n",
      "mean reward (100 episodes) 201.790770\n",
      "max reward (100 episodes) 307.235412\n",
      "mean step (100 episodes) 539.230000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 802\n",
      "timestep 343000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000372\n",
      "mean reward (100 episodes) 199.231231\n",
      "max reward (100 episodes) 307.235412\n",
      "mean step (100 episodes) 544.370000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 804\n",
      "timestep 344000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000372\n",
      "mean reward (100 episodes) 192.281892\n",
      "max reward (100 episodes) 307.235412\n",
      "mean step (100 episodes) 541.940000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 807\n",
      "timestep 345000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000372\n",
      "mean reward (100 episodes) 196.564843\n",
      "max reward (100 episodes) 306.818615\n",
      "mean step (100 episodes) 534.020000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 811\n",
      "timestep 346000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000371\n",
      "mean reward (100 episodes) 197.323157\n",
      "max reward (100 episodes) 306.818615\n",
      "mean step (100 episodes) 527.120000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 813\n",
      "timestep 347000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000371\n",
      "mean reward (100 episodes) 197.165412\n",
      "max reward (100 episodes) 306.818615\n",
      "mean step (100 episodes) 532.070000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 816\n",
      "timestep 348000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000371\n",
      "mean reward (100 episodes) 196.705550\n",
      "max reward (100 episodes) 306.818615\n",
      "mean step (100 episodes) 532.990000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 819\n",
      "timestep 349000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000371\n",
      "mean reward (100 episodes) 194.969863\n",
      "max reward (100 episodes) 306.818615\n",
      "mean step (100 episodes) 531.810000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_350000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 822\n",
      "timestep 350000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000370\n",
      "mean reward (100 episodes) 197.440954\n",
      "max reward (100 episodes) 306.818615\n",
      "mean step (100 episodes) 511.020000\n",
      "max step (100 episodes) 1000.000000\n",
      "Saved trajectories to save path: /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/trajs_6.pkl!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 824\n",
      "timestep 351000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000370\n",
      "mean reward (100 episodes) 195.995890\n",
      "max reward (100 episodes) 306.818615\n",
      "mean step (100 episodes) 511.990000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 826\n",
      "timestep 352000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000370\n",
      "mean reward (100 episodes) 196.835893\n",
      "max reward (100 episodes) 306.818615\n",
      "mean step (100 episodes) 497.070000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 828\n",
      "timestep 353000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000370\n",
      "mean reward (100 episodes) 196.280010\n",
      "max reward (100 episodes) 306.818615\n",
      "mean step (100 episodes) 489.380000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 830\n",
      "timestep 354000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000369\n",
      "mean reward (100 episodes) 191.773676\n",
      "max reward (100 episodes) 306.818615\n",
      "mean step (100 episodes) 510.760000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 833\n",
      "timestep 355000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000369\n",
      "mean reward (100 episodes) 187.386184\n",
      "max reward (100 episodes) 306.818615\n",
      "mean step (100 episodes) 525.860000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 835\n",
      "timestep 356000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000369\n",
      "mean reward (100 episodes) 193.646677\n",
      "max reward (100 episodes) 306.818615\n",
      "mean step (100 episodes) 507.880000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 837\n",
      "timestep 357000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000368\n",
      "mean reward (100 episodes) 191.868154\n",
      "max reward (100 episodes) 306.818615\n",
      "mean step (100 episodes) 503.940000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 840\n",
      "timestep 358000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000368\n",
      "mean reward (100 episodes) 192.016695\n",
      "max reward (100 episodes) 284.106030\n",
      "mean step (100 episodes) 501.830000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 842\n",
      "timestep 359000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000368\n",
      "mean reward (100 episodes) 188.508567\n",
      "max reward (100 episodes) 284.106030\n",
      "mean step (100 episodes) 509.570000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_360000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 844\n",
      "timestep 360000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000368\n",
      "mean reward (100 episodes) 186.803718\n",
      "max reward (100 episodes) 285.663116\n",
      "mean step (100 episodes) 520.410000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 846\n",
      "timestep 361000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000367\n",
      "mean reward (100 episodes) 190.105682\n",
      "max reward (100 episodes) 289.816882\n",
      "mean step (100 episodes) 502.980000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 849\n",
      "timestep 362000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000367\n",
      "mean reward (100 episodes) 190.067894\n",
      "max reward (100 episodes) 289.816882\n",
      "mean step (100 episodes) 502.030000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 853\n",
      "timestep 363000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000367\n",
      "mean reward (100 episodes) 194.628385\n",
      "max reward (100 episodes) 289.816882\n",
      "mean step (100 episodes) 491.170000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 856\n",
      "timestep 364000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000367\n",
      "mean reward (100 episodes) 200.758392\n",
      "max reward (100 episodes) 289.816882\n",
      "mean step (100 episodes) 483.380000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 859\n",
      "timestep 365000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000366\n",
      "mean reward (100 episodes) 201.903308\n",
      "max reward (100 episodes) 289.816882\n",
      "mean step (100 episodes) 482.670000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 861\n",
      "timestep 366000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000366\n",
      "mean reward (100 episodes) 201.449548\n",
      "max reward (100 episodes) 289.816882\n",
      "mean step (100 episodes) 488.900000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 863\n",
      "timestep 367000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000366\n",
      "mean reward (100 episodes) 198.350418\n",
      "max reward (100 episodes) 289.816882\n",
      "mean step (100 episodes) 500.340000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 865\n",
      "timestep 368000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000365\n",
      "mean reward (100 episodes) 196.116505\n",
      "max reward (100 episodes) 289.816882\n",
      "mean step (100 episodes) 512.510000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 867\n",
      "timestep 369000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000365\n",
      "mean reward (100 episodes) 199.035814\n",
      "max reward (100 episodes) 289.816882\n",
      "mean step (100 episodes) 501.580000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_370000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 869\n",
      "timestep 370000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000365\n",
      "mean reward (100 episodes) 195.964820\n",
      "max reward (100 episodes) 289.816882\n",
      "mean step (100 episodes) 523.610000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 871\n",
      "timestep 371000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000365\n",
      "mean reward (100 episodes) 195.051680\n",
      "max reward (100 episodes) 289.816882\n",
      "mean step (100 episodes) 531.230000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 874\n",
      "timestep 372000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000364\n",
      "mean reward (100 episodes) 194.323896\n",
      "max reward (100 episodes) 289.816882\n",
      "mean step (100 episodes) 536.120000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 876\n",
      "timestep 373000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000364\n",
      "mean reward (100 episodes) 191.227727\n",
      "max reward (100 episodes) 289.816882\n",
      "mean step (100 episodes) 549.440000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 879\n",
      "timestep 374000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000364\n",
      "mean reward (100 episodes) 192.977634\n",
      "max reward (100 episodes) 289.816882\n",
      "mean step (100 episodes) 538.160000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 881\n",
      "timestep 375000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000364\n",
      "mean reward (100 episodes) 189.966841\n",
      "max reward (100 episodes) 289.816882\n",
      "mean step (100 episodes) 547.290000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 883\n",
      "timestep 376000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000363\n",
      "mean reward (100 episodes) 186.098174\n",
      "max reward (100 episodes) 289.816882\n",
      "mean step (100 episodes) 558.140000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 886\n",
      "timestep 377000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000363\n",
      "mean reward (100 episodes) 185.786899\n",
      "max reward (100 episodes) 289.816882\n",
      "mean step (100 episodes) 563.900000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 888\n",
      "timestep 378000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000363\n",
      "mean reward (100 episodes) 185.796215\n",
      "max reward (100 episodes) 289.816882\n",
      "mean step (100 episodes) 565.670000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 891\n",
      "timestep 379000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000363\n",
      "mean reward (100 episodes) 185.938029\n",
      "max reward (100 episodes) 289.816882\n",
      "mean step (100 episodes) 570.960000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_380000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 893\n",
      "timestep 380000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000362\n",
      "mean reward (100 episodes) 185.746207\n",
      "max reward (100 episodes) 289.816882\n",
      "mean step (100 episodes) 571.360000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 895\n",
      "timestep 381000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000362\n",
      "mean reward (100 episodes) 183.891014\n",
      "max reward (100 episodes) 287.907750\n",
      "mean step (100 episodes) 587.050000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 897\n",
      "timestep 382000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000362\n",
      "mean reward (100 episodes) 183.016198\n",
      "max reward (100 episodes) 287.907750\n",
      "mean step (100 episodes) 588.680000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 900\n",
      "timestep 383000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000362\n",
      "mean reward (100 episodes) 173.798013\n",
      "max reward (100 episodes) 287.907750\n",
      "mean step (100 episodes) 615.510000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 903\n",
      "timestep 384000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000361\n",
      "mean reward (100 episodes) 174.527714\n",
      "max reward (100 episodes) 287.907750\n",
      "mean step (100 episodes) 615.190000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 905\n",
      "timestep 385000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000361\n",
      "mean reward (100 episodes) 173.253979\n",
      "max reward (100 episodes) 287.907750\n",
      "mean step (100 episodes) 620.900000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 907\n",
      "timestep 386000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000361\n",
      "mean reward (100 episodes) 173.414783\n",
      "max reward (100 episodes) 287.907750\n",
      "mean step (100 episodes) 626.110000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 910\n",
      "timestep 387000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000360\n",
      "mean reward (100 episodes) 177.781136\n",
      "max reward (100 episodes) 287.907750\n",
      "mean step (100 episodes) 611.620000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 912\n",
      "timestep 388000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000360\n",
      "mean reward (100 episodes) 180.688885\n",
      "max reward (100 episodes) 291.589082\n",
      "mean step (100 episodes) 601.770000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 915\n",
      "timestep 389000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000360\n",
      "mean reward (100 episodes) 179.517930\n",
      "max reward (100 episodes) 291.589082\n",
      "mean step (100 episodes) 606.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_390000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 918\n",
      "timestep 390000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000360\n",
      "mean reward (100 episodes) 180.322587\n",
      "max reward (100 episodes) 291.589082\n",
      "mean step (100 episodes) 594.220000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 921\n",
      "timestep 391000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000359\n",
      "mean reward (100 episodes) 181.029963\n",
      "max reward (100 episodes) 291.589082\n",
      "mean step (100 episodes) 594.350000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 924\n",
      "timestep 392000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000359\n",
      "mean reward (100 episodes) 183.039887\n",
      "max reward (100 episodes) 291.589082\n",
      "mean step (100 episodes) 595.800000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 926\n",
      "timestep 393000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000359\n",
      "mean reward (100 episodes) 185.009178\n",
      "max reward (100 episodes) 291.589082\n",
      "mean step (100 episodes) 590.690000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 929\n",
      "timestep 394000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000359\n",
      "mean reward (100 episodes) 182.952231\n",
      "max reward (100 episodes) 291.589082\n",
      "mean step (100 episodes) 586.360000\n",
      "max step (100 episodes) 1000.000000\n",
      "Saved trajectories to save path: /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/trajs_7.pkl!\n",
      "------------------------------------------------\n",
      "episodes 932\n",
      "timestep 395000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000358\n",
      "mean reward (100 episodes) 188.528193\n",
      "max reward (100 episodes) 291.589082\n",
      "mean step (100 episodes) 570.880000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 935\n",
      "timestep 396000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000358\n",
      "mean reward (100 episodes) 196.131906\n",
      "max reward (100 episodes) 291.589082\n",
      "mean step (100 episodes) 542.240000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 937\n",
      "timestep 397000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000358\n",
      "mean reward (100 episodes) 199.786253\n",
      "max reward (100 episodes) 291.589082\n",
      "mean step (100 episodes) 524.590000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 940\n",
      "timestep 398000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000358\n",
      "mean reward (100 episodes) 194.587172\n",
      "max reward (100 episodes) 291.589082\n",
      "mean step (100 episodes) 539.880000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 943\n",
      "timestep 399000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000357\n",
      "mean reward (100 episodes) 197.904666\n",
      "max reward (100 episodes) 291.589082\n",
      "mean step (100 episodes) 525.990000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_400000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 946\n",
      "timestep 400000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000357\n",
      "mean reward (100 episodes) 199.598299\n",
      "max reward (100 episodes) 291.589082\n",
      "mean step (100 episodes) 518.570000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 948\n",
      "timestep 401000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000357\n",
      "mean reward (100 episodes) 199.224152\n",
      "max reward (100 episodes) 291.589082\n",
      "mean step (100 episodes) 512.350000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 951\n",
      "timestep 402000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000357\n",
      "mean reward (100 episodes) 202.516674\n",
      "max reward (100 episodes) 291.589082\n",
      "mean step (100 episodes) 504.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 954\n",
      "timestep 403000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000356\n",
      "mean reward (100 episodes) 209.500963\n",
      "max reward (100 episodes) 291.589082\n",
      "mean step (100 episodes) 485.300000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 957\n",
      "timestep 404000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000356\n",
      "mean reward (100 episodes) 209.291959\n",
      "max reward (100 episodes) 295.659543\n",
      "mean step (100 episodes) 482.930000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 960\n",
      "timestep 405000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000356\n",
      "mean reward (100 episodes) 211.735319\n",
      "max reward (100 episodes) 295.659543\n",
      "mean step (100 episodes) 478.460000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 963\n",
      "timestep 406000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000356\n",
      "mean reward (100 episodes) 213.017802\n",
      "max reward (100 episodes) 309.274418\n",
      "mean step (100 episodes) 466.530000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 965\n",
      "timestep 407000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000355\n",
      "mean reward (100 episodes) 211.767656\n",
      "max reward (100 episodes) 309.274418\n",
      "mean step (100 episodes) 471.560000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 967\n",
      "timestep 408000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000355\n",
      "mean reward (100 episodes) 209.074830\n",
      "max reward (100 episodes) 309.274418\n",
      "mean step (100 episodes) 476.150000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 970\n",
      "timestep 409000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000355\n",
      "mean reward (100 episodes) 210.061761\n",
      "max reward (100 episodes) 309.274418\n",
      "mean step (100 episodes) 476.530000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_410000.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 972\n",
      "timestep 410000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000355\n",
      "mean reward (100 episodes) 212.541716\n",
      "max reward (100 episodes) 309.274418\n",
      "mean step (100 episodes) 469.450000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 975\n",
      "timestep 411000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000354\n",
      "mean reward (100 episodes) 213.458118\n",
      "max reward (100 episodes) 309.274418\n",
      "mean step (100 episodes) 461.370000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 978\n",
      "timestep 412000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000354\n",
      "mean reward (100 episodes) 212.536533\n",
      "max reward (100 episodes) 309.274418\n",
      "mean step (100 episodes) 456.480000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 982\n",
      "timestep 413000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000354\n",
      "mean reward (100 episodes) 215.266937\n",
      "max reward (100 episodes) 309.274418\n",
      "mean step (100 episodes) 448.420000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 986\n",
      "timestep 414000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000354\n",
      "mean reward (100 episodes) 217.798273\n",
      "max reward (100 episodes) 309.274418\n",
      "mean step (100 episodes) 450.320000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 988\n",
      "timestep 415000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000353\n",
      "mean reward (100 episodes) 218.101265\n",
      "max reward (100 episodes) 309.274418\n",
      "mean step (100 episodes) 449.490000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 991\n",
      "timestep 416000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000353\n",
      "mean reward (100 episodes) 218.509675\n",
      "max reward (100 episodes) 309.274418\n",
      "mean step (100 episodes) 458.660000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 993\n",
      "timestep 417000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000353\n",
      "mean reward (100 episodes) 216.970118\n",
      "max reward (100 episodes) 309.274418\n",
      "mean step (100 episodes) 477.380000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 996\n",
      "timestep 418000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000353\n",
      "mean reward (100 episodes) 222.037692\n",
      "max reward (100 episodes) 309.274418\n",
      "mean step (100 episodes) 458.940000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 999\n",
      "timestep 419000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000352\n",
      "mean reward (100 episodes) 213.615150\n",
      "max reward (100 episodes) 309.274418\n",
      "mean step (100 episodes) 483.920000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_420000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1002\n",
      "timestep 420000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000352\n",
      "mean reward (100 episodes) 211.248322\n",
      "max reward (100 episodes) 309.274418\n",
      "mean step (100 episodes) 494.350000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1006\n",
      "timestep 421000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000352\n",
      "mean reward (100 episodes) 208.072171\n",
      "max reward (100 episodes) 309.274418\n",
      "mean step (100 episodes) 500.240000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1010\n",
      "timestep 422000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000352\n",
      "mean reward (100 episodes) 207.542189\n",
      "max reward (100 episodes) 309.274418\n",
      "mean step (100 episodes) 511.060000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1013\n",
      "timestep 423000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000351\n",
      "mean reward (100 episodes) 205.677770\n",
      "max reward (100 episodes) 309.274418\n",
      "mean step (100 episodes) 519.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1015\n",
      "timestep 424000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000351\n",
      "mean reward (100 episodes) 207.185109\n",
      "max reward (100 episodes) 309.274418\n",
      "mean step (100 episodes) 517.360000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1018\n",
      "timestep 425000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000351\n",
      "mean reward (100 episodes) 208.402992\n",
      "max reward (100 episodes) 309.274418\n",
      "mean step (100 episodes) 505.440000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1022\n",
      "timestep 426000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000351\n",
      "mean reward (100 episodes) 203.968231\n",
      "max reward (100 episodes) 291.741583\n",
      "mean step (100 episodes) 525.940000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1024\n",
      "timestep 427000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000350\n",
      "mean reward (100 episodes) 205.045689\n",
      "max reward (100 episodes) 291.741583\n",
      "mean step (100 episodes) 513.560000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1027\n",
      "timestep 428000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000350\n",
      "mean reward (100 episodes) 208.314798\n",
      "max reward (100 episodes) 291.741583\n",
      "mean step (100 episodes) 502.910000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1030\n",
      "timestep 429000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000350\n",
      "mean reward (100 episodes) 206.655384\n",
      "max reward (100 episodes) 291.741583\n",
      "mean step (100 episodes) 508.680000\n",
      "max step (100 episodes) 1000.000000\n",
      "Saved trajectories to save path: /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/trajs_8.pkl!\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_430000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1033\n",
      "timestep 430000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000350\n",
      "mean reward (100 episodes) 207.732140\n",
      "max reward (100 episodes) 291.741583\n",
      "mean step (100 episodes) 499.150000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1037\n",
      "timestep 431000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000349\n",
      "mean reward (100 episodes) 203.946621\n",
      "max reward (100 episodes) 287.539748\n",
      "mean step (100 episodes) 522.510000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1039\n",
      "timestep 432000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000349\n",
      "mean reward (100 episodes) 202.098982\n",
      "max reward (100 episodes) 287.539748\n",
      "mean step (100 episodes) 517.400000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1041\n",
      "timestep 433000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000349\n",
      "mean reward (100 episodes) 202.611940\n",
      "max reward (100 episodes) 287.539748\n",
      "mean step (100 episodes) 524.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1043\n",
      "timestep 434000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000349\n",
      "mean reward (100 episodes) 197.249785\n",
      "max reward (100 episodes) 287.539748\n",
      "mean step (100 episodes) 550.560000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1046\n",
      "timestep 435000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000348\n",
      "mean reward (100 episodes) 195.180435\n",
      "max reward (100 episodes) 287.539748\n",
      "mean step (100 episodes) 553.050000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1048\n",
      "timestep 436000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000348\n",
      "mean reward (100 episodes) 194.037408\n",
      "max reward (100 episodes) 287.539748\n",
      "mean step (100 episodes) 556.620000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1051\n",
      "timestep 437000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000348\n",
      "mean reward (100 episodes) 195.158138\n",
      "max reward (100 episodes) 287.539748\n",
      "mean step (100 episodes) 550.650000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1054\n",
      "timestep 438000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000348\n",
      "mean reward (100 episodes) 193.768910\n",
      "max reward (100 episodes) 297.689560\n",
      "mean step (100 episodes) 565.740000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1056\n",
      "timestep 439000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000347\n",
      "mean reward (100 episodes) 195.477006\n",
      "max reward (100 episodes) 297.689560\n",
      "mean step (100 episodes) 566.920000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_440000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1059\n",
      "timestep 440000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000347\n",
      "mean reward (100 episodes) 197.318418\n",
      "max reward (100 episodes) 297.689560\n",
      "mean step (100 episodes) 555.610000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1063\n",
      "timestep 441000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000347\n",
      "mean reward (100 episodes) 200.652172\n",
      "max reward (100 episodes) 297.689560\n",
      "mean step (100 episodes) 555.480000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1066\n",
      "timestep 442000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000347\n",
      "mean reward (100 episodes) 199.504894\n",
      "max reward (100 episodes) 297.689560\n",
      "mean step (100 episodes) 551.220000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1068\n",
      "timestep 443000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000347\n",
      "mean reward (100 episodes) 200.896088\n",
      "max reward (100 episodes) 297.689560\n",
      "mean step (100 episodes) 538.430000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1071\n",
      "timestep 444000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000346\n",
      "mean reward (100 episodes) 198.042376\n",
      "max reward (100 episodes) 297.689560\n",
      "mean step (100 episodes) 548.160000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1074\n",
      "timestep 445000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000346\n",
      "mean reward (100 episodes) 195.978408\n",
      "max reward (100 episodes) 297.689560\n",
      "mean step (100 episodes) 558.330000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1077\n",
      "timestep 446000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000346\n",
      "mean reward (100 episodes) 200.009753\n",
      "max reward (100 episodes) 299.821709\n",
      "mean step (100 episodes) 543.680000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1079\n",
      "timestep 447000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000346\n",
      "mean reward (100 episodes) 198.343332\n",
      "max reward (100 episodes) 299.821709\n",
      "mean step (100 episodes) 557.180000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1082\n",
      "timestep 448000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000345\n",
      "mean reward (100 episodes) 197.524848\n",
      "max reward (100 episodes) 299.821709\n",
      "mean step (100 episodes) 562.570000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1084\n",
      "timestep 449000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000345\n",
      "mean reward (100 episodes) 196.515060\n",
      "max reward (100 episodes) 299.821709\n",
      "mean step (100 episodes) 561.200000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_450000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1087\n",
      "timestep 450000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000345\n",
      "mean reward (100 episodes) 194.185911\n",
      "max reward (100 episodes) 299.821709\n",
      "mean step (100 episodes) 573.570000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1091\n",
      "timestep 451000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000345\n",
      "mean reward (100 episodes) 193.564136\n",
      "max reward (100 episodes) 299.821709\n",
      "mean step (100 episodes) 570.860000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1094\n",
      "timestep 452000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000344\n",
      "mean reward (100 episodes) 195.251193\n",
      "max reward (100 episodes) 299.821709\n",
      "mean step (100 episodes) 577.520000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1097\n",
      "timestep 453000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000344\n",
      "mean reward (100 episodes) 192.807620\n",
      "max reward (100 episodes) 299.821709\n",
      "mean step (100 episodes) 575.400000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1099\n",
      "timestep 454000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000344\n",
      "mean reward (100 episodes) 195.282098\n",
      "max reward (100 episodes) 299.821709\n",
      "mean step (100 episodes) 570.040000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1102\n",
      "timestep 455000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000344\n",
      "mean reward (100 episodes) 190.249266\n",
      "max reward (100 episodes) 299.821709\n",
      "mean step (100 episodes) 588.740000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1104\n",
      "timestep 456000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000343\n",
      "mean reward (100 episodes) 190.045529\n",
      "max reward (100 episodes) 299.821709\n",
      "mean step (100 episodes) 594.860000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1106\n",
      "timestep 457000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000343\n",
      "mean reward (100 episodes) 188.751290\n",
      "max reward (100 episodes) 299.821709\n",
      "mean step (100 episodes) 590.330000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1108\n",
      "timestep 458000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000343\n",
      "mean reward (100 episodes) 190.368422\n",
      "max reward (100 episodes) 299.821709\n",
      "mean step (100 episodes) 575.970000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1112\n",
      "timestep 459000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000343\n",
      "mean reward (100 episodes) 193.717249\n",
      "max reward (100 episodes) 299.821709\n",
      "mean step (100 episodes) 561.800000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_460000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1114\n",
      "timestep 460000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000342\n",
      "mean reward (100 episodes) 193.963561\n",
      "max reward (100 episodes) 299.821709\n",
      "mean step (100 episodes) 565.850000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1116\n",
      "timestep 461000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000342\n",
      "mean reward (100 episodes) 194.291389\n",
      "max reward (100 episodes) 299.821709\n",
      "mean step (100 episodes) 563.670000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1119\n",
      "timestep 462000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000342\n",
      "mean reward (100 episodes) 195.565779\n",
      "max reward (100 episodes) 299.821709\n",
      "mean step (100 episodes) 557.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1122\n",
      "timestep 463000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000342\n",
      "mean reward (100 episodes) 196.318908\n",
      "max reward (100 episodes) 299.821709\n",
      "mean step (100 episodes) 552.590000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1125\n",
      "timestep 464000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000342\n",
      "mean reward (100 episodes) 197.617338\n",
      "max reward (100 episodes) 299.821709\n",
      "mean step (100 episodes) 547.140000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1127\n",
      "timestep 465000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000341\n",
      "mean reward (100 episodes) 198.910916\n",
      "max reward (100 episodes) 299.821709\n",
      "mean step (100 episodes) 541.940000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1129\n",
      "timestep 466000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000341\n",
      "mean reward (100 episodes) 199.604954\n",
      "max reward (100 episodes) 291.748888\n",
      "mean step (100 episodes) 536.190000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1132\n",
      "timestep 467000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000341\n",
      "mean reward (100 episodes) 200.871133\n",
      "max reward (100 episodes) 291.748888\n",
      "mean step (100 episodes) 528.880000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1134\n",
      "timestep 468000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000341\n",
      "mean reward (100 episodes) 200.498531\n",
      "max reward (100 episodes) 291.748888\n",
      "mean step (100 episodes) 535.480000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1138\n",
      "timestep 469000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000340\n",
      "mean reward (100 episodes) 201.445590\n",
      "max reward (100 episodes) 291.748888\n",
      "mean step (100 episodes) 530.330000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trajectories to save path: /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/trajs_9.pkl!\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_470000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1140\n",
      "timestep 470000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000340\n",
      "mean reward (100 episodes) 201.613174\n",
      "max reward (100 episodes) 291.748888\n",
      "mean step (100 episodes) 530.790000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1142\n",
      "timestep 471000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000340\n",
      "mean reward (100 episodes) 205.278901\n",
      "max reward (100 episodes) 294.897403\n",
      "mean step (100 episodes) 515.860000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1145\n",
      "timestep 472000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000340\n",
      "mean reward (100 episodes) 205.126479\n",
      "max reward (100 episodes) 294.897403\n",
      "mean step (100 episodes) 520.640000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1149\n",
      "timestep 473000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000339\n",
      "mean reward (100 episodes) 208.500422\n",
      "max reward (100 episodes) 294.897403\n",
      "mean step (100 episodes) 514.800000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1152\n",
      "timestep 474000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000339\n",
      "mean reward (100 episodes) 211.497205\n",
      "max reward (100 episodes) 294.897403\n",
      "mean step (100 episodes) 492.060000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1154\n",
      "timestep 475000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000339\n",
      "mean reward (100 episodes) 219.501973\n",
      "max reward (100 episodes) 294.897403\n",
      "mean step (100 episodes) 469.620000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1157\n",
      "timestep 476000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000339\n",
      "mean reward (100 episodes) 221.671014\n",
      "max reward (100 episodes) 294.897403\n",
      "mean step (100 episodes) 455.530000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1159\n",
      "timestep 477000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000339\n",
      "mean reward (100 episodes) 221.802557\n",
      "max reward (100 episodes) 294.897403\n",
      "mean step (100 episodes) 460.760000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1162\n",
      "timestep 478000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000338\n",
      "mean reward (100 episodes) 217.386623\n",
      "max reward (100 episodes) 294.897403\n",
      "mean step (100 episodes) 484.710000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1165\n",
      "timestep 479000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000338\n",
      "mean reward (100 episodes) 220.770196\n",
      "max reward (100 episodes) 294.897403\n",
      "mean step (100 episodes) 471.760000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_480000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1169\n",
      "timestep 480000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000338\n",
      "mean reward (100 episodes) 221.152254\n",
      "max reward (100 episodes) 294.897403\n",
      "mean step (100 episodes) 471.050000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1173\n",
      "timestep 481000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000338\n",
      "mean reward (100 episodes) 222.826425\n",
      "max reward (100 episodes) 294.897403\n",
      "mean step (100 episodes) 455.080000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1176\n",
      "timestep 482000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000337\n",
      "mean reward (100 episodes) 224.121325\n",
      "max reward (100 episodes) 295.074643\n",
      "mean step (100 episodes) 448.530000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1179\n",
      "timestep 483000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000337\n",
      "mean reward (100 episodes) 224.846180\n",
      "max reward (100 episodes) 295.074643\n",
      "mean step (100 episodes) 444.480000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1182\n",
      "timestep 484000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000337\n",
      "mean reward (100 episodes) 227.324575\n",
      "max reward (100 episodes) 295.074643\n",
      "mean step (100 episodes) 443.240000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1184\n",
      "timestep 485000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000337\n",
      "mean reward (100 episodes) 226.654481\n",
      "max reward (100 episodes) 295.074643\n",
      "mean step (100 episodes) 452.350000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1186\n",
      "timestep 486000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000336\n",
      "mean reward (100 episodes) 222.730477\n",
      "max reward (100 episodes) 295.074643\n",
      "mean step (100 episodes) 473.370000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1190\n",
      "timestep 487000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000336\n",
      "mean reward (100 episodes) 225.076872\n",
      "max reward (100 episodes) 295.074643\n",
      "mean step (100 episodes) 462.340000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1194\n",
      "timestep 488000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000336\n",
      "mean reward (100 episodes) 227.837053\n",
      "max reward (100 episodes) 295.074643\n",
      "mean step (100 episodes) 443.630000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1198\n",
      "timestep 489000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000336\n",
      "mean reward (100 episodes) 228.638031\n",
      "max reward (100 episodes) 295.074643\n",
      "mean step (100 episodes) 441.100000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_490000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1201\n",
      "timestep 490000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000336\n",
      "mean reward (100 episodes) 230.005765\n",
      "max reward (100 episodes) 295.074643\n",
      "mean step (100 episodes) 432.830000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1204\n",
      "timestep 491000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000335\n",
      "mean reward (100 episodes) 230.259203\n",
      "max reward (100 episodes) 295.074643\n",
      "mean step (100 episodes) 431.380000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1208\n",
      "timestep 492000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000335\n",
      "mean reward (100 episodes) 231.909122\n",
      "max reward (100 episodes) 295.074643\n",
      "mean step (100 episodes) 414.740000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1211\n",
      "timestep 493000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000335\n",
      "mean reward (100 episodes) 229.659446\n",
      "max reward (100 episodes) 295.074643\n",
      "mean step (100 episodes) 427.180000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1213\n",
      "timestep 494000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000335\n",
      "mean reward (100 episodes) 230.859125\n",
      "max reward (100 episodes) 317.089284\n",
      "mean step (100 episodes) 418.780000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1217\n",
      "timestep 495000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000334\n",
      "mean reward (100 episodes) 230.995189\n",
      "max reward (100 episodes) 317.089284\n",
      "mean step (100 episodes) 414.430000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1220\n",
      "timestep 496000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000334\n",
      "mean reward (100 episodes) 229.553504\n",
      "max reward (100 episodes) 317.089284\n",
      "mean step (100 episodes) 407.000000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1222\n",
      "timestep 497000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000334\n",
      "mean reward (100 episodes) 229.681079\n",
      "max reward (100 episodes) 317.089284\n",
      "mean step (100 episodes) 391.160000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1224\n",
      "timestep 498000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000334\n",
      "mean reward (100 episodes) 232.167965\n",
      "max reward (100 episodes) 317.089284\n",
      "mean step (100 episodes) 381.000000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 1227\n",
      "timestep 499000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000334\n",
      "mean reward (100 episodes) 232.686116\n",
      "max reward (100 episodes) 317.089284\n",
      "mean step (100 episodes) 382.780000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/dqn_500000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1231\n",
      "timestep 500000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000333\n",
      "mean reward (100 episodes) 232.855229\n",
      "max reward (100 episodes) 317.089284\n",
      "mean step (100 episodes) 367.290000\n",
      "max step (100 episodes) 1000.000000\n",
      "Saved trajectories to save path: /data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/trajs_10.pkl!\n"
     ]
    }
   ],
   "source": [
    "config['max_training_steps'] = 500000\n",
    "config['lr'] = 5e-4\n",
    "config['decay_steps'] = 1000000\n",
    "config['episode_counts_to_save'] = 500\n",
    "\n",
    "config['persistent_directory'] = '/data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/'\n",
    "config['checkpoint_path'] = '/data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/'\n",
    "\n",
    "agent = QuantileAgent(name='LunarLander-v2', num_actions=4, config=config)\n",
    "agent.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'max step')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rewards = pd.Series(agent.eval_episode_rewards)\n",
    "steps = pd.Series(agent.eval_episode_steps)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 8))\n",
    "\n",
    "axes[0][0].plot(rewards.rolling(100, min_periods=20).mean())\n",
    "axes[0][0].set_title('mean reward')\n",
    "axes[0][1].plot(rewards.rolling(100, min_periods=20).max())\n",
    "axes[0][1].set_title('max reward')\n",
    "axes[1][0].plot(steps.rolling(100, min_periods=20).mean())\n",
    "axes[1][0].set_title('mean step')\n",
    "axes[1][1].plot(steps.rolling(100, min_periods=20).max())\n",
    "axes[1][1].set_title('max step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent._eval(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persistent_directory = '/data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/'\n",
    "# files = os.listdir(persistent_directory)\n",
    "# files = sorted([file for file in files if file.endswith('.pkl')])\n",
    "\n",
    "# trajs = []\n",
    "# for file in files:\n",
    "#     path = persistent_directory + file\n",
    "#     with open(path, 'rb') as f:\n",
    "#         trajs.append(pickle.load(f))\n",
    "\n",
    "# trajs = [traj for file in trajs for traj in file] \n",
    "# # random.shuffle(trajs)\n",
    "\n",
    "# with open(persistent_directory+'/trajs_qr_dqn.pkl', 'wb') as f:\n",
    "#     pickle.dump(trajs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline QR-DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config['online'] = False\n",
    "config['max_training_steps'] = 500000\n",
    "config['lr'] = 5e-4\n",
    "config['decay_steps'] = 100000\n",
    "\n",
    "config['persistent_directory'] = '/data1/Prophet/sluo/projects/SALE/result/dqn/agent/'\n",
    "config['checkpoint_path'] = '/data1/Prophet/sluo/projects/SALE/result/qr_dqn/agent/ckpt/online/'\n",
    "\n",
    "# agent = QuantileAgent(name='LunarLander-v2', num_actions=4, config=config)\n",
    "# agent.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = pd.Series(agent.eval_episode_rewards)\n",
    "steps = pd.Series(agent.eval_episode_steps)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 8))\n",
    "\n",
    "axes[0][0].plot(rewards.rolling(100, min_periods=20).mean())\n",
    "axes[0][0].set_title('mean reward')\n",
    "axes[0][1].plot(rewards.rolling(100, min_periods=20).max())\n",
    "axes[0][1].set_title('max reward')\n",
    "axes[1][0].plot(steps.rolling(100, min_periods=20).mean())\n",
    "axes[1][0].set_title('mean step')\n",
    "axes[1][1].plot(steps.rolling(100, min_periods=20).max())\n",
    "axes[1][1].set_title('max step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

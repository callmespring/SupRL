{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.abspath('..')\n",
    "if path not in sys.path:\n",
    "    sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sale.agents.default_config import DEFAULT_CONFIG as config\n",
    "from sale.agents.qr_dqn import QuantileAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online QR-DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/Prophet/sluo/software/anaconda3/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save buffer every 500 episodes!\n",
      "------------------------------------------------\n",
      "episodes 15\n",
      "timestep 1000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000500\n",
      "mean reward (100 episodes) -587.876869\n",
      "max reward (100 episodes) -369.109733\n",
      "mean step (100 episodes) 68.600000\n",
      "max step (100 episodes) 88.000000\n",
      "------------------------------------------------\n",
      "episodes 26\n",
      "timestep 2000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000499\n",
      "mean reward (100 episodes) -328.748344\n",
      "max reward (100 episodes) -44.757731\n",
      "mean step (100 episodes) 534.300000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 32\n",
      "timestep 3000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000499\n",
      "mean reward (100 episodes) -313.422510\n",
      "max reward (100 episodes) -44.757731\n",
      "mean step (100 episodes) 513.200000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 35\n",
      "timestep 4000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000498\n",
      "mean reward (100 episodes) -328.856543\n",
      "max reward (100 episodes) -44.757731\n",
      "mean step (100 episodes) 497.550000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 37\n",
      "timestep 5000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000498\n",
      "mean reward (100 episodes) -286.212096\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 531.320000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 39\n",
      "timestep 6000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000497\n",
      "mean reward (100 episodes) -261.827855\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 577.433333\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 41\n",
      "timestep 7000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000497\n",
      "mean reward (100 episodes) -239.061193\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 620.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 43\n",
      "timestep 8000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000496\n",
      "mean reward (100 episodes) -235.187888\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 668.025000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 45\n",
      "timestep 9000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000496\n",
      "mean reward (100 episodes) -226.493603\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 704.911111\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_10000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 47\n",
      "timestep 10000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000495\n",
      "mean reward (100 episodes) -219.062011\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 734.420000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 49\n",
      "timestep 11000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000495\n",
      "mean reward (100 episodes) -210.081718\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 758.563636\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 51\n",
      "timestep 12000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000494\n",
      "mean reward (100 episodes) -205.700274\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 776.483333\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 53\n",
      "timestep 13000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000494\n",
      "mean reward (100 episodes) -200.813245\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 793.676923\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 55\n",
      "timestep 14000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000493\n",
      "mean reward (100 episodes) -196.836492\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 808.414286\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 57\n",
      "timestep 15000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000493\n",
      "mean reward (100 episodes) -192.780612\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 821.186667\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 59\n",
      "timestep 16000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000492\n",
      "mean reward (100 episodes) -189.233753\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 829.687500\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 61\n",
      "timestep 17000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000492\n",
      "mean reward (100 episodes) -185.415083\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 812.211765\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 63\n",
      "timestep 18000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000491\n",
      "mean reward (100 episodes) -183.242065\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 810.144444\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 65\n",
      "timestep 19000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000491\n",
      "mean reward (100 episodes) -180.571720\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 811.042105\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_20000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 67\n",
      "timestep 20000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000490\n",
      "mean reward (100 episodes) -177.014451\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 795.670000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 70\n",
      "timestep 21000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000490\n",
      "mean reward (100 episodes) -154.591817\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 825.250000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 72\n",
      "timestep 22000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000489\n",
      "mean reward (100 episodes) -158.492825\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 825.250000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 74\n",
      "timestep 23000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000489\n",
      "mean reward (100 episodes) -150.346317\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 835.400000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 76\n",
      "timestep 24000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000488\n",
      "mean reward (100 episodes) -137.037310\n",
      "max reward (100 episodes) 18.245708\n",
      "mean step (100 episodes) 842.190000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 78\n",
      "timestep 25000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000488\n",
      "mean reward (100 episodes) -139.355853\n",
      "max reward (100 episodes) 6.684170\n",
      "mean step (100 episodes) 842.880000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 80\n",
      "timestep 26000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000487\n",
      "mean reward (100 episodes) -137.546406\n",
      "max reward (100 episodes) 6.684170\n",
      "mean step (100 episodes) 844.660000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 82\n",
      "timestep 27000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000487\n",
      "mean reward (100 episodes) -137.634092\n",
      "max reward (100 episodes) -28.350185\n",
      "mean step (100 episodes) 833.990000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 84\n",
      "timestep 28000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000486\n",
      "mean reward (100 episodes) -135.631748\n",
      "max reward (100 episodes) -28.350185\n",
      "mean step (100 episodes) 810.100000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 86\n",
      "timestep 29000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000486\n",
      "mean reward (100 episodes) -135.792263\n",
      "max reward (100 episodes) -28.350185\n",
      "mean step (100 episodes) 800.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_30000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 90\n",
      "timestep 30000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000485\n",
      "mean reward (100 episodes) -133.925416\n",
      "max reward (100 episodes) -28.350185\n",
      "mean step (100 episodes) 786.750000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 94\n",
      "timestep 31000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000485\n",
      "mean reward (100 episodes) -132.354838\n",
      "max reward (100 episodes) -28.350185\n",
      "mean step (100 episodes) 769.510000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 96\n",
      "timestep 32000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000484\n",
      "mean reward (100 episodes) -131.906091\n",
      "max reward (100 episodes) -28.350185\n",
      "mean step (100 episodes) 754.910000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 98\n",
      "timestep 33000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000484\n",
      "mean reward (100 episodes) -129.996149\n",
      "max reward (100 episodes) 2.896017\n",
      "mean step (100 episodes) 737.440000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 100\n",
      "timestep 34000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000484\n",
      "mean reward (100 episodes) -125.288462\n",
      "max reward (100 episodes) 18.943683\n",
      "mean step (100 episodes) 721.190000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 102\n",
      "timestep 35000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000483\n",
      "mean reward (100 episodes) -122.796973\n",
      "max reward (100 episodes) 18.943683\n",
      "mean step (100 episodes) 696.150000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 104\n",
      "timestep 36000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000483\n",
      "mean reward (100 episodes) -120.369955\n",
      "max reward (100 episodes) 18.943683\n",
      "mean step (100 episodes) 677.420000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 106\n",
      "timestep 37000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000482\n",
      "mean reward (100 episodes) -116.998844\n",
      "max reward (100 episodes) 51.979232\n",
      "mean step (100 episodes) 677.300000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 108\n",
      "timestep 38000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000482\n",
      "mean reward (100 episodes) -115.483656\n",
      "max reward (100 episodes) 51.979232\n",
      "mean step (100 episodes) 672.140000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 110\n",
      "timestep 39000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000481\n",
      "mean reward (100 episodes) -111.362030\n",
      "max reward (100 episodes) 112.397920\n",
      "mean step (100 episodes) 657.980000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_40000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 112\n",
      "timestep 40000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000481\n",
      "mean reward (100 episodes) -106.433824\n",
      "max reward (100 episodes) 121.149601\n",
      "mean step (100 episodes) 680.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 115\n",
      "timestep 41000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000480\n",
      "mean reward (100 episodes) -98.638682\n",
      "max reward (100 episodes) 192.434161\n",
      "mean step (100 episodes) 679.770000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 117\n",
      "timestep 42000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000480\n",
      "mean reward (100 episodes) -91.887868\n",
      "max reward (100 episodes) 192.434161\n",
      "mean step (100 episodes) 674.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 119\n",
      "timestep 43000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000479\n",
      "mean reward (100 episodes) -88.189020\n",
      "max reward (100 episodes) 192.434161\n",
      "mean step (100 episodes) 690.560000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 121\n",
      "timestep 44000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000479\n",
      "mean reward (100 episodes) -83.318725\n",
      "max reward (100 episodes) 192.434161\n",
      "mean step (100 episodes) 711.240000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 123\n",
      "timestep 45000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000478\n",
      "mean reward (100 episodes) -77.495717\n",
      "max reward (100 episodes) 192.434161\n",
      "mean step (100 episodes) 726.290000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 125\n",
      "timestep 46000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000478\n",
      "mean reward (100 episodes) -72.492011\n",
      "max reward (100 episodes) 192.434161\n",
      "mean step (100 episodes) 733.030000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 127\n",
      "timestep 47000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000478\n",
      "mean reward (100 episodes) -66.936663\n",
      "max reward (100 episodes) 192.434161\n",
      "mean step (100 episodes) 745.860000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 129\n",
      "timestep 48000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000477\n",
      "mean reward (100 episodes) -57.865505\n",
      "max reward (100 episodes) 192.434161\n",
      "mean step (100 episodes) 761.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 131\n",
      "timestep 49000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000477\n",
      "mean reward (100 episodes) -46.719496\n",
      "max reward (100 episodes) 192.434161\n",
      "mean step (100 episodes) 765.060000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_50000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 133\n",
      "timestep 50000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000476\n",
      "mean reward (100 episodes) -39.049606\n",
      "max reward (100 episodes) 192.434161\n",
      "mean step (100 episodes) 778.640000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 135\n",
      "timestep 51000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000476\n",
      "mean reward (100 episodes) -36.681471\n",
      "max reward (100 episodes) 192.434161\n",
      "mean step (100 episodes) 777.860000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 137\n",
      "timestep 52000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000475\n",
      "mean reward (100 episodes) -22.402497\n",
      "max reward (100 episodes) 199.332140\n",
      "mean step (100 episodes) 787.310000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 139\n",
      "timestep 53000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000475\n",
      "mean reward (100 episodes) -17.359236\n",
      "max reward (100 episodes) 199.332140\n",
      "mean step (100 episodes) 802.830000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 141\n",
      "timestep 54000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000474\n",
      "mean reward (100 episodes) -13.071738\n",
      "max reward (100 episodes) 199.332140\n",
      "mean step (100 episodes) 814.130000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 143\n",
      "timestep 55000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000474\n",
      "mean reward (100 episodes) -5.209027\n",
      "max reward (100 episodes) 199.332140\n",
      "mean step (100 episodes) 833.620000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 145\n",
      "timestep 56000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000473\n",
      "mean reward (100 episodes) -2.530268\n",
      "max reward (100 episodes) 199.332140\n",
      "mean step (100 episodes) 852.120000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 147\n",
      "timestep 57000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000473\n",
      "mean reward (100 episodes) 4.207638\n",
      "max reward (100 episodes) 199.332140\n",
      "mean step (100 episodes) 875.610000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 149\n",
      "timestep 58000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000473\n",
      "mean reward (100 episodes) 12.477651\n",
      "max reward (100 episodes) 199.332140\n",
      "mean step (100 episodes) 890.810000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 151\n",
      "timestep 59000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000472\n",
      "mean reward (100 episodes) 15.328460\n",
      "max reward (100 episodes) 199.332140\n",
      "mean step (100 episodes) 913.610000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_60000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 153\n",
      "timestep 60000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000472\n",
      "mean reward (100 episodes) 15.410119\n",
      "max reward (100 episodes) 199.332140\n",
      "mean step (100 episodes) 904.200000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 155\n",
      "timestep 61000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000471\n",
      "mean reward (100 episodes) 14.632190\n",
      "max reward (100 episodes) 199.332140\n",
      "mean step (100 episodes) 912.080000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 157\n",
      "timestep 62000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000471\n",
      "mean reward (100 episodes) 20.729057\n",
      "max reward (100 episodes) 261.079226\n",
      "mean step (100 episodes) 900.940000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 159\n",
      "timestep 63000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000470\n",
      "mean reward (100 episodes) 26.803850\n",
      "max reward (100 episodes) 261.079226\n",
      "mean step (100 episodes) 885.140000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 161\n",
      "timestep 64000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000470\n",
      "mean reward (100 episodes) 32.527403\n",
      "max reward (100 episodes) 261.079226\n",
      "mean step (100 episodes) 869.130000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 163\n",
      "timestep 65000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000469\n",
      "mean reward (100 episodes) 40.769032\n",
      "max reward (100 episodes) 261.079226\n",
      "mean step (100 episodes) 852.160000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 165\n",
      "timestep 66000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000469\n",
      "mean reward (100 episodes) 42.315782\n",
      "max reward (100 episodes) 261.079226\n",
      "mean step (100 episodes) 853.240000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 167\n",
      "timestep 67000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000469\n",
      "mean reward (100 episodes) 43.709057\n",
      "max reward (100 episodes) 261.079226\n",
      "mean step (100 episodes) 841.860000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 169\n",
      "timestep 68000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000468\n",
      "mean reward (100 episodes) 43.261158\n",
      "max reward (100 episodes) 261.079226\n",
      "mean step (100 episodes) 840.050000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 171\n",
      "timestep 69000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000468\n",
      "mean reward (100 episodes) 42.223109\n",
      "max reward (100 episodes) 261.079226\n",
      "mean step (100 episodes) 828.310000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_70000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 174\n",
      "timestep 70000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000467\n",
      "mean reward (100 episodes) 41.069205\n",
      "max reward (100 episodes) 261.079226\n",
      "mean step (100 episodes) 810.480000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 177\n",
      "timestep 71000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000467\n",
      "mean reward (100 episodes) 46.047784\n",
      "max reward (100 episodes) 261.079226\n",
      "mean step (100 episodes) 814.720000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 180\n",
      "timestep 72000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000466\n",
      "mean reward (100 episodes) 42.800813\n",
      "max reward (100 episodes) 261.079226\n",
      "mean step (100 episodes) 806.430000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 182\n",
      "timestep 73000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000466\n",
      "mean reward (100 episodes) 45.128558\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 787.530000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 184\n",
      "timestep 74000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000466\n",
      "mean reward (100 episodes) 50.015438\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 789.570000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 186\n",
      "timestep 75000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000465\n",
      "mean reward (100 episodes) 50.656252\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 787.010000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 188\n",
      "timestep 76000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000465\n",
      "mean reward (100 episodes) 56.195127\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 789.380000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 190\n",
      "timestep 77000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000464\n",
      "mean reward (100 episodes) 54.673935\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 783.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 192\n",
      "timestep 78000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000464\n",
      "mean reward (100 episodes) 54.800793\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 778.790000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 194\n",
      "timestep 79000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000463\n",
      "mean reward (100 episodes) 61.113351\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 775.190000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_80000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 196\n",
      "timestep 80000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000463\n",
      "mean reward (100 episodes) 64.836352\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 775.340000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 198\n",
      "timestep 81000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000463\n",
      "mean reward (100 episodes) 73.486802\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 762.270000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 200\n",
      "timestep 82000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000462\n",
      "mean reward (100 episodes) 68.036536\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 772.040000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 202\n",
      "timestep 83000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000462\n",
      "mean reward (100 episodes) 67.823139\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 776.590000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 204\n",
      "timestep 84000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000461\n",
      "mean reward (100 episodes) 69.165532\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 770.960000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 206\n",
      "timestep 85000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000461\n",
      "mean reward (100 episodes) 69.242826\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 780.800000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 208\n",
      "timestep 86000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000460\n",
      "mean reward (100 episodes) 71.898921\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 774.500000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 210\n",
      "timestep 87000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000460\n",
      "mean reward (100 episodes) 73.191344\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 776.980000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 213\n",
      "timestep 88000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000460\n",
      "mean reward (100 episodes) 81.922368\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 762.670000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 215\n",
      "timestep 89000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000459\n",
      "mean reward (100 episodes) 91.429161\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 754.610000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_90000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 217\n",
      "timestep 90000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000459\n",
      "mean reward (100 episodes) 97.502919\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 760.050000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 219\n",
      "timestep 91000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000458\n",
      "mean reward (100 episodes) 97.957679\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 757.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 221\n",
      "timestep 92000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000458\n",
      "mean reward (100 episodes) 105.714990\n",
      "max reward (100 episodes) 282.300539\n",
      "mean step (100 episodes) 745.780000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 223\n",
      "timestep 93000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000457\n",
      "mean reward (100 episodes) 114.552431\n",
      "max reward (100 episodes) 279.586751\n",
      "mean step (100 episodes) 749.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 225\n",
      "timestep 94000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000457\n",
      "mean reward (100 episodes) 110.365960\n",
      "max reward (100 episodes) 279.954589\n",
      "mean step (100 episodes) 733.360000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 227\n",
      "timestep 95000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000457\n",
      "mean reward (100 episodes) 111.769504\n",
      "max reward (100 episodes) 279.954589\n",
      "mean step (100 episodes) 732.820000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 229\n",
      "timestep 96000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000456\n",
      "mean reward (100 episodes) 112.977610\n",
      "max reward (100 episodes) 279.954589\n",
      "mean step (100 episodes) 709.880000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 231\n",
      "timestep 97000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000456\n",
      "mean reward (100 episodes) 115.322560\n",
      "max reward (100 episodes) 279.954589\n",
      "mean step (100 episodes) 701.040000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 233\n",
      "timestep 98000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000455\n",
      "mean reward (100 episodes) 116.253996\n",
      "max reward (100 episodes) 279.954589\n",
      "mean step (100 episodes) 687.410000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 235\n",
      "timestep 99000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000455\n",
      "mean reward (100 episodes) 117.031373\n",
      "max reward (100 episodes) 291.986317\n",
      "mean step (100 episodes) 672.630000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_100000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 238\n",
      "timestep 100000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000455\n",
      "mean reward (100 episodes) 120.059268\n",
      "max reward (100 episodes) 291.986317\n",
      "mean step (100 episodes) 657.740000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 240\n",
      "timestep 101000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000454\n",
      "mean reward (100 episodes) 119.992704\n",
      "max reward (100 episodes) 291.986317\n",
      "mean step (100 episodes) 649.300000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 243\n",
      "timestep 102000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000454\n",
      "mean reward (100 episodes) 122.710811\n",
      "max reward (100 episodes) 291.986317\n",
      "mean step (100 episodes) 628.540000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 245\n",
      "timestep 103000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000453\n",
      "mean reward (100 episodes) 128.919685\n",
      "max reward (100 episodes) 291.986317\n",
      "mean step (100 episodes) 620.410000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 248\n",
      "timestep 104000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000453\n",
      "mean reward (100 episodes) 130.978355\n",
      "max reward (100 episodes) 291.986317\n",
      "mean step (100 episodes) 624.330000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 250\n",
      "timestep 105000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000452\n",
      "mean reward (100 episodes) 135.182903\n",
      "max reward (100 episodes) 291.986317\n",
      "mean step (100 episodes) 602.580000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 252\n",
      "timestep 106000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000452\n",
      "mean reward (100 episodes) 139.186265\n",
      "max reward (100 episodes) 291.986317\n",
      "mean step (100 episodes) 580.620000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 254\n",
      "timestep 107000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000452\n",
      "mean reward (100 episodes) 143.194287\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 558.610000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 256\n",
      "timestep 108000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000451\n",
      "mean reward (100 episodes) 145.349221\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 559.570000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 258\n",
      "timestep 109000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000451\n",
      "mean reward (100 episodes) 140.282708\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 555.560000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_110000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 260\n",
      "timestep 110000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000450\n",
      "mean reward (100 episodes) 140.971739\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 536.800000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 263\n",
      "timestep 111000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000450\n",
      "mean reward (100 episodes) 146.512880\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 530.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 266\n",
      "timestep 112000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000450\n",
      "mean reward (100 episodes) 148.065916\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 527.080000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 268\n",
      "timestep 113000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000449\n",
      "mean reward (100 episodes) 139.255914\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 514.990000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 272\n",
      "timestep 114000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000449\n",
      "mean reward (100 episodes) 147.297761\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 502.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 275\n",
      "timestep 115000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000448\n",
      "mean reward (100 episodes) 145.695873\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 486.660000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 277\n",
      "timestep 116000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000448\n",
      "mean reward (100 episodes) 141.538321\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 483.630000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 279\n",
      "timestep 117000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000448\n",
      "mean reward (100 episodes) 146.243606\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 481.940000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 281\n",
      "timestep 118000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000447\n",
      "mean reward (100 episodes) 151.468795\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 478.110000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 284\n",
      "timestep 119000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000447\n",
      "mean reward (100 episodes) 154.372689\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 465.910000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_120000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 287\n",
      "timestep 120000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000446\n",
      "mean reward (100 episodes) 157.138784\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 458.590000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 289\n",
      "timestep 121000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000446\n",
      "mean reward (100 episodes) 159.992361\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 457.650000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 291\n",
      "timestep 122000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000446\n",
      "mean reward (100 episodes) 161.833820\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 457.300000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 293\n",
      "timestep 123000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000445\n",
      "mean reward (100 episodes) 163.950892\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 445.250000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 295\n",
      "timestep 124000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000445\n",
      "mean reward (100 episodes) 166.252770\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 434.500000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 298\n",
      "timestep 125000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000444\n",
      "mean reward (100 episodes) 160.937837\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 439.610000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 301\n",
      "timestep 126000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000444\n",
      "mean reward (100 episodes) 160.075072\n",
      "max reward (100 episodes) 298.064122\n",
      "mean step (100 episodes) 434.970000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 304\n",
      "timestep 127000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000444\n",
      "mean reward (100 episodes) 162.013913\n",
      "max reward (100 episodes) 291.077152\n",
      "mean step (100 episodes) 442.880000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 308\n",
      "timestep 128000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000443\n",
      "mean reward (100 episodes) 160.376530\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 434.710000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 310\n",
      "timestep 129000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000443\n",
      "mean reward (100 episodes) 157.533149\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 442.750000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_130000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 313\n",
      "timestep 130000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000442\n",
      "mean reward (100 episodes) 156.789574\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 454.460000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 315\n",
      "timestep 131000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000442\n",
      "mean reward (100 episodes) 156.847921\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 469.730000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 319\n",
      "timestep 132000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000442\n",
      "mean reward (100 episodes) 155.201762\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 465.330000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 322\n",
      "timestep 133000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000441\n",
      "mean reward (100 episodes) 160.759826\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 467.830000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 325\n",
      "timestep 134000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000441\n",
      "mean reward (100 episodes) 160.602027\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 479.720000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 327\n",
      "timestep 135000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000441\n",
      "mean reward (100 episodes) 166.346860\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 488.250000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 330\n",
      "timestep 136000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000440\n",
      "mean reward (100 episodes) 172.289571\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 488.870000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 333\n",
      "timestep 137000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000440\n",
      "mean reward (100 episodes) 167.427797\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 499.800000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 335\n",
      "timestep 138000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000439\n",
      "mean reward (100 episodes) 171.310441\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 487.310000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 338\n",
      "timestep 139000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000439\n",
      "mean reward (100 episodes) 172.146388\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 495.670000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_140000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 340\n",
      "timestep 140000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000439\n",
      "mean reward (100 episodes) 172.605435\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 510.940000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 342\n",
      "timestep 141000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000438\n",
      "mean reward (100 episodes) 168.214818\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 511.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 345\n",
      "timestep 142000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000438\n",
      "mean reward (100 episodes) 165.220698\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 511.330000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 348\n",
      "timestep 143000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000437\n",
      "mean reward (100 episodes) 161.006368\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 519.360000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 351\n",
      "timestep 144000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000437\n",
      "mean reward (100 episodes) 161.659333\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 517.140000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 353\n",
      "timestep 145000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000437\n",
      "mean reward (100 episodes) 166.149178\n",
      "max reward (100 episodes) 291.864985\n",
      "mean step (100 episodes) 509.320000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 356\n",
      "timestep 146000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000436\n",
      "mean reward (100 episodes) 171.307157\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 510.850000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 358\n",
      "timestep 147000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000436\n",
      "mean reward (100 episodes) 170.398421\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 510.570000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 360\n",
      "timestep 148000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000436\n",
      "mean reward (100 episodes) 170.081162\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 510.350000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 362\n",
      "timestep 149000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000435\n",
      "mean reward (100 episodes) 172.216910\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 508.760000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_150000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 364\n",
      "timestep 150000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000435\n",
      "mean reward (100 episodes) 168.610325\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 514.980000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 367\n",
      "timestep 151000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000434\n",
      "mean reward (100 episodes) 172.198318\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 492.610000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 369\n",
      "timestep 152000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000434\n",
      "mean reward (100 episodes) 173.448447\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 490.690000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 372\n",
      "timestep 153000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000434\n",
      "mean reward (100 episodes) 172.342166\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 486.790000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 374\n",
      "timestep 154000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000433\n",
      "mean reward (100 episodes) 168.244334\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 474.940000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 378\n",
      "timestep 155000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000433\n",
      "mean reward (100 episodes) 170.058836\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 463.220000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 380\n",
      "timestep 156000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000433\n",
      "mean reward (100 episodes) 171.600331\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 459.640000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 382\n",
      "timestep 157000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000432\n",
      "mean reward (100 episodes) 177.031656\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 432.800000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 385\n",
      "timestep 158000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000432\n",
      "mean reward (100 episodes) 174.531530\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 433.530000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 387\n",
      "timestep 159000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000431\n",
      "mean reward (100 episodes) 170.587264\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 429.000000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_160000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 389\n",
      "timestep 160000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000431\n",
      "mean reward (100 episodes) 170.501597\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 433.580000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 393\n",
      "timestep 161000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000431\n",
      "mean reward (100 episodes) 169.528132\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 446.050000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 396\n",
      "timestep 162000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000430\n",
      "mean reward (100 episodes) 176.647528\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 440.690000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 398\n",
      "timestep 163000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000430\n",
      "mean reward (100 episodes) 176.804393\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 430.150000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 400\n",
      "timestep 164000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000430\n",
      "mean reward (100 episodes) 176.346022\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 424.680000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 404\n",
      "timestep 165000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000429\n",
      "mean reward (100 episodes) 174.764310\n",
      "max reward (100 episodes) 298.932126\n",
      "mean step (100 episodes) 424.120000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 407\n",
      "timestep 166000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000429\n",
      "mean reward (100 episodes) 170.450521\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 431.590000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 409\n",
      "timestep 167000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000428\n",
      "mean reward (100 episodes) 170.258779\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 450.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 411\n",
      "timestep 168000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000428\n",
      "mean reward (100 episodes) 169.047301\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 457.340000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 414\n",
      "timestep 169000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000428\n",
      "mean reward (100 episodes) 172.213553\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 453.120000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_170000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 416\n",
      "timestep 170000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000427\n",
      "mean reward (100 episodes) 178.769996\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 441.430000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 419\n",
      "timestep 171000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000427\n",
      "mean reward (100 episodes) 172.449130\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 457.520000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 421\n",
      "timestep 172000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000427\n",
      "mean reward (100 episodes) 170.715964\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 464.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 423\n",
      "timestep 173000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000426\n",
      "mean reward (100 episodes) 175.005381\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 472.440000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 425\n",
      "timestep 174000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000426\n",
      "mean reward (100 episodes) 169.568128\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 477.440000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 427\n",
      "timestep 175000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000426\n",
      "mean reward (100 episodes) 165.863340\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 477.330000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 429\n",
      "timestep 176000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000425\n",
      "mean reward (100 episodes) 166.933241\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 480.610000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 431\n",
      "timestep 177000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000425\n",
      "mean reward (100 episodes) 165.470127\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 493.380000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 433\n",
      "timestep 178000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000424\n",
      "mean reward (100 episodes) 163.091514\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 505.380000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 435\n",
      "timestep 179000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000424\n",
      "mean reward (100 episodes) 159.877801\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 525.670000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_180000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 437\n",
      "timestep 180000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000424\n",
      "mean reward (100 episodes) 159.707553\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 521.300000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 439\n",
      "timestep 181000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000423\n",
      "mean reward (100 episodes) 162.197021\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 525.590000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 441\n",
      "timestep 182000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000423\n",
      "mean reward (100 episodes) 159.831970\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 546.250000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 443\n",
      "timestep 183000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000423\n",
      "mean reward (100 episodes) 155.257068\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 561.200000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 445\n",
      "timestep 184000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000422\n",
      "mean reward (100 episodes) 154.604197\n",
      "max reward (100 episodes) 288.325597\n",
      "mean step (100 episodes) 578.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 447\n",
      "timestep 185000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000422\n",
      "mean reward (100 episodes) 145.664876\n",
      "max reward (100 episodes) 286.022229\n",
      "mean step (100 episodes) 604.060000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 449\n",
      "timestep 186000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000422\n",
      "mean reward (100 episodes) 144.649994\n",
      "max reward (100 episodes) 286.022229\n",
      "mean step (100 episodes) 615.540000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 451\n",
      "timestep 187000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000421\n",
      "mean reward (100 episodes) 142.659787\n",
      "max reward (100 episodes) 286.022229\n",
      "mean step (100 episodes) 607.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 453\n",
      "timestep 188000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000421\n",
      "mean reward (100 episodes) 145.828043\n",
      "max reward (100 episodes) 286.022229\n",
      "mean step (100 episodes) 609.220000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 455\n",
      "timestep 189000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000421\n",
      "mean reward (100 episodes) 147.991664\n",
      "max reward (100 episodes) 287.779958\n",
      "mean step (100 episodes) 605.430000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_190000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 457\n",
      "timestep 190000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000420\n",
      "mean reward (100 episodes) 150.196855\n",
      "max reward (100 episodes) 287.779958\n",
      "mean step (100 episodes) 610.430000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 459\n",
      "timestep 191000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000420\n",
      "mean reward (100 episodes) 149.523237\n",
      "max reward (100 episodes) 287.779958\n",
      "mean step (100 episodes) 612.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 461\n",
      "timestep 192000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000419\n",
      "mean reward (100 episodes) 149.664631\n",
      "max reward (100 episodes) 287.779958\n",
      "mean step (100 episodes) 615.730000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 465\n",
      "timestep 193000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000419\n",
      "mean reward (100 episodes) 151.511910\n",
      "max reward (100 episodes) 292.091259\n",
      "mean step (100 episodes) 604.310000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 467\n",
      "timestep 194000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000419\n",
      "mean reward (100 episodes) 160.128660\n",
      "max reward (100 episodes) 292.091259\n",
      "mean step (100 episodes) 607.560000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 469\n",
      "timestep 195000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000418\n",
      "mean reward (100 episodes) 164.463925\n",
      "max reward (100 episodes) 292.091259\n",
      "mean step (100 episodes) 603.640000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 471\n",
      "timestep 196000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000418\n",
      "mean reward (100 episodes) 162.545953\n",
      "max reward (100 episodes) 292.091259\n",
      "mean step (100 episodes) 617.490000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 474\n",
      "timestep 197000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000418\n",
      "mean reward (100 episodes) 166.036027\n",
      "max reward (100 episodes) 292.091259\n",
      "mean step (100 episodes) 603.720000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 476\n",
      "timestep 198000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000417\n",
      "mean reward (100 episodes) 170.044526\n",
      "max reward (100 episodes) 292.091259\n",
      "mean step (100 episodes) 596.330000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 478\n",
      "timestep 199000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000417\n",
      "mean reward (100 episodes) 175.954810\n",
      "max reward (100 episodes) 292.091259\n",
      "mean step (100 episodes) 582.480000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_200000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 480\n",
      "timestep 200000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000417\n",
      "mean reward (100 episodes) 178.799871\n",
      "max reward (100 episodes) 292.091259\n",
      "mean step (100 episodes) 564.990000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 482\n",
      "timestep 201000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000416\n",
      "mean reward (100 episodes) 182.880233\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 545.270000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 484\n",
      "timestep 202000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000416\n",
      "mean reward (100 episodes) 187.468067\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 538.700000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 486\n",
      "timestep 203000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000416\n",
      "mean reward (100 episodes) 195.502016\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 528.480000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 488\n",
      "timestep 204000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000415\n",
      "mean reward (100 episodes) 193.666689\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 533.650000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 490\n",
      "timestep 205000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000415\n",
      "mean reward (100 episodes) 205.323855\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 514.620000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 492\n",
      "timestep 206000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000415\n",
      "mean reward (100 episodes) 209.575224\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 498.020000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 494\n",
      "timestep 207000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000414\n",
      "mean reward (100 episodes) 211.309590\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 510.530000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 498\n",
      "timestep 208000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000414\n",
      "mean reward (100 episodes) 211.885659\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 506.050000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 500\n",
      "timestep 209000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000414\n",
      "mean reward (100 episodes) 213.172162\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 502.210000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_210000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 502\n",
      "timestep 210000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000413\n",
      "mean reward (100 episodes) 212.123765\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 496.720000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 505\n",
      "timestep 211000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000413\n",
      "mean reward (100 episodes) 218.604245\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 474.980000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 507\n",
      "timestep 212000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000413\n",
      "mean reward (100 episodes) 219.166343\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 468.410000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 509\n",
      "timestep 213000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000412\n",
      "mean reward (100 episodes) 216.907492\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 474.170000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 511\n",
      "timestep 214000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000412\n",
      "mean reward (100 episodes) 217.365747\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 483.080000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 513\n",
      "timestep 215000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000412\n",
      "mean reward (100 episodes) 218.218444\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 485.490000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 515\n",
      "timestep 216000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000411\n",
      "mean reward (100 episodes) 220.172951\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 475.470000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 518\n",
      "timestep 217000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000411\n",
      "mean reward (100 episodes) 216.513956\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 495.530000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 520\n",
      "timestep 218000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000411\n",
      "mean reward (100 episodes) 214.290979\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 505.250000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 523\n",
      "timestep 219000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000410\n",
      "mean reward (100 episodes) 213.679094\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 503.160000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_220000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 525\n",
      "timestep 220000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000410\n",
      "mean reward (100 episodes) 212.924635\n",
      "max reward (100 episodes) 300.683931\n",
      "mean step (100 episodes) 516.570000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 527\n",
      "timestep 221000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000410\n",
      "mean reward (100 episodes) 212.655638\n",
      "max reward (100 episodes) 293.221784\n",
      "mean step (100 episodes) 519.910000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 529\n",
      "timestep 222000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000409\n",
      "mean reward (100 episodes) 213.757777\n",
      "max reward (100 episodes) 293.221784\n",
      "mean step (100 episodes) 510.660000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 531\n",
      "timestep 223000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000409\n",
      "mean reward (100 episodes) 212.253079\n",
      "max reward (100 episodes) 293.221784\n",
      "mean step (100 episodes) 513.090000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 534\n",
      "timestep 224000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000408\n",
      "mean reward (100 episodes) 214.510619\n",
      "max reward (100 episodes) 293.221784\n",
      "mean step (100 episodes) 501.940000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 537\n",
      "timestep 225000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000408\n",
      "mean reward (100 episodes) 216.117315\n",
      "max reward (100 episodes) 298.848046\n",
      "mean step (100 episodes) 498.910000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 539\n",
      "timestep 226000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000408\n",
      "mean reward (100 episodes) 215.593353\n",
      "max reward (100 episodes) 298.848046\n",
      "mean step (100 episodes) 504.160000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 542\n",
      "timestep 227000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000407\n",
      "mean reward (100 episodes) 219.524374\n",
      "max reward (100 episodes) 298.848046\n",
      "mean step (100 episodes) 480.670000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 545\n",
      "timestep 228000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000407\n",
      "mean reward (100 episodes) 219.525660\n",
      "max reward (100 episodes) 298.848046\n",
      "mean step (100 episodes) 481.210000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 547\n",
      "timestep 229000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000407\n",
      "mean reward (100 episodes) 216.748545\n",
      "max reward (100 episodes) 298.848046\n",
      "mean step (100 episodes) 495.730000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_230000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 549\n",
      "timestep 230000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000407\n",
      "mean reward (100 episodes) 217.574367\n",
      "max reward (100 episodes) 298.848046\n",
      "mean step (100 episodes) 489.220000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 551\n",
      "timestep 231000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000406\n",
      "mean reward (100 episodes) 213.568056\n",
      "max reward (100 episodes) 298.848046\n",
      "mean step (100 episodes) 522.540000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 554\n",
      "timestep 232000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000406\n",
      "mean reward (100 episodes) 212.108584\n",
      "max reward (100 episodes) 298.848046\n",
      "mean step (100 episodes) 542.580000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 556\n",
      "timestep 233000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000406\n",
      "mean reward (100 episodes) 214.167235\n",
      "max reward (100 episodes) 298.848046\n",
      "mean step (100 episodes) 537.930000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 560\n",
      "timestep 234000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000405\n",
      "mean reward (100 episodes) 213.703160\n",
      "max reward (100 episodes) 298.848046\n",
      "mean step (100 episodes) 539.380000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 562\n",
      "timestep 235000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000405\n",
      "mean reward (100 episodes) 209.998461\n",
      "max reward (100 episodes) 298.848046\n",
      "mean step (100 episodes) 555.430000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 564\n",
      "timestep 236000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000405\n",
      "mean reward (100 episodes) 211.901616\n",
      "max reward (100 episodes) 298.848046\n",
      "mean step (100 episodes) 550.510000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 566\n",
      "timestep 237000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000404\n",
      "mean reward (100 episodes) 215.614060\n",
      "max reward (100 episodes) 298.848046\n",
      "mean step (100 episodes) 534.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 568\n",
      "timestep 238000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000404\n",
      "mean reward (100 episodes) 219.748122\n",
      "max reward (100 episodes) 307.153258\n",
      "mean step (100 episodes) 519.080000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 571\n",
      "timestep 239000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000404\n",
      "mean reward (100 episodes) 222.925079\n",
      "max reward (100 episodes) 307.153258\n",
      "mean step (100 episodes) 507.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_240000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 574\n",
      "timestep 240000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000403\n",
      "mean reward (100 episodes) 223.652048\n",
      "max reward (100 episodes) 307.153258\n",
      "mean step (100 episodes) 499.490000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 576\n",
      "timestep 241000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000403\n",
      "mean reward (100 episodes) 218.800040\n",
      "max reward (100 episodes) 307.153258\n",
      "mean step (100 episodes) 530.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 578\n",
      "timestep 242000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000403\n",
      "mean reward (100 episodes) 216.280471\n",
      "max reward (100 episodes) 307.153258\n",
      "mean step (100 episodes) 547.400000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 581\n",
      "timestep 243000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000402\n",
      "mean reward (100 episodes) 217.817502\n",
      "max reward (100 episodes) 311.234522\n",
      "mean step (100 episodes) 551.980000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 585\n",
      "timestep 244000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000402\n",
      "mean reward (100 episodes) 219.375073\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 547.020000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 587\n",
      "timestep 245000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000402\n",
      "mean reward (100 episodes) 221.223799\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 540.500000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 590\n",
      "timestep 246000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000401\n",
      "mean reward (100 episodes) 224.516463\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 526.570000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 593\n",
      "timestep 247000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000401\n",
      "mean reward (100 episodes) 226.614746\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 515.050000\n",
      "max step (100 episodes) 1000.000000\n",
      "Saved trajectories to save path: /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/trajs_0.pkl!\n",
      "------------------------------------------------\n",
      "episodes 597\n",
      "timestep 248000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000401\n",
      "mean reward (100 episodes) 225.957237\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 520.160000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 599\n",
      "timestep 249000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000400\n",
      "mean reward (100 episodes) 227.472694\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 521.340000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_250000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 601\n",
      "timestep 250000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000400\n",
      "mean reward (100 episodes) 228.397259\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 531.460000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 603\n",
      "timestep 251000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000400\n",
      "mean reward (100 episodes) 230.266822\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 503.080000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 606\n",
      "timestep 252000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000399\n",
      "mean reward (100 episodes) 232.710201\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 484.270000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 608\n",
      "timestep 253000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000399\n",
      "mean reward (100 episodes) 229.697394\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 491.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 610\n",
      "timestep 254000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000399\n",
      "mean reward (100 episodes) 227.498140\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 472.550000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 614\n",
      "timestep 255000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000398\n",
      "mean reward (100 episodes) 230.986639\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 447.990000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 617\n",
      "timestep 256000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000398\n",
      "mean reward (100 episodes) 231.182168\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 448.240000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 620\n",
      "timestep 257000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000398\n",
      "mean reward (100 episodes) 230.643270\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 441.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 625\n",
      "timestep 258000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000397\n",
      "mean reward (100 episodes) 225.800982\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 437.160000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 628\n",
      "timestep 259000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000397\n",
      "mean reward (100 episodes) 220.230367\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 430.560000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_260000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 634\n",
      "timestep 260000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000397\n",
      "mean reward (100 episodes) 216.756434\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 425.290000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 639\n",
      "timestep 261000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000397\n",
      "mean reward (100 episodes) 212.818185\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 391.690000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 644\n",
      "timestep 262000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000396\n",
      "mean reward (100 episodes) 217.025477\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 366.800000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 647\n",
      "timestep 263000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000396\n",
      "mean reward (100 episodes) 213.689115\n",
      "max reward (100 episodes) 313.197819\n",
      "mean step (100 episodes) 358.560000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 649\n",
      "timestep 264000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000396\n",
      "mean reward (100 episodes) 214.364832\n",
      "max reward (100 episodes) 307.764627\n",
      "mean step (100 episodes) 354.160000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 652\n",
      "timestep 265000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000395\n",
      "mean reward (100 episodes) 209.782940\n",
      "max reward (100 episodes) 306.228669\n",
      "mean step (100 episodes) 351.560000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 656\n",
      "timestep 266000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000395\n",
      "mean reward (100 episodes) 203.166157\n",
      "max reward (100 episodes) 306.228669\n",
      "mean step (100 episodes) 356.550000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 658\n",
      "timestep 267000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000395\n",
      "mean reward (100 episodes) 200.945237\n",
      "max reward (100 episodes) 303.758154\n",
      "mean step (100 episodes) 365.740000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 663\n",
      "timestep 268000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000394\n",
      "mean reward (100 episodes) 198.699968\n",
      "max reward (100 episodes) 303.758154\n",
      "mean step (100 episodes) 356.150000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 665\n",
      "timestep 269000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000394\n",
      "mean reward (100 episodes) 200.538393\n",
      "max reward (100 episodes) 303.758154\n",
      "mean step (100 episodes) 344.490000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_270000.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 669\n",
      "timestep 270000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000394\n",
      "mean reward (100 episodes) 196.107384\n",
      "max reward (100 episodes) 303.758154\n",
      "mean step (100 episodes) 366.790000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 673\n",
      "timestep 271000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000393\n",
      "mean reward (100 episodes) 198.152536\n",
      "max reward (100 episodes) 303.758154\n",
      "mean step (100 episodes) 372.790000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 675\n",
      "timestep 272000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000393\n",
      "mean reward (100 episodes) 200.116273\n",
      "max reward (100 episodes) 305.297701\n",
      "mean step (100 episodes) 366.460000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 677\n",
      "timestep 273000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000393\n",
      "mean reward (100 episodes) 202.925249\n",
      "max reward (100 episodes) 308.101673\n",
      "mean step (100 episodes) 363.710000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 679\n",
      "timestep 274000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000392\n",
      "mean reward (100 episodes) 204.776428\n",
      "max reward (100 episodes) 308.101673\n",
      "mean step (100 episodes) 359.370000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 681\n",
      "timestep 275000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000392\n",
      "mean reward (100 episodes) 202.589818\n",
      "max reward (100 episodes) 308.101673\n",
      "mean step (100 episodes) 376.460000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 684\n",
      "timestep 276000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000392\n",
      "mean reward (100 episodes) 202.942153\n",
      "max reward (100 episodes) 314.472475\n",
      "mean step (100 episodes) 368.500000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 687\n",
      "timestep 277000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000392\n",
      "mean reward (100 episodes) 205.130607\n",
      "max reward (100 episodes) 314.472475\n",
      "mean step (100 episodes) 373.960000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 689\n",
      "timestep 278000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000391\n",
      "mean reward (100 episodes) 209.657749\n",
      "max reward (100 episodes) 314.472475\n",
      "mean step (100 episodes) 380.880000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 691\n",
      "timestep 279000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000391\n",
      "mean reward (100 episodes) 214.975130\n",
      "max reward (100 episodes) 314.472475\n",
      "mean step (100 episodes) 392.110000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_280000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 693\n",
      "timestep 280000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000391\n",
      "mean reward (100 episodes) 215.863899\n",
      "max reward (100 episodes) 314.472475\n",
      "mean step (100 episodes) 410.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 697\n",
      "timestep 281000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000390\n",
      "mean reward (100 episodes) 225.611731\n",
      "max reward (100 episodes) 314.472475\n",
      "mean step (100 episodes) 406.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 699\n",
      "timestep 282000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000390\n",
      "mean reward (100 episodes) 225.613634\n",
      "max reward (100 episodes) 314.472475\n",
      "mean step (100 episodes) 405.110000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 701\n",
      "timestep 283000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000390\n",
      "mean reward (100 episodes) 230.818792\n",
      "max reward (100 episodes) 314.472475\n",
      "mean step (100 episodes) 396.470000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 703\n",
      "timestep 284000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000389\n",
      "mean reward (100 episodes) 231.165695\n",
      "max reward (100 episodes) 314.472475\n",
      "mean step (100 episodes) 392.570000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 706\n",
      "timestep 285000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000389\n",
      "mean reward (100 episodes) 236.052289\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 391.750000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 708\n",
      "timestep 286000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000389\n",
      "mean reward (100 episodes) 240.203988\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 402.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 711\n",
      "timestep 287000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000389\n",
      "mean reward (100 episodes) 240.568688\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 412.640000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 713\n",
      "timestep 288000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000388\n",
      "mean reward (100 episodes) 244.934383\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 406.570000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 715\n",
      "timestep 289000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000388\n",
      "mean reward (100 episodes) 245.476419\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 398.310000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_290000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 717\n",
      "timestep 290000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000388\n",
      "mean reward (100 episodes) 246.505737\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 366.100000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 719\n",
      "timestep 291000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000387\n",
      "mean reward (100 episodes) 244.761472\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 372.770000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 721\n",
      "timestep 292000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000387\n",
      "mean reward (100 episodes) 241.661718\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 381.210000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 723\n",
      "timestep 293000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000387\n",
      "mean reward (100 episodes) 242.373398\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 371.960000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 725\n",
      "timestep 294000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000386\n",
      "mean reward (100 episodes) 243.554926\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 384.780000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 728\n",
      "timestep 295000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000386\n",
      "mean reward (100 episodes) 244.726250\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 374.710000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 730\n",
      "timestep 296000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000386\n",
      "mean reward (100 episodes) 240.868815\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 409.160000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 732\n",
      "timestep 297000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000386\n",
      "mean reward (100 episodes) 230.742663\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 412.440000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 735\n",
      "timestep 298000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000385\n",
      "mean reward (100 episodes) 225.490136\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 415.100000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 737\n",
      "timestep 299000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000385\n",
      "mean reward (100 episodes) 222.660162\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 439.980000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_300000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 740\n",
      "timestep 300000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000385\n",
      "mean reward (100 episodes) 224.956154\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 444.020000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 744\n",
      "timestep 301000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000384\n",
      "mean reward (100 episodes) 224.802196\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 446.490000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 748\n",
      "timestep 302000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000384\n",
      "mean reward (100 episodes) 224.307446\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 455.270000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 751\n",
      "timestep 303000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000384\n",
      "mean reward (100 episodes) 224.438574\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 461.850000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 753\n",
      "timestep 304000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000383\n",
      "mean reward (100 episodes) 220.355636\n",
      "max reward (100 episodes) 314.754207\n",
      "mean step (100 episodes) 460.190000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 756\n",
      "timestep 305000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000383\n",
      "mean reward (100 episodes) 218.879721\n",
      "max reward (100 episodes) 312.670878\n",
      "mean step (100 episodes) 465.960000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 759\n",
      "timestep 306000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000383\n",
      "mean reward (100 episodes) 221.499187\n",
      "max reward (100 episodes) 312.670878\n",
      "mean step (100 episodes) 471.250000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 762\n",
      "timestep 307000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000383\n",
      "mean reward (100 episodes) 223.052540\n",
      "max reward (100 episodes) 312.670878\n",
      "mean step (100 episodes) 452.060000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 764\n",
      "timestep 308000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000382\n",
      "mean reward (100 episodes) 223.768967\n",
      "max reward (100 episodes) 312.670878\n",
      "mean step (100 episodes) 453.970000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 768\n",
      "timestep 309000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000382\n",
      "mean reward (100 episodes) 217.159627\n",
      "max reward (100 episodes) 312.670878\n",
      "mean step (100 episodes) 492.860000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_310000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 772\n",
      "timestep 310000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000382\n",
      "mean reward (100 episodes) 220.953039\n",
      "max reward (100 episodes) 312.670878\n",
      "mean step (100 episodes) 485.460000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 775\n",
      "timestep 311000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000381\n",
      "mean reward (100 episodes) 223.342660\n",
      "max reward (100 episodes) 312.670878\n",
      "mean step (100 episodes) 475.100000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 777\n",
      "timestep 312000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000381\n",
      "mean reward (100 episodes) 224.661321\n",
      "max reward (100 episodes) 312.670878\n",
      "mean step (100 episodes) 473.400000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 780\n",
      "timestep 313000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000381\n",
      "mean reward (100 episodes) 221.698988\n",
      "max reward (100 episodes) 312.670878\n",
      "mean step (100 episodes) 498.100000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 784\n",
      "timestep 314000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000381\n",
      "mean reward (100 episodes) 224.681563\n",
      "max reward (100 episodes) 312.670878\n",
      "mean step (100 episodes) 482.570000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 787\n",
      "timestep 315000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000380\n",
      "mean reward (100 episodes) 227.341491\n",
      "max reward (100 episodes) 312.670878\n",
      "mean step (100 episodes) 474.510000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 791\n",
      "timestep 316000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000380\n",
      "mean reward (100 episodes) 230.603039\n",
      "max reward (100 episodes) 312.670878\n",
      "mean step (100 episodes) 452.190000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 793\n",
      "timestep 317000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000380\n",
      "mean reward (100 episodes) 237.133629\n",
      "max reward (100 episodes) 312.670878\n",
      "mean step (100 episodes) 463.800000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 795\n",
      "timestep 318000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000379\n",
      "mean reward (100 episodes) 241.424177\n",
      "max reward (100 episodes) 301.472419\n",
      "mean step (100 episodes) 475.250000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 798\n",
      "timestep 319000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000379\n",
      "mean reward (100 episodes) 246.196965\n",
      "max reward (100 episodes) 301.472419\n",
      "mean step (100 episodes) 443.180000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_320000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 801\n",
      "timestep 320000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000379\n",
      "mean reward (100 episodes) 241.090460\n",
      "max reward (100 episodes) 301.472419\n",
      "mean step (100 episodes) 455.820000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 805\n",
      "timestep 321000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000379\n",
      "mean reward (100 episodes) 240.304434\n",
      "max reward (100 episodes) 301.472419\n",
      "mean step (100 episodes) 464.860000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 809\n",
      "timestep 322000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000378\n",
      "mean reward (100 episodes) 239.671083\n",
      "max reward (100 episodes) 301.472419\n",
      "mean step (100 episodes) 459.920000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 811\n",
      "timestep 323000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000378\n",
      "mean reward (100 episodes) 238.063246\n",
      "max reward (100 episodes) 301.472419\n",
      "mean step (100 episodes) 469.920000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 813\n",
      "timestep 324000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000378\n",
      "mean reward (100 episodes) 241.931979\n",
      "max reward (100 episodes) 301.472419\n",
      "mean step (100 episodes) 473.640000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 816\n",
      "timestep 325000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000377\n",
      "mean reward (100 episodes) 243.755947\n",
      "max reward (100 episodes) 304.869117\n",
      "mean step (100 episodes) 468.510000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 819\n",
      "timestep 326000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000377\n",
      "mean reward (100 episodes) 243.162765\n",
      "max reward (100 episodes) 309.022119\n",
      "mean step (100 episodes) 452.100000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 821\n",
      "timestep 327000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000377\n",
      "mean reward (100 episodes) 242.447661\n",
      "max reward (100 episodes) 309.022119\n",
      "mean step (100 episodes) 467.990000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 826\n",
      "timestep 328000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000377\n",
      "mean reward (100 episodes) 242.883779\n",
      "max reward (100 episodes) 309.022119\n",
      "mean step (100 episodes) 464.230000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 831\n",
      "timestep 329000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000376\n",
      "mean reward (100 episodes) 249.389415\n",
      "max reward (100 episodes) 309.022119\n",
      "mean step (100 episodes) 422.870000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_330000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 834\n",
      "timestep 330000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000376\n",
      "mean reward (100 episodes) 248.014801\n",
      "max reward (100 episodes) 309.022119\n",
      "mean step (100 episodes) 432.330000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 837\n",
      "timestep 331000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000376\n",
      "mean reward (100 episodes) 248.901147\n",
      "max reward (100 episodes) 309.022119\n",
      "mean step (100 episodes) 419.510000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 842\n",
      "timestep 332000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000375\n",
      "mean reward (100 episodes) 250.273531\n",
      "max reward (100 episodes) 309.022119\n",
      "mean step (100 episodes) 409.080000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 845\n",
      "timestep 333000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000375\n",
      "mean reward (100 episodes) 248.009825\n",
      "max reward (100 episodes) 309.022119\n",
      "mean step (100 episodes) 422.280000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 849\n",
      "timestep 334000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000375\n",
      "mean reward (100 episodes) 248.831136\n",
      "max reward (100 episodes) 309.022119\n",
      "mean step (100 episodes) 422.350000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 853\n",
      "timestep 335000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000375\n",
      "mean reward (100 episodes) 246.024480\n",
      "max reward (100 episodes) 309.022119\n",
      "mean step (100 episodes) 431.760000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 856\n",
      "timestep 336000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000374\n",
      "mean reward (100 episodes) 248.328884\n",
      "max reward (100 episodes) 309.022119\n",
      "mean step (100 episodes) 415.140000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 860\n",
      "timestep 337000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000374\n",
      "mean reward (100 episodes) 251.989542\n",
      "max reward (100 episodes) 309.022119\n",
      "mean step (100 episodes) 390.880000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 865\n",
      "timestep 338000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000374\n",
      "mean reward (100 episodes) 251.573229\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 376.250000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 869\n",
      "timestep 339000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000373\n",
      "mean reward (100 episodes) 250.383340\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 382.040000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_340000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 873\n",
      "timestep 340000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000373\n",
      "mean reward (100 episodes) 257.563762\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 341.810000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 876\n",
      "timestep 341000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000373\n",
      "mean reward (100 episodes) 258.275844\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 329.180000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 880\n",
      "timestep 342000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000373\n",
      "mean reward (100 episodes) 260.235077\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 324.980000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 883\n",
      "timestep 343000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000372\n",
      "mean reward (100 episodes) 259.401234\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 314.520000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 886\n",
      "timestep 344000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000372\n",
      "mean reward (100 episodes) 257.974832\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 329.410000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 889\n",
      "timestep 345000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000372\n",
      "mean reward (100 episodes) 254.680212\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 336.630000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 891\n",
      "timestep 346000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000371\n",
      "mean reward (100 episodes) 252.201247\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 354.720000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 895\n",
      "timestep 347000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000371\n",
      "mean reward (100 episodes) 253.352236\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 338.350000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 899\n",
      "timestep 348000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000371\n",
      "mean reward (100 episodes) 253.228499\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 338.300000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 903\n",
      "timestep 349000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000371\n",
      "mean reward (100 episodes) 252.859249\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 348.170000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_350000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 907\n",
      "timestep 350000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000370\n",
      "mean reward (100 episodes) 252.982623\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 346.380000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 911\n",
      "timestep 351000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000370\n",
      "mean reward (100 episodes) 252.266990\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 352.470000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 914\n",
      "timestep 352000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000370\n",
      "mean reward (100 episodes) 252.476196\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 353.810000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 918\n",
      "timestep 353000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000370\n",
      "mean reward (100 episodes) 257.883550\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 312.970000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 922\n",
      "timestep 354000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000369\n",
      "mean reward (100 episodes) 247.174777\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 334.680000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 926\n",
      "timestep 355000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000369\n",
      "mean reward (100 episodes) 248.740396\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 325.440000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 929\n",
      "timestep 356000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000369\n",
      "mean reward (100 episodes) 247.302827\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 333.200000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 932\n",
      "timestep 357000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000368\n",
      "mean reward (100 episodes) 240.620018\n",
      "max reward (100 episodes) 320.122245\n",
      "mean step (100 episodes) 350.850000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 935\n",
      "timestep 358000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000368\n",
      "mean reward (100 episodes) 242.516751\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 350.810000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 939\n",
      "timestep 359000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000368\n",
      "mean reward (100 episodes) 243.378623\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 342.330000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_360000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 943\n",
      "timestep 360000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000368\n",
      "mean reward (100 episodes) 243.440536\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 344.710000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 945\n",
      "timestep 361000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000367\n",
      "mean reward (100 episodes) 240.587580\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 344.500000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 949\n",
      "timestep 362000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000367\n",
      "mean reward (100 episodes) 237.977625\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 350.920000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 951\n",
      "timestep 363000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000367\n",
      "mean reward (100 episodes) 235.855371\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 342.510000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 954\n",
      "timestep 364000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000367\n",
      "mean reward (100 episodes) 237.747154\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 327.720000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 956\n",
      "timestep 365000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000366\n",
      "mean reward (100 episodes) 235.582697\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 329.180000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 959\n",
      "timestep 366000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000366\n",
      "mean reward (100 episodes) 238.269727\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 305.170000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 963\n",
      "timestep 367000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000366\n",
      "mean reward (100 episodes) 237.857988\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 305.220000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 968\n",
      "timestep 368000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000365\n",
      "mean reward (100 episodes) 235.984041\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 314.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 972\n",
      "timestep 369000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000365\n",
      "mean reward (100 episodes) 236.027358\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 313.910000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_370000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 975\n",
      "timestep 370000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000365\n",
      "mean reward (100 episodes) 237.397144\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 306.490000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 979\n",
      "timestep 371000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000365\n",
      "mean reward (100 episodes) 236.209079\n",
      "max reward (100 episodes) 317.537414\n",
      "mean step (100 episodes) 316.410000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 983\n",
      "timestep 372000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000364\n",
      "mean reward (100 episodes) 232.897871\n",
      "max reward (100 episodes) 317.438570\n",
      "mean step (100 episodes) 315.450000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 987\n",
      "timestep 373000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000364\n",
      "mean reward (100 episodes) 232.160108\n",
      "max reward (100 episodes) 317.438570\n",
      "mean step (100 episodes) 327.340000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 989\n",
      "timestep 374000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000364\n",
      "mean reward (100 episodes) 242.911047\n",
      "max reward (100 episodes) 317.438570\n",
      "mean step (100 episodes) 305.820000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 992\n",
      "timestep 375000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000364\n",
      "mean reward (100 episodes) 243.403229\n",
      "max reward (100 episodes) 317.438570\n",
      "mean step (100 episodes) 305.130000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 996\n",
      "timestep 376000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000363\n",
      "mean reward (100 episodes) 244.131437\n",
      "max reward (100 episodes) 317.438570\n",
      "mean step (100 episodes) 296.780000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1000\n",
      "timestep 377000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000363\n",
      "mean reward (100 episodes) 250.413740\n",
      "max reward (100 episodes) 313.394286\n",
      "mean step (100 episodes) 282.300000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1002\n",
      "timestep 378000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000363\n",
      "mean reward (100 episodes) 246.947381\n",
      "max reward (100 episodes) 313.394286\n",
      "mean step (100 episodes) 308.750000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1006\n",
      "timestep 379000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000363\n",
      "mean reward (100 episodes) 246.504590\n",
      "max reward (100 episodes) 313.394286\n",
      "mean step (100 episodes) 309.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_380000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1009\n",
      "timestep 380000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000362\n",
      "mean reward (100 episodes) 243.204891\n",
      "max reward (100 episodes) 314.872561\n",
      "mean step (100 episodes) 331.110000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1011\n",
      "timestep 381000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000362\n",
      "mean reward (100 episodes) 246.268165\n",
      "max reward (100 episodes) 314.872561\n",
      "mean step (100 episodes) 329.940000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1014\n",
      "timestep 382000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000362\n",
      "mean reward (100 episodes) 247.277859\n",
      "max reward (100 episodes) 314.872561\n",
      "mean step (100 episodes) 322.690000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1018\n",
      "timestep 383000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000362\n",
      "mean reward (100 episodes) 251.613098\n",
      "max reward (100 episodes) 314.872561\n",
      "mean step (100 episodes) 333.690000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1023\n",
      "timestep 384000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000361\n",
      "mean reward (100 episodes) 251.155995\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 337.070000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1025\n",
      "timestep 385000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000361\n",
      "mean reward (100 episodes) 255.871786\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 329.180000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1029\n",
      "timestep 386000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000361\n",
      "mean reward (100 episodes) 251.060885\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 327.480000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1032\n",
      "timestep 387000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000360\n",
      "mean reward (100 episodes) 244.891140\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 336.720000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1035\n",
      "timestep 388000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000360\n",
      "mean reward (100 episodes) 245.695463\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 334.610000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1040\n",
      "timestep 389000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000360\n",
      "mean reward (100 episodes) 247.115632\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 327.400000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_390000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1043\n",
      "timestep 390000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000360\n",
      "mean reward (100 episodes) 245.406131\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 343.300000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1047\n",
      "timestep 391000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000359\n",
      "mean reward (100 episodes) 245.042337\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 338.460000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1049\n",
      "timestep 392000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000359\n",
      "mean reward (100 episodes) 245.428983\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 346.200000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1052\n",
      "timestep 393000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000359\n",
      "mean reward (100 episodes) 247.073194\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 339.180000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1055\n",
      "timestep 394000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000359\n",
      "mean reward (100 episodes) 237.346070\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 337.640000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1057\n",
      "timestep 395000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000358\n",
      "mean reward (100 episodes) 236.754865\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 347.440000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1059\n",
      "timestep 396000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000358\n",
      "mean reward (100 episodes) 237.297751\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 347.070000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1063\n",
      "timestep 397000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000358\n",
      "mean reward (100 episodes) 237.190378\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 346.440000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1065\n",
      "timestep 398000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000358\n",
      "mean reward (100 episodes) 236.601188\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 324.190000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1068\n",
      "timestep 399000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000357\n",
      "mean reward (100 episodes) 235.818560\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 333.480000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_400000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1072\n",
      "timestep 400000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000357\n",
      "mean reward (100 episodes) 236.617862\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 329.090000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1074\n",
      "timestep 401000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000357\n",
      "mean reward (100 episodes) 235.614075\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 341.500000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1078\n",
      "timestep 402000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000357\n",
      "mean reward (100 episodes) 233.445613\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 360.920000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1080\n",
      "timestep 403000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000356\n",
      "mean reward (100 episodes) 233.822910\n",
      "max reward (100 episodes) 327.592069\n",
      "mean step (100 episodes) 351.340000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1084\n",
      "timestep 404000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000356\n",
      "mean reward (100 episodes) 233.679652\n",
      "max reward (100 episodes) 316.380722\n",
      "mean step (100 episodes) 348.810000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1088\n",
      "timestep 405000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000356\n",
      "mean reward (100 episodes) 227.172309\n",
      "max reward (100 episodes) 316.380722\n",
      "mean step (100 episodes) 363.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1090\n",
      "timestep 406000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000356\n",
      "mean reward (100 episodes) 231.248996\n",
      "max reward (100 episodes) 316.380722\n",
      "mean step (100 episodes) 373.120000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1093\n",
      "timestep 407000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000355\n",
      "mean reward (100 episodes) 235.910322\n",
      "max reward (100 episodes) 316.380722\n",
      "mean step (100 episodes) 378.980000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1096\n",
      "timestep 408000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000355\n",
      "mean reward (100 episodes) 236.976214\n",
      "max reward (100 episodes) 316.380722\n",
      "mean step (100 episodes) 374.280000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1099\n",
      "timestep 409000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000355\n",
      "mean reward (100 episodes) 234.837141\n",
      "max reward (100 episodes) 316.380722\n",
      "mean step (100 episodes) 380.140000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_410000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1102\n",
      "timestep 410000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000355\n",
      "mean reward (100 episodes) 237.234527\n",
      "max reward (100 episodes) 316.380722\n",
      "mean step (100 episodes) 363.990000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1106\n",
      "timestep 411000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000354\n",
      "mean reward (100 episodes) 237.184358\n",
      "max reward (100 episodes) 316.380722\n",
      "mean step (100 episodes) 368.920000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1108\n",
      "timestep 412000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000354\n",
      "mean reward (100 episodes) 238.297782\n",
      "max reward (100 episodes) 316.380722\n",
      "mean step (100 episodes) 369.640000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1111\n",
      "timestep 413000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000354\n",
      "mean reward (100 episodes) 233.553812\n",
      "max reward (100 episodes) 310.552167\n",
      "mean step (100 episodes) 390.410000\n",
      "max step (100 episodes) 1000.000000\n",
      "Saved trajectories to save path: /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/trajs_1.pkl!\n",
      "------------------------------------------------\n",
      "episodes 1114\n",
      "timestep 414000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000354\n",
      "mean reward (100 episodes) 241.309231\n",
      "max reward (100 episodes) 310.552167\n",
      "mean step (100 episodes) 417.690000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1116\n",
      "timestep 415000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000353\n",
      "mean reward (100 episodes) 239.762829\n",
      "max reward (100 episodes) 310.552167\n",
      "mean step (100 episodes) 407.700000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1119\n",
      "timestep 416000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000353\n",
      "mean reward (100 episodes) 237.226615\n",
      "max reward (100 episodes) 310.552167\n",
      "mean step (100 episodes) 422.700000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1122\n",
      "timestep 417000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000353\n",
      "mean reward (100 episodes) 236.389870\n",
      "max reward (100 episodes) 310.552167\n",
      "mean step (100 episodes) 428.650000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1125\n",
      "timestep 418000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000353\n",
      "mean reward (100 episodes) 239.129945\n",
      "max reward (100 episodes) 310.552167\n",
      "mean step (100 episodes) 426.600000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 1128\n",
      "timestep 419000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000352\n",
      "mean reward (100 episodes) 241.191690\n",
      "max reward (100 episodes) 310.552167\n",
      "mean step (100 episodes) 417.320000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_420000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1131\n",
      "timestep 420000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000352\n",
      "mean reward (100 episodes) 243.300383\n",
      "max reward (100 episodes) 306.870274\n",
      "mean step (100 episodes) 400.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1135\n",
      "timestep 421000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000352\n",
      "mean reward (100 episodes) 244.635252\n",
      "max reward (100 episodes) 306.870274\n",
      "mean step (100 episodes) 390.430000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1140\n",
      "timestep 422000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000352\n",
      "mean reward (100 episodes) 248.042128\n",
      "max reward (100 episodes) 308.819457\n",
      "mean step (100 episodes) 371.890000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1142\n",
      "timestep 423000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000351\n",
      "mean reward (100 episodes) 248.897241\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 371.910000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1147\n",
      "timestep 424000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000351\n",
      "mean reward (100 episodes) 247.796791\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 373.750000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1153\n",
      "timestep 425000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000351\n",
      "mean reward (100 episodes) 251.346428\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 374.100000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1156\n",
      "timestep 426000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000351\n",
      "mean reward (100 episodes) 250.181820\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 374.100000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1159\n",
      "timestep 427000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000350\n",
      "mean reward (100 episodes) 250.868455\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 365.470000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1164\n",
      "timestep 428000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000350\n",
      "mean reward (100 episodes) 250.185886\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 371.050000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1169\n",
      "timestep 429000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000350\n",
      "mean reward (100 episodes) 250.110094\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 371.900000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_430000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1172\n",
      "timestep 430000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000350\n",
      "mean reward (100 episodes) 250.093715\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 374.900000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1176\n",
      "timestep 431000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000349\n",
      "mean reward (100 episodes) 252.834701\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 357.320000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1179\n",
      "timestep 432000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000349\n",
      "mean reward (100 episodes) 254.191744\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 351.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1182\n",
      "timestep 433000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000349\n",
      "mean reward (100 episodes) 258.524221\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 326.530000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1187\n",
      "timestep 434000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000349\n",
      "mean reward (100 episodes) 260.383443\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 299.280000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1193\n",
      "timestep 435000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000348\n",
      "mean reward (100 episodes) 260.069143\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 324.510000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1196\n",
      "timestep 436000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000348\n",
      "mean reward (100 episodes) 263.485643\n",
      "max reward (100 episodes) 313.276777\n",
      "mean step (100 episodes) 309.030000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1200\n",
      "timestep 437000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000348\n",
      "mean reward (100 episodes) 265.163993\n",
      "max reward (100 episodes) 314.549273\n",
      "mean step (100 episodes) 301.500000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1204\n",
      "timestep 438000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000348\n",
      "mean reward (100 episodes) 264.985155\n",
      "max reward (100 episodes) 314.549273\n",
      "mean step (100 episodes) 303.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1207\n",
      "timestep 439000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000347\n",
      "mean reward (100 episodes) 259.716262\n",
      "max reward (100 episodes) 314.549273\n",
      "mean step (100 episodes) 307.350000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_440000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1211\n",
      "timestep 440000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000347\n",
      "mean reward (100 episodes) 259.686819\n",
      "max reward (100 episodes) 314.549273\n",
      "mean step (100 episodes) 306.590000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1215\n",
      "timestep 441000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000347\n",
      "mean reward (100 episodes) 259.829368\n",
      "max reward (100 episodes) 314.549273\n",
      "mean step (100 episodes) 306.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1218\n",
      "timestep 442000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000347\n",
      "mean reward (100 episodes) 259.855243\n",
      "max reward (100 episodes) 314.549273\n",
      "mean step (100 episodes) 310.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1221\n",
      "timestep 443000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000347\n",
      "mean reward (100 episodes) 260.012168\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 317.130000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1225\n",
      "timestep 444000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000346\n",
      "mean reward (100 episodes) 248.589836\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 322.590000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1231\n",
      "timestep 445000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000346\n",
      "mean reward (100 episodes) 247.088174\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 314.010000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1235\n",
      "timestep 446000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000346\n",
      "mean reward (100 episodes) 248.107802\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 312.790000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1241\n",
      "timestep 447000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000346\n",
      "mean reward (100 episodes) 248.555211\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 313.780000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1246\n",
      "timestep 448000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000345\n",
      "mean reward (100 episodes) 246.921751\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 321.240000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 1253\n",
      "timestep 449000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000345\n",
      "mean reward (100 episodes) 244.941200\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 320.620000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_450000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1259\n",
      "timestep 450000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000345\n",
      "mean reward (100 episodes) 241.951374\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 317.210000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1264\n",
      "timestep 451000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000345\n",
      "mean reward (100 episodes) 240.884958\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 325.010000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1268\n",
      "timestep 452000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000344\n",
      "mean reward (100 episodes) 240.920384\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 322.510000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1273\n",
      "timestep 453000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000344\n",
      "mean reward (100 episodes) 238.378004\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 321.020000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1277\n",
      "timestep 454000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000344\n",
      "mean reward (100 episodes) 235.269649\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 328.370000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1282\n",
      "timestep 455000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000344\n",
      "mean reward (100 episodes) 238.015540\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 302.210000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1287\n",
      "timestep 456000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000343\n",
      "mean reward (100 episodes) 235.524196\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 309.580000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1291\n",
      "timestep 457000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000343\n",
      "mean reward (100 episodes) 235.664354\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 308.010000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1295\n",
      "timestep 458000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000343\n",
      "mean reward (100 episodes) 236.635268\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 304.560000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1300\n",
      "timestep 459000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000343\n",
      "mean reward (100 episodes) 236.561866\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 315.100000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_460000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1305\n",
      "timestep 460000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000342\n",
      "mean reward (100 episodes) 236.737814\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 313.220000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1308\n",
      "timestep 461000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000342\n",
      "mean reward (100 episodes) 236.703154\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 311.870000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1312\n",
      "timestep 462000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000342\n",
      "mean reward (100 episodes) 236.129589\n",
      "max reward (100 episodes) 322.415693\n",
      "mean step (100 episodes) 306.190000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1317\n",
      "timestep 463000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000342\n",
      "mean reward (100 episodes) 231.838524\n",
      "max reward (100 episodes) 315.835665\n",
      "mean step (100 episodes) 323.150000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1322\n",
      "timestep 464000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000342\n",
      "mean reward (100 episodes) 245.545517\n",
      "max reward (100 episodes) 315.835665\n",
      "mean step (100 episodes) 309.810000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1327\n",
      "timestep 465000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000341\n",
      "mean reward (100 episodes) 250.225242\n",
      "max reward (100 episodes) 315.835665\n",
      "mean step (100 episodes) 300.790000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1331\n",
      "timestep 466000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000341\n",
      "mean reward (100 episodes) 251.842330\n",
      "max reward (100 episodes) 315.835665\n",
      "mean step (100 episodes) 292.570000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1335\n",
      "timestep 467000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000341\n",
      "mean reward (100 episodes) 253.502798\n",
      "max reward (100 episodes) 315.835665\n",
      "mean step (100 episodes) 283.080000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1339\n",
      "timestep 468000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000341\n",
      "mean reward (100 episodes) 254.626120\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 275.950000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1345\n",
      "timestep 469000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000340\n",
      "mean reward (100 episodes) 257.032273\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 276.900000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_470000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1349\n",
      "timestep 470000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000340\n",
      "mean reward (100 episodes) 256.937239\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 277.140000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1352\n",
      "timestep 471000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000340\n",
      "mean reward (100 episodes) 258.139857\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 268.820000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1356\n",
      "timestep 472000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000340\n",
      "mean reward (100 episodes) 258.163838\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 268.540000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1358\n",
      "timestep 473000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000339\n",
      "mean reward (100 episodes) 258.583596\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 290.410000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1362\n",
      "timestep 474000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000339\n",
      "mean reward (100 episodes) 261.071700\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 281.890000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1368\n",
      "timestep 475000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000339\n",
      "mean reward (100 episodes) 259.206226\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 292.480000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1371\n",
      "timestep 476000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000339\n",
      "mean reward (100 episodes) 259.752408\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 297.670000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1374\n",
      "timestep 477000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000339\n",
      "mean reward (100 episodes) 259.005222\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 297.270000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1379\n",
      "timestep 478000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000338\n",
      "mean reward (100 episodes) 258.726469\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 289.580000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "episodes 1381\n",
      "timestep 479000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000338\n",
      "mean reward (100 episodes) 263.200648\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 272.940000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_480000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1384\n",
      "timestep 480000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000338\n",
      "mean reward (100 episodes) 263.575104\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 274.760000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1388\n",
      "timestep 481000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000338\n",
      "mean reward (100 episodes) 264.343794\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 275.380000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1392\n",
      "timestep 482000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000337\n",
      "mean reward (100 episodes) 261.680640\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 291.810000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1397\n",
      "timestep 483000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000337\n",
      "mean reward (100 episodes) 264.300131\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 275.590000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1401\n",
      "timestep 484000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000337\n",
      "mean reward (100 episodes) 261.653808\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 285.130000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1405\n",
      "timestep 485000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000337\n",
      "mean reward (100 episodes) 261.437440\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 285.270000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1411\n",
      "timestep 486000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000336\n",
      "mean reward (100 episodes) 260.044046\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 295.370000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1416\n",
      "timestep 487000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000336\n",
      "mean reward (100 episodes) 258.732097\n",
      "max reward (100 episodes) 318.631503\n",
      "mean step (100 episodes) 296.430000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1421\n",
      "timestep 488000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000336\n",
      "mean reward (100 episodes) 260.214053\n",
      "max reward (100 episodes) 315.280556\n",
      "mean step (100 episodes) 287.820000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1424\n",
      "timestep 489000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000336\n",
      "mean reward (100 episodes) 259.492324\n",
      "max reward (100 episodes) 315.280556\n",
      "mean step (100 episodes) 278.990000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_490000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1429\n",
      "timestep 490000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000336\n",
      "mean reward (100 episodes) 261.670867\n",
      "max reward (100 episodes) 318.872612\n",
      "mean step (100 episodes) 286.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1434\n",
      "timestep 491000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000335\n",
      "mean reward (100 episodes) 260.973022\n",
      "max reward (100 episodes) 318.872612\n",
      "mean step (100 episodes) 295.480000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1438\n",
      "timestep 492000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000335\n",
      "mean reward (100 episodes) 258.480550\n",
      "max reward (100 episodes) 318.872612\n",
      "mean step (100 episodes) 307.990000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1443\n",
      "timestep 493000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000335\n",
      "mean reward (100 episodes) 261.055405\n",
      "max reward (100 episodes) 318.872612\n",
      "mean step (100 episodes) 288.190000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1447\n",
      "timestep 494000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000335\n",
      "mean reward (100 episodes) 259.766585\n",
      "max reward (100 episodes) 318.872612\n",
      "mean step (100 episodes) 301.450000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1451\n",
      "timestep 495000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000334\n",
      "mean reward (100 episodes) 261.627799\n",
      "max reward (100 episodes) 318.872612\n",
      "mean step (100 episodes) 294.980000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1455\n",
      "timestep 496000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000334\n",
      "mean reward (100 episodes) 262.203339\n",
      "max reward (100 episodes) 318.872612\n",
      "mean step (100 episodes) 290.240000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1460\n",
      "timestep 497000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000334\n",
      "mean reward (100 episodes) 261.859676\n",
      "max reward (100 episodes) 318.872612\n",
      "mean step (100 episodes) 292.650000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1464\n",
      "timestep 498000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000334\n",
      "mean reward (100 episodes) 262.253399\n",
      "max reward (100 episodes) 318.872612\n",
      "mean step (100 episodes) 293.500000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "episodes 1467\n",
      "timestep 499000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000334\n",
      "mean reward (100 episodes) 262.951518\n",
      "max reward (100 episodes) 318.872612\n",
      "mean step (100 episodes) 294.350000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/ckpt/dqn_500000.ckpt\n",
      "------------------------------------------------\n",
      "episodes 1472\n",
      "timestep 500000\n",
      "exploration 0.100000\n",
      "learning_rate 0.000333\n",
      "mean reward (100 episodes) 263.024751\n",
      "max reward (100 episodes) 318.872612\n",
      "mean step (100 episodes) 291.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "Saved trajectories to save path: /data1/Prophet/sluo/projects/SALE/sale/result/qr_dqn/online/trajs_2.pkl!\n"
     ]
    }
   ],
   "source": [
    "##### update config for QR-DQN agent #####\n",
    "config['hiddens'] = [256, 256]\n",
    "config['max_training_steps'] = 500000\n",
    "config['lr'] = 5e-4\n",
    "config['decay_steps'] = 1000000\n",
    "config['episode_counts_to_save'] = 100\n",
    "config['persistent_directory'] = 'online/'\n",
    "config['checkpoint_path'] = 'online/ckpts/'\n",
    "##### train the agent #####\n",
    "agent = QuantileAgent(name='LunarLander-v2', num_actions=4, config=config)\n",
    "agent.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'max step')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rewards = pd.Series(agent.eval_episode_rewards)\n",
    "steps = pd.Series(agent.eval_episode_steps)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 8))\n",
    "\n",
    "axes[0][0].plot(rewards.rolling(100, min_periods=20).mean())\n",
    "axes[0][0].set_title('mean reward')\n",
    "axes[0][1].plot(rewards.rolling(100, min_periods=20).max())\n",
    "axes[0][1].set_title('max reward')\n",
    "axes[1][0].plot(steps.rolling(100, min_periods=20).mean())\n",
    "axes[1][0].set_title('mean step')\n",
    "axes[1][1].plot(steps.rolling(100, min_periods=20).max())\n",
    "axes[1][1].set_title('max step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### gather all trajectories #####\n",
    "files = os.listdir('online')\n",
    "files = sorted([file for file in files if file.endswith('.pkl')])\n",
    "trajs = []\n",
    "for file in files:\n",
    "    path = 'online/' + file\n",
    "    with open(path, 'rb') as f:\n",
    "        trajs.append(pickle.load(f))\n",
    "trajs = [traj for file in trajs for traj in file]\n",
    "with open('online/trajs_qr_dqn.pkl', 'wb') as f:\n",
    "    pickle.dump(trajs, f)\n",
    "\n",
    "for file in files:\n",
    "    path = 'online/' + file\n",
    "    os.remove(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline QR-DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/Prophet/sluo/software/anaconda3/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trajectories from load path: offline/agent/trajs_qr_dqn.pkl!\n",
      "Refresh buffer every 1000000 sampling!\n"
     ]
    }
   ],
   "source": [
    "config['online'] = False\n",
    "config['max_training_steps'] = 500000\n",
    "\n",
    "config['lr'] = 5e-4\n",
    "config['decay_steps'] = 1000000\n",
    "\n",
    "config['persistent_directory'] = 'offline/agent/'\n",
    "config['checkpoint_path'] = 'offline/agent/ckpts/'\n",
    "\n",
    "agent = QuantileAgent(name='LunarLander-v2', num_actions=4, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "timestep 1000\n",
      "learning_rate 0.000500\n",
      "mean reward (100 episodes) -521.631992\n",
      "max reward (100 episodes) -403.451045\n",
      "mean step (100 episodes) 145.400000\n",
      "max step (100 episodes) 177.000000\n",
      "------------------------------------------------\n",
      "timestep 2000\n",
      "learning_rate 0.000499\n",
      "mean reward (100 episodes) -409.613346\n",
      "max reward (100 episodes) -92.882683\n",
      "mean step (100 episodes) 138.800000\n",
      "max step (100 episodes) 177.000000\n",
      "------------------------------------------------\n",
      "timestep 3000\n",
      "learning_rate 0.000499\n",
      "mean reward (100 episodes) -369.282034\n",
      "max reward (100 episodes) -75.653620\n",
      "mean step (100 episodes) 154.533333\n",
      "max step (100 episodes) 229.000000\n",
      "------------------------------------------------\n",
      "timestep 4000\n",
      "learning_rate 0.000498\n",
      "mean reward (100 episodes) -313.707643\n",
      "max reward (100 episodes) 11.371285\n",
      "mean step (100 episodes) 166.900000\n",
      "max step (100 episodes) 265.000000\n",
      "------------------------------------------------\n",
      "timestep 5000\n",
      "learning_rate 0.000498\n",
      "mean reward (100 episodes) -309.617849\n",
      "max reward (100 episodes) 110.664451\n",
      "mean step (100 episodes) 200.080000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 6000\n",
      "learning_rate 0.000497\n",
      "mean reward (100 episodes) -283.794582\n",
      "max reward (100 episodes) 110.664451\n",
      "mean step (100 episodes) 238.466667\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 7000\n",
      "learning_rate 0.000497\n",
      "mean reward (100 episodes) -268.367253\n",
      "max reward (100 episodes) 245.241916\n",
      "mean step (100 episodes) 261.200000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 8000\n",
      "learning_rate 0.000496\n",
      "mean reward (100 episodes) -230.804492\n",
      "max reward (100 episodes) 245.241916\n",
      "mean step (100 episodes) 279.200000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 9000\n",
      "learning_rate 0.000496\n",
      "mean reward (100 episodes) -215.293395\n",
      "max reward (100 episodes) 245.241916\n",
      "mean step (100 episodes) 359.288889\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_10000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 10000\n",
      "learning_rate 0.000495\n",
      "mean reward (100 episodes) -201.805617\n",
      "max reward (100 episodes) 245.241916\n",
      "mean step (100 episodes) 423.360000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 11000\n",
      "learning_rate 0.000495\n",
      "mean reward (100 episodes) -194.468613\n",
      "max reward (100 episodes) 245.241916\n",
      "mean step (100 episodes) 472.909091\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 12000\n",
      "learning_rate 0.000494\n",
      "mean reward (100 episodes) -191.019792\n",
      "max reward (100 episodes) 245.241916\n",
      "mean step (100 episodes) 516.833333\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 13000\n",
      "learning_rate 0.000494\n",
      "mean reward (100 episodes) -185.258621\n",
      "max reward (100 episodes) 245.241916\n",
      "mean step (100 episodes) 554.000000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 14000\n",
      "learning_rate 0.000493\n",
      "mean reward (100 episodes) -179.321937\n",
      "max reward (100 episodes) 245.241916\n",
      "mean step (100 episodes) 571.014286\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 15000\n",
      "learning_rate 0.000493\n",
      "mean reward (100 episodes) -174.595572\n",
      "max reward (100 episodes) 245.241916\n",
      "mean step (100 episodes) 589.240000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 16000\n",
      "learning_rate 0.000492\n",
      "mean reward (100 episodes) -169.670992\n",
      "max reward (100 episodes) 245.241916\n",
      "mean step (100 episodes) 581.737500\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 17000\n",
      "learning_rate 0.000492\n",
      "mean reward (100 episodes) -164.593135\n",
      "max reward (100 episodes) 245.241916\n",
      "mean step (100 episodes) 580.000000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 18000\n",
      "learning_rate 0.000491\n",
      "mean reward (100 episodes) -152.176786\n",
      "max reward (100 episodes) 245.241916\n",
      "mean step (100 episodes) 588.044444\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 19000\n",
      "learning_rate 0.000491\n",
      "mean reward (100 episodes) -141.811902\n",
      "max reward (100 episodes) 245.241916\n",
      "mean step (100 episodes) 586.326316\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_20000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 20000\n",
      "learning_rate 0.000490\n",
      "mean reward (100 episodes) -133.240227\n",
      "max reward (100 episodes) 245.241916\n",
      "mean step (100 episodes) 571.040000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 21000\n",
      "learning_rate 0.000490\n",
      "mean reward (100 episodes) -108.353805\n",
      "max reward (100 episodes) 245.241916\n",
      "mean step (100 episodes) 604.570000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 22000\n",
      "learning_rate 0.000489\n",
      "mean reward (100 episodes) -92.161776\n",
      "max reward (100 episodes) 245.241916\n",
      "mean step (100 episodes) 611.330000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 23000\n",
      "learning_rate 0.000489\n",
      "mean reward (100 episodes) -76.148205\n",
      "max reward (100 episodes) 245.241916\n",
      "mean step (100 episodes) 622.070000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 24000\n",
      "learning_rate 0.000488\n",
      "mean reward (100 episodes) -67.918481\n",
      "max reward (100 episodes) 245.241916\n",
      "mean step (100 episodes) 635.420000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 25000\n",
      "learning_rate 0.000488\n",
      "mean reward (100 episodes) -55.786542\n",
      "max reward (100 episodes) 245.241916\n",
      "mean step (100 episodes) 624.140000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 26000\n",
      "learning_rate 0.000487\n",
      "mean reward (100 episodes) -44.987602\n",
      "max reward (100 episodes) 245.241916\n",
      "mean step (100 episodes) 618.470000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 27000\n",
      "learning_rate 0.000487\n",
      "mean reward (100 episodes) -35.676392\n",
      "max reward (100 episodes) 223.530995\n",
      "mean step (100 episodes) 610.940000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 28000\n",
      "learning_rate 0.000486\n",
      "mean reward (100 episodes) -36.433523\n",
      "max reward (100 episodes) 250.869634\n",
      "mean step (100 episodes) 603.010000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 29000\n",
      "learning_rate 0.000486\n",
      "mean reward (100 episodes) -33.822438\n",
      "max reward (100 episodes) 250.869634\n",
      "mean step (100 episodes) 560.170000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_30000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 30000\n",
      "learning_rate 0.000485\n",
      "mean reward (100 episodes) -29.423656\n",
      "max reward (100 episodes) 250.869634\n",
      "mean step (100 episodes) 517.200000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 31000\n",
      "learning_rate 0.000485\n",
      "mean reward (100 episodes) -20.635395\n",
      "max reward (100 episodes) 250.869634\n",
      "mean step (100 episodes) 501.630000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 32000\n",
      "learning_rate 0.000484\n",
      "mean reward (100 episodes) -11.070306\n",
      "max reward (100 episodes) 250.869634\n",
      "mean step (100 episodes) 469.140000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 33000\n",
      "learning_rate 0.000484\n",
      "mean reward (100 episodes) -7.706034\n",
      "max reward (100 episodes) 250.869634\n",
      "mean step (100 episodes) 427.120000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 34000\n",
      "learning_rate 0.000484\n",
      "mean reward (100 episodes) 9.340315\n",
      "max reward (100 episodes) 268.715691\n",
      "mean step (100 episodes) 402.430000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 35000\n",
      "learning_rate 0.000483\n",
      "mean reward (100 episodes) 13.198351\n",
      "max reward (100 episodes) 268.715691\n",
      "mean step (100 episodes) 365.670000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "timestep 36000\n",
      "learning_rate 0.000483\n",
      "mean reward (100 episodes) 16.985500\n",
      "max reward (100 episodes) 268.715691\n",
      "mean step (100 episodes) 349.120000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 37000\n",
      "learning_rate 0.000482\n",
      "mean reward (100 episodes) 24.064618\n",
      "max reward (100 episodes) 268.715691\n",
      "mean step (100 episodes) 332.180000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 38000\n",
      "learning_rate 0.000482\n",
      "mean reward (100 episodes) 28.811729\n",
      "max reward (100 episodes) 268.715691\n",
      "mean step (100 episodes) 306.240000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 39000\n",
      "learning_rate 0.000481\n",
      "mean reward (100 episodes) 26.627539\n",
      "max reward (100 episodes) 268.715691\n",
      "mean step (100 episodes) 285.430000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_40000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 40000\n",
      "learning_rate 0.000481\n",
      "mean reward (100 episodes) 28.072902\n",
      "max reward (100 episodes) 268.715691\n",
      "mean step (100 episodes) 279.490000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 41000\n",
      "learning_rate 0.000480\n",
      "mean reward (100 episodes) 37.190974\n",
      "max reward (100 episodes) 287.190857\n",
      "mean step (100 episodes) 249.190000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 42000\n",
      "learning_rate 0.000480\n",
      "mean reward (100 episodes) 49.163119\n",
      "max reward (100 episodes) 293.810918\n",
      "mean step (100 episodes) 248.440000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 43000\n",
      "learning_rate 0.000479\n",
      "mean reward (100 episodes) 48.348447\n",
      "max reward (100 episodes) 293.810918\n",
      "mean step (100 episodes) 236.040000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 44000\n",
      "learning_rate 0.000479\n",
      "mean reward (100 episodes) 46.662681\n",
      "max reward (100 episodes) 293.810918\n",
      "mean step (100 episodes) 217.490000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 45000\n",
      "learning_rate 0.000478\n",
      "mean reward (100 episodes) 55.789612\n",
      "max reward (100 episodes) 293.810918\n",
      "mean step (100 episodes) 233.360000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 46000\n",
      "learning_rate 0.000478\n",
      "mean reward (100 episodes) 54.441388\n",
      "max reward (100 episodes) 293.810918\n",
      "mean step (100 episodes) 231.800000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 47000\n",
      "learning_rate 0.000478\n",
      "mean reward (100 episodes) 60.254293\n",
      "max reward (100 episodes) 293.810918\n",
      "mean step (100 episodes) 230.460000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 48000\n",
      "learning_rate 0.000477\n",
      "mean reward (100 episodes) 68.323891\n",
      "max reward (100 episodes) 293.810918\n",
      "mean step (100 episodes) 225.490000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 49000\n",
      "learning_rate 0.000477\n",
      "mean reward (100 episodes) 78.785220\n",
      "max reward (100 episodes) 293.810918\n",
      "mean step (100 episodes) 226.870000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_50000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 50000\n",
      "learning_rate 0.000476\n",
      "mean reward (100 episodes) 84.931165\n",
      "max reward (100 episodes) 293.810918\n",
      "mean step (100 episodes) 237.120000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 51000\n",
      "learning_rate 0.000476\n",
      "mean reward (100 episodes) 93.966956\n",
      "max reward (100 episodes) 293.810918\n",
      "mean step (100 episodes) 222.350000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 52000\n",
      "learning_rate 0.000475\n",
      "mean reward (100 episodes) 96.122517\n",
      "max reward (100 episodes) 293.810918\n",
      "mean step (100 episodes) 218.350000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 53000\n",
      "learning_rate 0.000475\n",
      "mean reward (100 episodes) 103.716245\n",
      "max reward (100 episodes) 293.810918\n",
      "mean step (100 episodes) 233.980000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 54000\n",
      "learning_rate 0.000474\n",
      "mean reward (100 episodes) 97.724793\n",
      "max reward (100 episodes) 293.810918\n",
      "mean step (100 episodes) 238.760000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 55000\n",
      "learning_rate 0.000474\n",
      "mean reward (100 episodes) 104.179858\n",
      "max reward (100 episodes) 293.810918\n",
      "mean step (100 episodes) 250.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 56000\n",
      "learning_rate 0.000473\n",
      "mean reward (100 episodes) 113.630409\n",
      "max reward (100 episodes) 293.810918\n",
      "mean step (100 episodes) 265.480000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 57000\n",
      "learning_rate 0.000473\n",
      "mean reward (100 episodes) 118.699453\n",
      "max reward (100 episodes) 293.810918\n",
      "mean step (100 episodes) 262.980000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 58000\n",
      "learning_rate 0.000473\n",
      "mean reward (100 episodes) 121.562079\n",
      "max reward (100 episodes) 293.810918\n",
      "mean step (100 episodes) 261.030000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 59000\n",
      "learning_rate 0.000472\n",
      "mean reward (100 episodes) 127.480718\n",
      "max reward (100 episodes) 293.810918\n",
      "mean step (100 episodes) 270.120000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_60000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 60000\n",
      "learning_rate 0.000472\n",
      "mean reward (100 episodes) 135.632168\n",
      "max reward (100 episodes) 293.810918\n",
      "mean step (100 episodes) 276.020000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 61000\n",
      "learning_rate 0.000471\n",
      "mean reward (100 episodes) 134.626529\n",
      "max reward (100 episodes) 293.810918\n",
      "mean step (100 episodes) 283.500000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 62000\n",
      "learning_rate 0.000471\n",
      "mean reward (100 episodes) 132.832811\n",
      "max reward (100 episodes) 289.907074\n",
      "mean step (100 episodes) 285.700000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 63000\n",
      "learning_rate 0.000470\n",
      "mean reward (100 episodes) 138.763041\n",
      "max reward (100 episodes) 289.907074\n",
      "mean step (100 episodes) 300.530000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 64000\n",
      "learning_rate 0.000470\n",
      "mean reward (100 episodes) 152.238530\n",
      "max reward (100 episodes) 295.333863\n",
      "mean step (100 episodes) 313.670000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 65000\n",
      "learning_rate 0.000469\n",
      "mean reward (100 episodes) 149.427731\n",
      "max reward (100 episodes) 295.333863\n",
      "mean step (100 episodes) 310.530000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 66000\n",
      "learning_rate 0.000469\n",
      "mean reward (100 episodes) 153.698446\n",
      "max reward (100 episodes) 295.333863\n",
      "mean step (100 episodes) 308.300000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 67000\n",
      "learning_rate 0.000469\n",
      "mean reward (100 episodes) 151.993561\n",
      "max reward (100 episodes) 295.333863\n",
      "mean step (100 episodes) 313.900000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 68000\n",
      "learning_rate 0.000468\n",
      "mean reward (100 episodes) 150.474317\n",
      "max reward (100 episodes) 295.333863\n",
      "mean step (100 episodes) 317.730000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 69000\n",
      "learning_rate 0.000468\n",
      "mean reward (100 episodes) 145.255295\n",
      "max reward (100 episodes) 295.333863\n",
      "mean step (100 episodes) 319.110000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_70000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 70000\n",
      "learning_rate 0.000467\n",
      "mean reward (100 episodes) 148.376452\n",
      "max reward (100 episodes) 295.333863\n",
      "mean step (100 episodes) 327.000000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "timestep 71000\n",
      "learning_rate 0.000467\n",
      "mean reward (100 episodes) 144.520405\n",
      "max reward (100 episodes) 308.591842\n",
      "mean step (100 episodes) 344.630000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 72000\n",
      "learning_rate 0.000466\n",
      "mean reward (100 episodes) 152.100595\n",
      "max reward (100 episodes) 308.591842\n",
      "mean step (100 episodes) 359.280000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 73000\n",
      "learning_rate 0.000466\n",
      "mean reward (100 episodes) 157.172381\n",
      "max reward (100 episodes) 308.591842\n",
      "mean step (100 episodes) 363.930000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 74000\n",
      "learning_rate 0.000466\n",
      "mean reward (100 episodes) 160.400824\n",
      "max reward (100 episodes) 308.591842\n",
      "mean step (100 episodes) 384.190000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 75000\n",
      "learning_rate 0.000465\n",
      "mean reward (100 episodes) 160.492737\n",
      "max reward (100 episodes) 308.591842\n",
      "mean step (100 episodes) 397.500000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 76000\n",
      "learning_rate 0.000465\n",
      "mean reward (100 episodes) 160.700132\n",
      "max reward (100 episodes) 308.591842\n",
      "mean step (100 episodes) 413.970000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 77000\n",
      "learning_rate 0.000464\n",
      "mean reward (100 episodes) 158.380969\n",
      "max reward (100 episodes) 308.591842\n",
      "mean step (100 episodes) 433.620000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 78000\n",
      "learning_rate 0.000464\n",
      "mean reward (100 episodes) 157.436157\n",
      "max reward (100 episodes) 308.591842\n",
      "mean step (100 episodes) 456.610000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 79000\n",
      "learning_rate 0.000463\n",
      "mean reward (100 episodes) 161.725153\n",
      "max reward (100 episodes) 308.591842\n",
      "mean step (100 episodes) 465.500000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_80000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 83000\n",
      "learning_rate 0.000462\n",
      "mean reward (100 episodes) 146.591343\n",
      "max reward (100 episodes) 308.591842\n",
      "mean step (100 episodes) 537.910000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 84000\n",
      "learning_rate 0.000461\n",
      "mean reward (100 episodes) 134.796994\n",
      "max reward (100 episodes) 308.591842\n",
      "mean step (100 episodes) 557.090000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 87000\n",
      "learning_rate 0.000460\n",
      "mean reward (100 episodes) 143.026066\n",
      "max reward (100 episodes) 308.591842\n",
      "mean step (100 episodes) 602.010000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 88000\n",
      "learning_rate 0.000460\n",
      "mean reward (100 episodes) 139.931906\n",
      "max reward (100 episodes) 308.591842\n",
      "mean step (100 episodes) 601.130000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 89000\n",
      "learning_rate 0.000459\n",
      "mean reward (100 episodes) 134.686980\n",
      "max reward (100 episodes) 308.591842\n",
      "mean step (100 episodes) 641.210000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_90000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 90000\n",
      "learning_rate 0.000459\n",
      "mean reward (100 episodes) 135.345918\n",
      "max reward (100 episodes) 308.591842\n",
      "mean step (100 episodes) 644.430000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 91000\n",
      "learning_rate 0.000458\n",
      "mean reward (100 episodes) 128.649914\n",
      "max reward (100 episodes) 298.796438\n",
      "mean step (100 episodes) 651.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 92000\n",
      "learning_rate 0.000458\n",
      "mean reward (100 episodes) 120.204684\n",
      "max reward (100 episodes) 298.796438\n",
      "mean step (100 episodes) 643.300000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 93000\n",
      "learning_rate 0.000457\n",
      "mean reward (100 episodes) 120.981075\n",
      "max reward (100 episodes) 315.855404\n",
      "mean step (100 episodes) 642.730000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 94000\n",
      "learning_rate 0.000457\n",
      "mean reward (100 episodes) 112.571298\n",
      "max reward (100 episodes) 315.855404\n",
      "mean step (100 episodes) 643.920000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 95000\n",
      "learning_rate 0.000457\n",
      "mean reward (100 episodes) 115.171030\n",
      "max reward (100 episodes) 315.855404\n",
      "mean step (100 episodes) 643.590000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 96000\n",
      "learning_rate 0.000456\n",
      "mean reward (100 episodes) 117.842090\n",
      "max reward (100 episodes) 315.855404\n",
      "mean step (100 episodes) 631.270000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 97000\n",
      "learning_rate 0.000456\n",
      "mean reward (100 episodes) 121.020718\n",
      "max reward (100 episodes) 315.855404\n",
      "mean step (100 episodes) 633.060000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 98000\n",
      "learning_rate 0.000455\n",
      "mean reward (100 episodes) 120.461315\n",
      "max reward (100 episodes) 315.855404\n",
      "mean step (100 episodes) 620.760000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 99000\n",
      "learning_rate 0.000455\n",
      "mean reward (100 episodes) 117.356703\n",
      "max reward (100 episodes) 315.855404\n",
      "mean step (100 episodes) 633.440000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_100000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 100000\n",
      "learning_rate 0.000455\n",
      "mean reward (100 episodes) 113.756474\n",
      "max reward (100 episodes) 315.855404\n",
      "mean step (100 episodes) 645.970000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 101000\n",
      "learning_rate 0.000454\n",
      "mean reward (100 episodes) 111.469216\n",
      "max reward (100 episodes) 315.855404\n",
      "mean step (100 episodes) 648.850000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 102000\n",
      "learning_rate 0.000454\n",
      "mean reward (100 episodes) 117.287470\n",
      "max reward (100 episodes) 315.855404\n",
      "mean step (100 episodes) 645.980000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 103000\n",
      "learning_rate 0.000453\n",
      "mean reward (100 episodes) 123.221644\n",
      "max reward (100 episodes) 315.855404\n",
      "mean step (100 episodes) 620.290000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 104000\n",
      "learning_rate 0.000453\n",
      "mean reward (100 episodes) 133.531403\n",
      "max reward (100 episodes) 315.855404\n",
      "mean step (100 episodes) 607.480000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 105000\n",
      "learning_rate 0.000452\n",
      "mean reward (100 episodes) 125.146192\n",
      "max reward (100 episodes) 315.855404\n",
      "mean step (100 episodes) 625.420000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 106000\n",
      "learning_rate 0.000452\n",
      "mean reward (100 episodes) 125.883754\n",
      "max reward (100 episodes) 315.855404\n",
      "mean step (100 episodes) 626.650000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 107000\n",
      "learning_rate 0.000452\n",
      "mean reward (100 episodes) 135.019784\n",
      "max reward (100 episodes) 315.855404\n",
      "mean step (100 episodes) 611.450000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 108000\n",
      "learning_rate 0.000451\n",
      "mean reward (100 episodes) 131.300416\n",
      "max reward (100 episodes) 315.855404\n",
      "mean step (100 episodes) 646.000000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 109000\n",
      "learning_rate 0.000451\n",
      "mean reward (100 episodes) 144.806175\n",
      "max reward (100 episodes) 315.855404\n",
      "mean step (100 episodes) 617.110000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_110000.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "timestep 110000\n",
      "learning_rate 0.000450\n",
      "mean reward (100 episodes) 147.503750\n",
      "max reward (100 episodes) 315.855404\n",
      "mean step (100 episodes) 607.560000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 111000\n",
      "learning_rate 0.000450\n",
      "mean reward (100 episodes) 151.008473\n",
      "max reward (100 episodes) 315.855404\n",
      "mean step (100 episodes) 599.760000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 112000\n",
      "learning_rate 0.000450\n",
      "mean reward (100 episodes) 149.390734\n",
      "max reward (100 episodes) 315.855404\n",
      "mean step (100 episodes) 621.790000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 113000\n",
      "learning_rate 0.000449\n",
      "mean reward (100 episodes) 150.464475\n",
      "max reward (100 episodes) 315.489022\n",
      "mean step (100 episodes) 614.670000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 114000\n",
      "learning_rate 0.000449\n",
      "mean reward (100 episodes) 160.634235\n",
      "max reward (100 episodes) 315.489022\n",
      "mean step (100 episodes) 600.150000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 115000\n",
      "learning_rate 0.000448\n",
      "mean reward (100 episodes) 165.363038\n",
      "max reward (100 episodes) 315.489022\n",
      "mean step (100 episodes) 590.120000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 116000\n",
      "learning_rate 0.000448\n",
      "mean reward (100 episodes) 167.657091\n",
      "max reward (100 episodes) 311.527667\n",
      "mean step (100 episodes) 574.410000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 117000\n",
      "learning_rate 0.000448\n",
      "mean reward (100 episodes) 169.858550\n",
      "max reward (100 episodes) 311.527667\n",
      "mean step (100 episodes) 577.540000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 118000\n",
      "learning_rate 0.000447\n",
      "mean reward (100 episodes) 174.469348\n",
      "max reward (100 episodes) 313.204192\n",
      "mean step (100 episodes) 571.400000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 119000\n",
      "learning_rate 0.000447\n",
      "mean reward (100 episodes) 178.784954\n",
      "max reward (100 episodes) 313.204192\n",
      "mean step (100 episodes) 559.210000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_120000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 120000\n",
      "learning_rate 0.000446\n",
      "mean reward (100 episodes) 191.705115\n",
      "max reward (100 episodes) 313.204192\n",
      "mean step (100 episodes) 519.890000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 121000\n",
      "learning_rate 0.000446\n",
      "mean reward (100 episodes) 202.327936\n",
      "max reward (100 episodes) 313.204192\n",
      "mean step (100 episodes) 506.160000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 122000\n",
      "learning_rate 0.000446\n",
      "mean reward (100 episodes) 201.476606\n",
      "max reward (100 episodes) 313.204192\n",
      "mean step (100 episodes) 505.200000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 123000\n",
      "learning_rate 0.000445\n",
      "mean reward (100 episodes) 199.931015\n",
      "max reward (100 episodes) 313.204192\n",
      "mean step (100 episodes) 512.850000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 124000\n",
      "learning_rate 0.000445\n",
      "mean reward (100 episodes) 196.878852\n",
      "max reward (100 episodes) 313.204192\n",
      "mean step (100 episodes) 499.680000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 125000\n",
      "learning_rate 0.000444\n",
      "mean reward (100 episodes) 208.951334\n",
      "max reward (100 episodes) 313.204192\n",
      "mean step (100 episodes) 470.810000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 126000\n",
      "learning_rate 0.000444\n",
      "mean reward (100 episodes) 207.953291\n",
      "max reward (100 episodes) 313.204192\n",
      "mean step (100 episodes) 473.930000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 127000\n",
      "learning_rate 0.000444\n",
      "mean reward (100 episodes) 209.861310\n",
      "max reward (100 episodes) 313.204192\n",
      "mean step (100 episodes) 467.780000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 130000\n",
      "learning_rate 0.000442\n",
      "mean reward (100 episodes) 217.472066\n",
      "max reward (100 episodes) 313.204192\n",
      "mean step (100 episodes) 436.420000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 131000\n",
      "learning_rate 0.000442\n",
      "mean reward (100 episodes) 224.904389\n",
      "max reward (100 episodes) 313.204192\n",
      "mean step (100 episodes) 420.230000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 132000\n",
      "learning_rate 0.000442\n",
      "mean reward (100 episodes) 232.436968\n",
      "max reward (100 episodes) 313.204192\n",
      "mean step (100 episodes) 405.080000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 133000\n",
      "learning_rate 0.000441\n",
      "mean reward (100 episodes) 230.274462\n",
      "max reward (100 episodes) 313.204192\n",
      "mean step (100 episodes) 402.320000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 134000\n",
      "learning_rate 0.000441\n",
      "mean reward (100 episodes) 231.576949\n",
      "max reward (100 episodes) 313.204192\n",
      "mean step (100 episodes) 403.890000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 135000\n",
      "learning_rate 0.000441\n",
      "mean reward (100 episodes) 232.661365\n",
      "max reward (100 episodes) 313.204192\n",
      "mean step (100 episodes) 400.120000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 136000\n",
      "learning_rate 0.000440\n",
      "mean reward (100 episodes) 232.412597\n",
      "max reward (100 episodes) 313.204192\n",
      "mean step (100 episodes) 399.410000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 137000\n",
      "learning_rate 0.000440\n",
      "mean reward (100 episodes) 232.143726\n",
      "max reward (100 episodes) 313.204192\n",
      "mean step (100 episodes) 376.360000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 138000\n",
      "learning_rate 0.000439\n",
      "mean reward (100 episodes) 229.406447\n",
      "max reward (100 episodes) 312.074944\n",
      "mean step (100 episodes) 390.710000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 139000\n",
      "learning_rate 0.000439\n",
      "mean reward (100 episodes) 229.866846\n",
      "max reward (100 episodes) 312.074944\n",
      "mean step (100 episodes) 385.900000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_140000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 140000\n",
      "learning_rate 0.000439\n",
      "mean reward (100 episodes) 229.698080\n",
      "max reward (100 episodes) 312.074944\n",
      "mean step (100 episodes) 388.420000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 141000\n",
      "learning_rate 0.000438\n",
      "mean reward (100 episodes) 231.091763\n",
      "max reward (100 episodes) 312.074944\n",
      "mean step (100 episodes) 371.710000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 142000\n",
      "learning_rate 0.000438\n",
      "mean reward (100 episodes) 231.342002\n",
      "max reward (100 episodes) 312.074944\n",
      "mean step (100 episodes) 376.580000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 143000\n",
      "learning_rate 0.000437\n",
      "mean reward (100 episodes) 229.910923\n",
      "max reward (100 episodes) 312.074944\n",
      "mean step (100 episodes) 393.860000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 144000\n",
      "learning_rate 0.000437\n",
      "mean reward (100 episodes) 233.159184\n",
      "max reward (100 episodes) 312.074944\n",
      "mean step (100 episodes) 410.900000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 145000\n",
      "learning_rate 0.000437\n",
      "mean reward (100 episodes) 234.448785\n",
      "max reward (100 episodes) 313.069503\n",
      "mean step (100 episodes) 402.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 146000\n",
      "learning_rate 0.000436\n",
      "mean reward (100 episodes) 234.048597\n",
      "max reward (100 episodes) 313.069503\n",
      "mean step (100 episodes) 411.990000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "timestep 147000\n",
      "learning_rate 0.000436\n",
      "mean reward (100 episodes) 235.359450\n",
      "max reward (100 episodes) 313.069503\n",
      "mean step (100 episodes) 396.890000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 148000\n",
      "learning_rate 0.000436\n",
      "mean reward (100 episodes) 234.727495\n",
      "max reward (100 episodes) 313.069503\n",
      "mean step (100 episodes) 396.070000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 149000\n",
      "learning_rate 0.000435\n",
      "mean reward (100 episodes) 241.804419\n",
      "max reward (100 episodes) 313.069503\n",
      "mean step (100 episodes) 400.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_150000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 150000\n",
      "learning_rate 0.000435\n",
      "mean reward (100 episodes) 242.809658\n",
      "max reward (100 episodes) 315.719446\n",
      "mean step (100 episodes) 384.460000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 151000\n",
      "learning_rate 0.000434\n",
      "mean reward (100 episodes) 242.946172\n",
      "max reward (100 episodes) 315.719446\n",
      "mean step (100 episodes) 383.410000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 152000\n",
      "learning_rate 0.000434\n",
      "mean reward (100 episodes) 246.757323\n",
      "max reward (100 episodes) 315.719446\n",
      "mean step (100 episodes) 375.530000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 153000\n",
      "learning_rate 0.000434\n",
      "mean reward (100 episodes) 249.597958\n",
      "max reward (100 episodes) 315.719446\n",
      "mean step (100 episodes) 375.510000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 154000\n",
      "learning_rate 0.000433\n",
      "mean reward (100 episodes) 248.583016\n",
      "max reward (100 episodes) 315.719446\n",
      "mean step (100 episodes) 373.440000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 155000\n",
      "learning_rate 0.000433\n",
      "mean reward (100 episodes) 248.519644\n",
      "max reward (100 episodes) 318.502748\n",
      "mean step (100 episodes) 369.960000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 156000\n",
      "learning_rate 0.000433\n",
      "mean reward (100 episodes) 248.919159\n",
      "max reward (100 episodes) 318.502748\n",
      "mean step (100 episodes) 370.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 157000\n",
      "learning_rate 0.000432\n",
      "mean reward (100 episodes) 244.668407\n",
      "max reward (100 episodes) 318.502748\n",
      "mean step (100 episodes) 381.060000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 158000\n",
      "learning_rate 0.000432\n",
      "mean reward (100 episodes) 247.484888\n",
      "max reward (100 episodes) 318.502748\n",
      "mean step (100 episodes) 363.960000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 159000\n",
      "learning_rate 0.000431\n",
      "mean reward (100 episodes) 247.775820\n",
      "max reward (100 episodes) 318.502748\n",
      "mean step (100 episodes) 362.810000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_160000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 160000\n",
      "learning_rate 0.000431\n",
      "mean reward (100 episodes) 245.092783\n",
      "max reward (100 episodes) 318.502748\n",
      "mean step (100 episodes) 382.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 164000\n",
      "learning_rate 0.000430\n",
      "mean reward (100 episodes) 248.405609\n",
      "max reward (100 episodes) 321.919436\n",
      "mean step (100 episodes) 333.860000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 165000\n",
      "learning_rate 0.000429\n",
      "mean reward (100 episodes) 247.612081\n",
      "max reward (100 episodes) 321.919436\n",
      "mean step (100 episodes) 339.170000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 166000\n",
      "learning_rate 0.000429\n",
      "mean reward (100 episodes) 244.486597\n",
      "max reward (100 episodes) 321.919436\n",
      "mean step (100 episodes) 342.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 167000\n",
      "learning_rate 0.000428\n",
      "mean reward (100 episodes) 243.965471\n",
      "max reward (100 episodes) 321.919436\n",
      "mean step (100 episodes) 350.100000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 168000\n",
      "learning_rate 0.000428\n",
      "mean reward (100 episodes) 243.403765\n",
      "max reward (100 episodes) 321.919436\n",
      "mean step (100 episodes) 347.640000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 169000\n",
      "learning_rate 0.000428\n",
      "mean reward (100 episodes) 235.838601\n",
      "max reward (100 episodes) 321.919436\n",
      "mean step (100 episodes) 360.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_170000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 170000\n",
      "learning_rate 0.000427\n",
      "mean reward (100 episodes) 223.851143\n",
      "max reward (100 episodes) 321.919436\n",
      "mean step (100 episodes) 365.470000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 171000\n",
      "learning_rate 0.000427\n",
      "mean reward (100 episodes) 222.151185\n",
      "max reward (100 episodes) 321.919436\n",
      "mean step (100 episodes) 367.710000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 172000\n",
      "learning_rate 0.000427\n",
      "mean reward (100 episodes) 221.030006\n",
      "max reward (100 episodes) 321.919436\n",
      "mean step (100 episodes) 370.460000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 173000\n",
      "learning_rate 0.000426\n",
      "mean reward (100 episodes) 222.632347\n",
      "max reward (100 episodes) 321.919436\n",
      "mean step (100 episodes) 364.620000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 174000\n",
      "learning_rate 0.000426\n",
      "mean reward (100 episodes) 224.361096\n",
      "max reward (100 episodes) 321.919436\n",
      "mean step (100 episodes) 358.780000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 175000\n",
      "learning_rate 0.000426\n",
      "mean reward (100 episodes) 224.277027\n",
      "max reward (100 episodes) 321.919436\n",
      "mean step (100 episodes) 369.800000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 176000\n",
      "learning_rate 0.000425\n",
      "mean reward (100 episodes) 222.568683\n",
      "max reward (100 episodes) 321.919436\n",
      "mean step (100 episodes) 371.980000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 177000\n",
      "learning_rate 0.000425\n",
      "mean reward (100 episodes) 214.907341\n",
      "max reward (100 episodes) 321.919436\n",
      "mean step (100 episodes) 375.300000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 178000\n",
      "learning_rate 0.000424\n",
      "mean reward (100 episodes) 212.292043\n",
      "max reward (100 episodes) 321.919436\n",
      "mean step (100 episodes) 397.800000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 179000\n",
      "learning_rate 0.000424\n",
      "mean reward (100 episodes) 214.184981\n",
      "max reward (100 episodes) 321.919436\n",
      "mean step (100 episodes) 388.220000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_180000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 180000\n",
      "learning_rate 0.000424\n",
      "mean reward (100 episodes) 214.049695\n",
      "max reward (100 episodes) 321.919436\n",
      "mean step (100 episodes) 390.210000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 181000\n",
      "learning_rate 0.000423\n",
      "mean reward (100 episodes) 213.957523\n",
      "max reward (100 episodes) 313.024095\n",
      "mean step (100 episodes) 385.990000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 182000\n",
      "learning_rate 0.000423\n",
      "mean reward (100 episodes) 217.767318\n",
      "max reward (100 episodes) 313.024095\n",
      "mean step (100 episodes) 386.830000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 183000\n",
      "learning_rate 0.000423\n",
      "mean reward (100 episodes) 211.596176\n",
      "max reward (100 episodes) 313.024095\n",
      "mean step (100 episodes) 387.620000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "timestep 184000\n",
      "learning_rate 0.000422\n",
      "mean reward (100 episodes) 207.493197\n",
      "max reward (100 episodes) 313.024095\n",
      "mean step (100 episodes) 414.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 185000\n",
      "learning_rate 0.000422\n",
      "mean reward (100 episodes) 206.407196\n",
      "max reward (100 episodes) 313.024095\n",
      "mean step (100 episodes) 407.980000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 186000\n",
      "learning_rate 0.000422\n",
      "mean reward (100 episodes) 210.887388\n",
      "max reward (100 episodes) 313.024095\n",
      "mean step (100 episodes) 389.770000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 187000\n",
      "learning_rate 0.000421\n",
      "mean reward (100 episodes) 208.304759\n",
      "max reward (100 episodes) 313.024095\n",
      "mean step (100 episodes) 399.960000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 188000\n",
      "learning_rate 0.000421\n",
      "mean reward (100 episodes) 196.391091\n",
      "max reward (100 episodes) 313.024095\n",
      "mean step (100 episodes) 420.950000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 189000\n",
      "learning_rate 0.000421\n",
      "mean reward (100 episodes) 200.231443\n",
      "max reward (100 episodes) 313.024095\n",
      "mean step (100 episodes) 405.920000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_190000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 190000\n",
      "learning_rate 0.000420\n",
      "mean reward (100 episodes) 210.538773\n",
      "max reward (100 episodes) 313.024095\n",
      "mean step (100 episodes) 403.550000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 191000\n",
      "learning_rate 0.000420\n",
      "mean reward (100 episodes) 209.900801\n",
      "max reward (100 episodes) 313.024095\n",
      "mean step (100 episodes) 405.790000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 192000\n",
      "learning_rate 0.000419\n",
      "mean reward (100 episodes) 208.759951\n",
      "max reward (100 episodes) 313.024095\n",
      "mean step (100 episodes) 392.930000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 193000\n",
      "learning_rate 0.000419\n",
      "mean reward (100 episodes) 205.827638\n",
      "max reward (100 episodes) 313.024095\n",
      "mean step (100 episodes) 403.830000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 194000\n",
      "learning_rate 0.000419\n",
      "mean reward (100 episodes) 205.654517\n",
      "max reward (100 episodes) 313.024095\n",
      "mean step (100 episodes) 402.460000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 195000\n",
      "learning_rate 0.000418\n",
      "mean reward (100 episodes) 203.294467\n",
      "max reward (100 episodes) 309.925675\n",
      "mean step (100 episodes) 390.870000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 196000\n",
      "learning_rate 0.000418\n",
      "mean reward (100 episodes) 202.811561\n",
      "max reward (100 episodes) 309.925675\n",
      "mean step (100 episodes) 401.900000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 197000\n",
      "learning_rate 0.000418\n",
      "mean reward (100 episodes) 215.833368\n",
      "max reward (100 episodes) 308.403565\n",
      "mean step (100 episodes) 388.220000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 198000\n",
      "learning_rate 0.000417\n",
      "mean reward (100 episodes) 214.890835\n",
      "max reward (100 episodes) 308.403565\n",
      "mean step (100 episodes) 373.200000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 199000\n",
      "learning_rate 0.000417\n",
      "mean reward (100 episodes) 212.037444\n",
      "max reward (100 episodes) 308.403565\n",
      "mean step (100 episodes) 372.220000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_200000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 200000\n",
      "learning_rate 0.000417\n",
      "mean reward (100 episodes) 212.058432\n",
      "max reward (100 episodes) 308.403565\n",
      "mean step (100 episodes) 359.460000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 201000\n",
      "learning_rate 0.000416\n",
      "mean reward (100 episodes) 206.603549\n",
      "max reward (100 episodes) 308.403565\n",
      "mean step (100 episodes) 369.510000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 202000\n",
      "learning_rate 0.000416\n",
      "mean reward (100 episodes) 200.754909\n",
      "max reward (100 episodes) 308.403565\n",
      "mean step (100 episodes) 377.790000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 203000\n",
      "learning_rate 0.000416\n",
      "mean reward (100 episodes) 200.859949\n",
      "max reward (100 episodes) 308.403565\n",
      "mean step (100 episodes) 378.510000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 204000\n",
      "learning_rate 0.000415\n",
      "mean reward (100 episodes) 197.533165\n",
      "max reward (100 episodes) 308.403565\n",
      "mean step (100 episodes) 356.460000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 205000\n",
      "learning_rate 0.000415\n",
      "mean reward (100 episodes) 196.085071\n",
      "max reward (100 episodes) 308.403565\n",
      "mean step (100 episodes) 362.590000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 206000\n",
      "learning_rate 0.000415\n",
      "mean reward (100 episodes) 187.960259\n",
      "max reward (100 episodes) 308.403565\n",
      "mean step (100 episodes) 357.310000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 207000\n",
      "learning_rate 0.000414\n",
      "mean reward (100 episodes) 179.929132\n",
      "max reward (100 episodes) 308.403565\n",
      "mean step (100 episodes) 344.040000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 208000\n",
      "learning_rate 0.000414\n",
      "mean reward (100 episodes) 189.936842\n",
      "max reward (100 episodes) 308.403565\n",
      "mean step (100 episodes) 322.110000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 209000\n",
      "learning_rate 0.000414\n",
      "mean reward (100 episodes) 187.212297\n",
      "max reward (100 episodes) 306.205072\n",
      "mean step (100 episodes) 325.190000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_210000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 210000\n",
      "learning_rate 0.000413\n",
      "mean reward (100 episodes) 187.365694\n",
      "max reward (100 episodes) 306.205072\n",
      "mean step (100 episodes) 322.200000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 211000\n",
      "learning_rate 0.000413\n",
      "mean reward (100 episodes) 186.568433\n",
      "max reward (100 episodes) 313.807379\n",
      "mean step (100 episodes) 325.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 212000\n",
      "learning_rate 0.000413\n",
      "mean reward (100 episodes) 182.204585\n",
      "max reward (100 episodes) 313.807379\n",
      "mean step (100 episodes) 325.230000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 213000\n",
      "learning_rate 0.000412\n",
      "mean reward (100 episodes) 184.726564\n",
      "max reward (100 episodes) 313.807379\n",
      "mean step (100 episodes) 320.490000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 214000\n",
      "learning_rate 0.000412\n",
      "mean reward (100 episodes) 185.493864\n",
      "max reward (100 episodes) 313.807379\n",
      "mean step (100 episodes) 312.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 215000\n",
      "learning_rate 0.000412\n",
      "mean reward (100 episodes) 181.947300\n",
      "max reward (100 episodes) 313.807379\n",
      "mean step (100 episodes) 316.540000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 216000\n",
      "learning_rate 0.000411\n",
      "mean reward (100 episodes) 176.323764\n",
      "max reward (100 episodes) 313.807379\n",
      "mean step (100 episodes) 309.480000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 217000\n",
      "learning_rate 0.000411\n",
      "mean reward (100 episodes) 176.839759\n",
      "max reward (100 episodes) 313.807379\n",
      "mean step (100 episodes) 317.580000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 218000\n",
      "learning_rate 0.000411\n",
      "mean reward (100 episodes) 174.081494\n",
      "max reward (100 episodes) 313.807379\n",
      "mean step (100 episodes) 315.950000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "timestep 219000\n",
      "learning_rate 0.000410\n",
      "mean reward (100 episodes) 167.295663\n",
      "max reward (100 episodes) 313.807379\n",
      "mean step (100 episodes) 335.870000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_220000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 220000\n",
      "learning_rate 0.000410\n",
      "mean reward (100 episodes) 169.117986\n",
      "max reward (100 episodes) 313.807379\n",
      "mean step (100 episodes) 322.940000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 221000\n",
      "learning_rate 0.000410\n",
      "mean reward (100 episodes) 175.507779\n",
      "max reward (100 episodes) 313.807379\n",
      "mean step (100 episodes) 313.240000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 222000\n",
      "learning_rate 0.000409\n",
      "mean reward (100 episodes) 180.950153\n",
      "max reward (100 episodes) 313.807379\n",
      "mean step (100 episodes) 307.050000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 223000\n",
      "learning_rate 0.000409\n",
      "mean reward (100 episodes) 187.378458\n",
      "max reward (100 episodes) 313.807379\n",
      "mean step (100 episodes) 297.660000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 224000\n",
      "learning_rate 0.000408\n",
      "mean reward (100 episodes) 194.035766\n",
      "max reward (100 episodes) 313.807379\n",
      "mean step (100 episodes) 306.670000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 225000\n",
      "learning_rate 0.000408\n",
      "mean reward (100 episodes) 197.903550\n",
      "max reward (100 episodes) 313.807379\n",
      "mean step (100 episodes) 298.630000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 226000\n",
      "learning_rate 0.000408\n",
      "mean reward (100 episodes) 205.882129\n",
      "max reward (100 episodes) 313.807379\n",
      "mean step (100 episodes) 306.570000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 227000\n",
      "learning_rate 0.000407\n",
      "mean reward (100 episodes) 215.890321\n",
      "max reward (100 episodes) 313.807379\n",
      "mean step (100 episodes) 311.370000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 228000\n",
      "learning_rate 0.000407\n",
      "mean reward (100 episodes) 219.236285\n",
      "max reward (100 episodes) 313.807379\n",
      "mean step (100 episodes) 307.380000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 229000\n",
      "learning_rate 0.000407\n",
      "mean reward (100 episodes) 224.357190\n",
      "max reward (100 episodes) 313.807379\n",
      "mean step (100 episodes) 308.750000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_230000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 230000\n",
      "learning_rate 0.000407\n",
      "mean reward (100 episodes) 225.075550\n",
      "max reward (100 episodes) 313.807379\n",
      "mean step (100 episodes) 322.630000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 231000\n",
      "learning_rate 0.000406\n",
      "mean reward (100 episodes) 229.509874\n",
      "max reward (100 episodes) 312.345378\n",
      "mean step (100 episodes) 306.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 232000\n",
      "learning_rate 0.000406\n",
      "mean reward (100 episodes) 235.424151\n",
      "max reward (100 episodes) 312.345378\n",
      "mean step (100 episodes) 316.860000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 233000\n",
      "learning_rate 0.000406\n",
      "mean reward (100 episodes) 233.872602\n",
      "max reward (100 episodes) 312.345378\n",
      "mean step (100 episodes) 322.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 234000\n",
      "learning_rate 0.000405\n",
      "mean reward (100 episodes) 233.121026\n",
      "max reward (100 episodes) 312.345378\n",
      "mean step (100 episodes) 328.190000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 235000\n",
      "learning_rate 0.000405\n",
      "mean reward (100 episodes) 237.931172\n",
      "max reward (100 episodes) 312.345378\n",
      "mean step (100 episodes) 339.770000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 236000\n",
      "learning_rate 0.000405\n",
      "mean reward (100 episodes) 245.580276\n",
      "max reward (100 episodes) 312.345378\n",
      "mean step (100 episodes) 345.680000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 237000\n",
      "learning_rate 0.000404\n",
      "mean reward (100 episodes) 247.656324\n",
      "max reward (100 episodes) 319.449183\n",
      "mean step (100 episodes) 337.690000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 238000\n",
      "learning_rate 0.000404\n",
      "mean reward (100 episodes) 254.000901\n",
      "max reward (100 episodes) 319.449183\n",
      "mean step (100 episodes) 339.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 239000\n",
      "learning_rate 0.000404\n",
      "mean reward (100 episodes) 261.113498\n",
      "max reward (100 episodes) 319.449183\n",
      "mean step (100 episodes) 336.420000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_240000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 240000\n",
      "learning_rate 0.000403\n",
      "mean reward (100 episodes) 263.714893\n",
      "max reward (100 episodes) 319.449183\n",
      "mean step (100 episodes) 337.290000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 241000\n",
      "learning_rate 0.000403\n",
      "mean reward (100 episodes) 261.779779\n",
      "max reward (100 episodes) 319.449183\n",
      "mean step (100 episodes) 345.300000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 242000\n",
      "learning_rate 0.000403\n",
      "mean reward (100 episodes) 261.181764\n",
      "max reward (100 episodes) 319.449183\n",
      "mean step (100 episodes) 344.950000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 243000\n",
      "learning_rate 0.000402\n",
      "mean reward (100 episodes) 260.515010\n",
      "max reward (100 episodes) 319.449183\n",
      "mean step (100 episodes) 356.110000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 244000\n",
      "learning_rate 0.000402\n",
      "mean reward (100 episodes) 258.562795\n",
      "max reward (100 episodes) 319.449183\n",
      "mean step (100 episodes) 356.160000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 245000\n",
      "learning_rate 0.000402\n",
      "mean reward (100 episodes) 257.472424\n",
      "max reward (100 episodes) 319.449183\n",
      "mean step (100 episodes) 357.890000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 246000\n",
      "learning_rate 0.000401\n",
      "mean reward (100 episodes) 257.417216\n",
      "max reward (100 episodes) 319.449183\n",
      "mean step (100 episodes) 363.070000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 247000\n",
      "learning_rate 0.000401\n",
      "mean reward (100 episodes) 257.544001\n",
      "max reward (100 episodes) 319.449183\n",
      "mean step (100 episodes) 354.890000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 248000\n",
      "learning_rate 0.000401\n",
      "mean reward (100 episodes) 256.941411\n",
      "max reward (100 episodes) 319.449183\n",
      "mean step (100 episodes) 364.090000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 249000\n",
      "learning_rate 0.000400\n",
      "mean reward (100 episodes) 258.560373\n",
      "max reward (100 episodes) 319.449183\n",
      "mean step (100 episodes) 365.850000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_250000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 250000\n",
      "learning_rate 0.000400\n",
      "mean reward (100 episodes) 259.389041\n",
      "max reward (100 episodes) 319.449183\n",
      "mean step (100 episodes) 355.470000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 251000\n",
      "learning_rate 0.000400\n",
      "mean reward (100 episodes) 259.499778\n",
      "max reward (100 episodes) 319.449183\n",
      "mean step (100 episodes) 356.520000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 252000\n",
      "learning_rate 0.000399\n",
      "mean reward (100 episodes) 259.624924\n",
      "max reward (100 episodes) 319.449183\n",
      "mean step (100 episodes) 356.440000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "timestep 253000\n",
      "learning_rate 0.000399\n",
      "mean reward (100 episodes) 258.277236\n",
      "max reward (100 episodes) 319.449183\n",
      "mean step (100 episodes) 349.910000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 254000\n",
      "learning_rate 0.000399\n",
      "mean reward (100 episodes) 257.961159\n",
      "max reward (100 episodes) 319.449183\n",
      "mean step (100 episodes) 354.080000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 255000\n",
      "learning_rate 0.000398\n",
      "mean reward (100 episodes) 257.859375\n",
      "max reward (100 episodes) 319.449183\n",
      "mean step (100 episodes) 346.820000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 256000\n",
      "learning_rate 0.000398\n",
      "mean reward (100 episodes) 256.785870\n",
      "max reward (100 episodes) 319.449183\n",
      "mean step (100 episodes) 346.030000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 257000\n",
      "learning_rate 0.000398\n",
      "mean reward (100 episodes) 254.233634\n",
      "max reward (100 episodes) 310.046059\n",
      "mean step (100 episodes) 354.760000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 258000\n",
      "learning_rate 0.000397\n",
      "mean reward (100 episodes) 253.975582\n",
      "max reward (100 episodes) 310.046059\n",
      "mean step (100 episodes) 352.220000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 259000\n",
      "learning_rate 0.000397\n",
      "mean reward (100 episodes) 253.749707\n",
      "max reward (100 episodes) 314.177990\n",
      "mean step (100 episodes) 353.270000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_260000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 260000\n",
      "learning_rate 0.000397\n",
      "mean reward (100 episodes) 250.574616\n",
      "max reward (100 episodes) 314.177990\n",
      "mean step (100 episodes) 368.050000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 261000\n",
      "learning_rate 0.000397\n",
      "mean reward (100 episodes) 251.325223\n",
      "max reward (100 episodes) 314.177990\n",
      "mean step (100 episodes) 359.980000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 262000\n",
      "learning_rate 0.000396\n",
      "mean reward (100 episodes) 252.439455\n",
      "max reward (100 episodes) 314.177990\n",
      "mean step (100 episodes) 359.790000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 263000\n",
      "learning_rate 0.000396\n",
      "mean reward (100 episodes) 251.873454\n",
      "max reward (100 episodes) 314.177990\n",
      "mean step (100 episodes) 358.520000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 264000\n",
      "learning_rate 0.000396\n",
      "mean reward (100 episodes) 254.566328\n",
      "max reward (100 episodes) 314.177990\n",
      "mean step (100 episodes) 351.090000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 265000\n",
      "learning_rate 0.000395\n",
      "mean reward (100 episodes) 253.714331\n",
      "max reward (100 episodes) 314.177990\n",
      "mean step (100 episodes) 358.370000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 266000\n",
      "learning_rate 0.000395\n",
      "mean reward (100 episodes) 253.951057\n",
      "max reward (100 episodes) 314.177990\n",
      "mean step (100 episodes) 351.230000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 267000\n",
      "learning_rate 0.000395\n",
      "mean reward (100 episodes) 254.841782\n",
      "max reward (100 episodes) 314.177990\n",
      "mean step (100 episodes) 353.950000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 268000\n",
      "learning_rate 0.000394\n",
      "mean reward (100 episodes) 252.871800\n",
      "max reward (100 episodes) 314.177990\n",
      "mean step (100 episodes) 356.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 269000\n",
      "learning_rate 0.000394\n",
      "mean reward (100 episodes) 252.224042\n",
      "max reward (100 episodes) 314.177990\n",
      "mean step (100 episodes) 350.010000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_270000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 270000\n",
      "learning_rate 0.000394\n",
      "mean reward (100 episodes) 252.202714\n",
      "max reward (100 episodes) 314.177990\n",
      "mean step (100 episodes) 349.220000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 271000\n",
      "learning_rate 0.000393\n",
      "mean reward (100 episodes) 251.862680\n",
      "max reward (100 episodes) 314.177990\n",
      "mean step (100 episodes) 353.550000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 272000\n",
      "learning_rate 0.000393\n",
      "mean reward (100 episodes) 250.773627\n",
      "max reward (100 episodes) 314.177990\n",
      "mean step (100 episodes) 356.080000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 273000\n",
      "learning_rate 0.000393\n",
      "mean reward (100 episodes) 253.037274\n",
      "max reward (100 episodes) 314.177990\n",
      "mean step (100 episodes) 358.450000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 274000\n",
      "learning_rate 0.000392\n",
      "mean reward (100 episodes) 252.567522\n",
      "max reward (100 episodes) 314.177990\n",
      "mean step (100 episodes) 345.820000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 275000\n",
      "learning_rate 0.000392\n",
      "mean reward (100 episodes) 253.548508\n",
      "max reward (100 episodes) 314.177990\n",
      "mean step (100 episodes) 342.100000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 276000\n",
      "learning_rate 0.000392\n",
      "mean reward (100 episodes) 254.197124\n",
      "max reward (100 episodes) 314.177990\n",
      "mean step (100 episodes) 331.280000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 277000\n",
      "learning_rate 0.000392\n",
      "mean reward (100 episodes) 255.710609\n",
      "max reward (100 episodes) 314.177990\n",
      "mean step (100 episodes) 323.230000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 278000\n",
      "learning_rate 0.000391\n",
      "mean reward (100 episodes) 254.215357\n",
      "max reward (100 episodes) 314.177990\n",
      "mean step (100 episodes) 330.550000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 279000\n",
      "learning_rate 0.000391\n",
      "mean reward (100 episodes) 250.058708\n",
      "max reward (100 episodes) 310.173086\n",
      "mean step (100 episodes) 340.860000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_280000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 280000\n",
      "learning_rate 0.000391\n",
      "mean reward (100 episodes) 252.268658\n",
      "max reward (100 episodes) 310.173086\n",
      "mean step (100 episodes) 333.270000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 281000\n",
      "learning_rate 0.000390\n",
      "mean reward (100 episodes) 249.731129\n",
      "max reward (100 episodes) 310.173086\n",
      "mean step (100 episodes) 353.930000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 282000\n",
      "learning_rate 0.000390\n",
      "mean reward (100 episodes) 249.247403\n",
      "max reward (100 episodes) 310.173086\n",
      "mean step (100 episodes) 352.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 283000\n",
      "learning_rate 0.000390\n",
      "mean reward (100 episodes) 250.001298\n",
      "max reward (100 episodes) 310.173086\n",
      "mean step (100 episodes) 343.440000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 284000\n",
      "learning_rate 0.000389\n",
      "mean reward (100 episodes) 249.982385\n",
      "max reward (100 episodes) 311.632523\n",
      "mean step (100 episodes) 338.290000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 285000\n",
      "learning_rate 0.000389\n",
      "mean reward (100 episodes) 251.167283\n",
      "max reward (100 episodes) 312.282160\n",
      "mean step (100 episodes) 329.070000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 286000\n",
      "learning_rate 0.000389\n",
      "mean reward (100 episodes) 247.925224\n",
      "max reward (100 episodes) 312.282160\n",
      "mean step (100 episodes) 344.560000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 287000\n",
      "learning_rate 0.000389\n",
      "mean reward (100 episodes) 245.601861\n",
      "max reward (100 episodes) 312.282160\n",
      "mean step (100 episodes) 357.200000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "timestep 288000\n",
      "learning_rate 0.000388\n",
      "mean reward (100 episodes) 245.308780\n",
      "max reward (100 episodes) 312.282160\n",
      "mean step (100 episodes) 365.030000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 289000\n",
      "learning_rate 0.000388\n",
      "mean reward (100 episodes) 245.806269\n",
      "max reward (100 episodes) 312.282160\n",
      "mean step (100 episodes) 365.950000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_290000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 290000\n",
      "learning_rate 0.000388\n",
      "mean reward (100 episodes) 240.985803\n",
      "max reward (100 episodes) 312.282160\n",
      "mean step (100 episodes) 386.150000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 291000\n",
      "learning_rate 0.000387\n",
      "mean reward (100 episodes) 242.278941\n",
      "max reward (100 episodes) 312.500983\n",
      "mean step (100 episodes) 381.630000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 292000\n",
      "learning_rate 0.000387\n",
      "mean reward (100 episodes) 242.579629\n",
      "max reward (100 episodes) 312.500983\n",
      "mean step (100 episodes) 369.860000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 293000\n",
      "learning_rate 0.000387\n",
      "mean reward (100 episodes) 241.635631\n",
      "max reward (100 episodes) 312.500983\n",
      "mean step (100 episodes) 367.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 294000\n",
      "learning_rate 0.000386\n",
      "mean reward (100 episodes) 243.190858\n",
      "max reward (100 episodes) 312.500983\n",
      "mean step (100 episodes) 380.430000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 295000\n",
      "learning_rate 0.000386\n",
      "mean reward (100 episodes) 242.632712\n",
      "max reward (100 episodes) 312.500983\n",
      "mean step (100 episodes) 377.250000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 296000\n",
      "learning_rate 0.000386\n",
      "mean reward (100 episodes) 244.140730\n",
      "max reward (100 episodes) 315.072567\n",
      "mean step (100 episodes) 377.540000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 297000\n",
      "learning_rate 0.000386\n",
      "mean reward (100 episodes) 242.617150\n",
      "max reward (100 episodes) 315.072567\n",
      "mean step (100 episodes) 375.050000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 298000\n",
      "learning_rate 0.000385\n",
      "mean reward (100 episodes) 243.631674\n",
      "max reward (100 episodes) 315.072567\n",
      "mean step (100 episodes) 370.350000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 299000\n",
      "learning_rate 0.000385\n",
      "mean reward (100 episodes) 250.664866\n",
      "max reward (100 episodes) 315.072567\n",
      "mean step (100 episodes) 344.030000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_300000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 300000\n",
      "learning_rate 0.000385\n",
      "mean reward (100 episodes) 248.942887\n",
      "max reward (100 episodes) 315.072567\n",
      "mean step (100 episodes) 354.770000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 301000\n",
      "learning_rate 0.000384\n",
      "mean reward (100 episodes) 249.601435\n",
      "max reward (100 episodes) 320.784300\n",
      "mean step (100 episodes) 340.010000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 302000\n",
      "learning_rate 0.000384\n",
      "mean reward (100 episodes) 247.907799\n",
      "max reward (100 episodes) 320.784300\n",
      "mean step (100 episodes) 336.400000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 303000\n",
      "learning_rate 0.000384\n",
      "mean reward (100 episodes) 248.777981\n",
      "max reward (100 episodes) 320.784300\n",
      "mean step (100 episodes) 335.590000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 304000\n",
      "learning_rate 0.000383\n",
      "mean reward (100 episodes) 247.583109\n",
      "max reward (100 episodes) 320.784300\n",
      "mean step (100 episodes) 338.490000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 305000\n",
      "learning_rate 0.000383\n",
      "mean reward (100 episodes) 247.913504\n",
      "max reward (100 episodes) 320.784300\n",
      "mean step (100 episodes) 339.170000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 306000\n",
      "learning_rate 0.000383\n",
      "mean reward (100 episodes) 252.191501\n",
      "max reward (100 episodes) 320.784300\n",
      "mean step (100 episodes) 321.550000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 307000\n",
      "learning_rate 0.000383\n",
      "mean reward (100 episodes) 247.387235\n",
      "max reward (100 episodes) 320.784300\n",
      "mean step (100 episodes) 319.250000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 308000\n",
      "learning_rate 0.000382\n",
      "mean reward (100 episodes) 247.840214\n",
      "max reward (100 episodes) 320.784300\n",
      "mean step (100 episodes) 300.650000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 309000\n",
      "learning_rate 0.000382\n",
      "mean reward (100 episodes) 242.842822\n",
      "max reward (100 episodes) 320.784300\n",
      "mean step (100 episodes) 295.450000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_310000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 310000\n",
      "learning_rate 0.000382\n",
      "mean reward (100 episodes) 244.177781\n",
      "max reward (100 episodes) 320.784300\n",
      "mean step (100 episodes) 287.160000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 311000\n",
      "learning_rate 0.000381\n",
      "mean reward (100 episodes) 242.191641\n",
      "max reward (100 episodes) 320.784300\n",
      "mean step (100 episodes) 295.710000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 312000\n",
      "learning_rate 0.000381\n",
      "mean reward (100 episodes) 243.574790\n",
      "max reward (100 episodes) 320.784300\n",
      "mean step (100 episodes) 303.580000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 313000\n",
      "learning_rate 0.000381\n",
      "mean reward (100 episodes) 245.157543\n",
      "max reward (100 episodes) 320.784300\n",
      "mean step (100 episodes) 297.150000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 314000\n",
      "learning_rate 0.000381\n",
      "mean reward (100 episodes) 244.131733\n",
      "max reward (100 episodes) 320.784300\n",
      "mean step (100 episodes) 296.540000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 315000\n",
      "learning_rate 0.000380\n",
      "mean reward (100 episodes) 245.697198\n",
      "max reward (100 episodes) 320.784300\n",
      "mean step (100 episodes) 293.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 316000\n",
      "learning_rate 0.000380\n",
      "mean reward (100 episodes) 244.017308\n",
      "max reward (100 episodes) 320.784300\n",
      "mean step (100 episodes) 293.560000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 317000\n",
      "learning_rate 0.000380\n",
      "mean reward (100 episodes) 245.951701\n",
      "max reward (100 episodes) 320.784300\n",
      "mean step (100 episodes) 296.480000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 318000\n",
      "learning_rate 0.000379\n",
      "mean reward (100 episodes) 245.149091\n",
      "max reward (100 episodes) 320.784300\n",
      "mean step (100 episodes) 300.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 319000\n",
      "learning_rate 0.000379\n",
      "mean reward (100 episodes) 242.219336\n",
      "max reward (100 episodes) 320.784300\n",
      "mean step (100 episodes) 299.800000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_320000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 320000\n",
      "learning_rate 0.000379\n",
      "mean reward (100 episodes) 240.702771\n",
      "max reward (100 episodes) 320.784300\n",
      "mean step (100 episodes) 287.890000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 321000\n",
      "learning_rate 0.000379\n",
      "mean reward (100 episodes) 241.102608\n",
      "max reward (100 episodes) 318.978988\n",
      "mean step (100 episodes) 288.250000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "timestep 322000\n",
      "learning_rate 0.000378\n",
      "mean reward (100 episodes) 236.915716\n",
      "max reward (100 episodes) 318.978988\n",
      "mean step (100 episodes) 287.160000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 323000\n",
      "learning_rate 0.000378\n",
      "mean reward (100 episodes) 234.430821\n",
      "max reward (100 episodes) 314.015635\n",
      "mean step (100 episodes) 288.670000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 324000\n",
      "learning_rate 0.000378\n",
      "mean reward (100 episodes) 236.400838\n",
      "max reward (100 episodes) 314.015635\n",
      "mean step (100 episodes) 281.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 325000\n",
      "learning_rate 0.000377\n",
      "mean reward (100 episodes) 233.449064\n",
      "max reward (100 episodes) 314.015635\n",
      "mean step (100 episodes) 291.110000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 326000\n",
      "learning_rate 0.000377\n",
      "mean reward (100 episodes) 231.445868\n",
      "max reward (100 episodes) 314.015635\n",
      "mean step (100 episodes) 297.030000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 327000\n",
      "learning_rate 0.000377\n",
      "mean reward (100 episodes) 237.754069\n",
      "max reward (100 episodes) 314.015635\n",
      "mean step (100 episodes) 291.440000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 328000\n",
      "learning_rate 0.000377\n",
      "mean reward (100 episodes) 240.035855\n",
      "max reward (100 episodes) 314.015635\n",
      "mean step (100 episodes) 296.400000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 329000\n",
      "learning_rate 0.000376\n",
      "mean reward (100 episodes) 244.708982\n",
      "max reward (100 episodes) 314.015635\n",
      "mean step (100 episodes) 298.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_330000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 330000\n",
      "learning_rate 0.000376\n",
      "mean reward (100 episodes) 247.694755\n",
      "max reward (100 episodes) 314.015635\n",
      "mean step (100 episodes) 297.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 331000\n",
      "learning_rate 0.000376\n",
      "mean reward (100 episodes) 242.557836\n",
      "max reward (100 episodes) 314.015635\n",
      "mean step (100 episodes) 289.940000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 332000\n",
      "learning_rate 0.000375\n",
      "mean reward (100 episodes) 237.733832\n",
      "max reward (100 episodes) 305.775728\n",
      "mean step (100 episodes) 282.760000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 333000\n",
      "learning_rate 0.000375\n",
      "mean reward (100 episodes) 235.119596\n",
      "max reward (100 episodes) 305.775728\n",
      "mean step (100 episodes) 298.990000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 334000\n",
      "learning_rate 0.000375\n",
      "mean reward (100 episodes) 234.884659\n",
      "max reward (100 episodes) 305.775728\n",
      "mean step (100 episodes) 296.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 335000\n",
      "learning_rate 0.000375\n",
      "mean reward (100 episodes) 226.074915\n",
      "max reward (100 episodes) 305.775728\n",
      "mean step (100 episodes) 296.550000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 336000\n",
      "learning_rate 0.000374\n",
      "mean reward (100 episodes) 222.803752\n",
      "max reward (100 episodes) 305.775728\n",
      "mean step (100 episodes) 306.820000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 337000\n",
      "learning_rate 0.000374\n",
      "mean reward (100 episodes) 221.365179\n",
      "max reward (100 episodes) 305.775728\n",
      "mean step (100 episodes) 308.830000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 338000\n",
      "learning_rate 0.000374\n",
      "mean reward (100 episodes) 222.314225\n",
      "max reward (100 episodes) 305.775728\n",
      "mean step (100 episodes) 305.680000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 339000\n",
      "learning_rate 0.000373\n",
      "mean reward (100 episodes) 215.899015\n",
      "max reward (100 episodes) 305.775728\n",
      "mean step (100 episodes) 314.140000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_340000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 340000\n",
      "learning_rate 0.000373\n",
      "mean reward (100 episodes) 219.013003\n",
      "max reward (100 episodes) 305.775728\n",
      "mean step (100 episodes) 307.760000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 341000\n",
      "learning_rate 0.000373\n",
      "mean reward (100 episodes) 220.283809\n",
      "max reward (100 episodes) 305.775728\n",
      "mean step (100 episodes) 312.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 342000\n",
      "learning_rate 0.000373\n",
      "mean reward (100 episodes) 222.911286\n",
      "max reward (100 episodes) 305.775728\n",
      "mean step (100 episodes) 326.030000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 343000\n",
      "learning_rate 0.000372\n",
      "mean reward (100 episodes) 222.149626\n",
      "max reward (100 episodes) 305.775728\n",
      "mean step (100 episodes) 326.130000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 344000\n",
      "learning_rate 0.000372\n",
      "mean reward (100 episodes) 221.770520\n",
      "max reward (100 episodes) 304.888035\n",
      "mean step (100 episodes) 327.950000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 345000\n",
      "learning_rate 0.000372\n",
      "mean reward (100 episodes) 222.212507\n",
      "max reward (100 episodes) 304.888035\n",
      "mean step (100 episodes) 330.640000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 346000\n",
      "learning_rate 0.000371\n",
      "mean reward (100 episodes) 223.975675\n",
      "max reward (100 episodes) 304.888035\n",
      "mean step (100 episodes) 327.450000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 347000\n",
      "learning_rate 0.000371\n",
      "mean reward (100 episodes) 222.735232\n",
      "max reward (100 episodes) 304.888035\n",
      "mean step (100 episodes) 329.530000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 348000\n",
      "learning_rate 0.000371\n",
      "mean reward (100 episodes) 222.102442\n",
      "max reward (100 episodes) 304.888035\n",
      "mean step (100 episodes) 325.460000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 349000\n",
      "learning_rate 0.000371\n",
      "mean reward (100 episodes) 221.271347\n",
      "max reward (100 episodes) 304.888035\n",
      "mean step (100 episodes) 329.430000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_350000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 350000\n",
      "learning_rate 0.000370\n",
      "mean reward (100 episodes) 221.277627\n",
      "max reward (100 episodes) 304.888035\n",
      "mean step (100 episodes) 321.350000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 351000\n",
      "learning_rate 0.000370\n",
      "mean reward (100 episodes) 226.816711\n",
      "max reward (100 episodes) 304.888035\n",
      "mean step (100 episodes) 325.340000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 352000\n",
      "learning_rate 0.000370\n",
      "mean reward (100 episodes) 219.403487\n",
      "max reward (100 episodes) 304.888035\n",
      "mean step (100 episodes) 334.350000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 353000\n",
      "learning_rate 0.000370\n",
      "mean reward (100 episodes) 219.651980\n",
      "max reward (100 episodes) 309.124300\n",
      "mean step (100 episodes) 323.180000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 354000\n",
      "learning_rate 0.000369\n",
      "mean reward (100 episodes) 217.824965\n",
      "max reward (100 episodes) 309.124300\n",
      "mean step (100 episodes) 315.410000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 355000\n",
      "learning_rate 0.000369\n",
      "mean reward (100 episodes) 225.711962\n",
      "max reward (100 episodes) 309.124300\n",
      "mean step (100 episodes) 318.130000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 356000\n",
      "learning_rate 0.000369\n",
      "mean reward (100 episodes) 228.171922\n",
      "max reward (100 episodes) 309.124300\n",
      "mean step (100 episodes) 311.230000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "timestep 357000\n",
      "learning_rate 0.000368\n",
      "mean reward (100 episodes) 228.184716\n",
      "max reward (100 episodes) 309.124300\n",
      "mean step (100 episodes) 316.340000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 358000\n",
      "learning_rate 0.000368\n",
      "mean reward (100 episodes) 226.739945\n",
      "max reward (100 episodes) 309.124300\n",
      "mean step (100 episodes) 319.050000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 359000\n",
      "learning_rate 0.000368\n",
      "mean reward (100 episodes) 233.243603\n",
      "max reward (100 episodes) 309.124300\n",
      "mean step (100 episodes) 326.200000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_360000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 360000\n",
      "learning_rate 0.000368\n",
      "mean reward (100 episodes) 228.374197\n",
      "max reward (100 episodes) 309.124300\n",
      "mean step (100 episodes) 328.830000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 361000\n",
      "learning_rate 0.000367\n",
      "mean reward (100 episodes) 222.237209\n",
      "max reward (100 episodes) 309.124300\n",
      "mean step (100 episodes) 316.500000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 362000\n",
      "learning_rate 0.000367\n",
      "mean reward (100 episodes) 223.229892\n",
      "max reward (100 episodes) 309.124300\n",
      "mean step (100 episodes) 317.090000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 363000\n",
      "learning_rate 0.000367\n",
      "mean reward (100 episodes) 224.928006\n",
      "max reward (100 episodes) 309.124300\n",
      "mean step (100 episodes) 320.060000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 364000\n",
      "learning_rate 0.000367\n",
      "mean reward (100 episodes) 224.850974\n",
      "max reward (100 episodes) 309.124300\n",
      "mean step (100 episodes) 319.720000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 365000\n",
      "learning_rate 0.000366\n",
      "mean reward (100 episodes) 225.953776\n",
      "max reward (100 episodes) 309.124300\n",
      "mean step (100 episodes) 318.420000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 366000\n",
      "learning_rate 0.000366\n",
      "mean reward (100 episodes) 226.263249\n",
      "max reward (100 episodes) 309.124300\n",
      "mean step (100 episodes) 315.740000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 367000\n",
      "learning_rate 0.000366\n",
      "mean reward (100 episodes) 227.573577\n",
      "max reward (100 episodes) 309.124300\n",
      "mean step (100 episodes) 307.470000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 368000\n",
      "learning_rate 0.000365\n",
      "mean reward (100 episodes) 227.024507\n",
      "max reward (100 episodes) 309.124300\n",
      "mean step (100 episodes) 319.610000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 369000\n",
      "learning_rate 0.000365\n",
      "mean reward (100 episodes) 227.991085\n",
      "max reward (100 episodes) 309.124300\n",
      "mean step (100 episodes) 316.200000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_370000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 370000\n",
      "learning_rate 0.000365\n",
      "mean reward (100 episodes) 228.381998\n",
      "max reward (100 episodes) 309.124300\n",
      "mean step (100 episodes) 315.170000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 371000\n",
      "learning_rate 0.000365\n",
      "mean reward (100 episodes) 226.564726\n",
      "max reward (100 episodes) 309.124300\n",
      "mean step (100 episodes) 327.290000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 372000\n",
      "learning_rate 0.000364\n",
      "mean reward (100 episodes) 237.462816\n",
      "max reward (100 episodes) 309.124300\n",
      "mean step (100 episodes) 327.480000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 373000\n",
      "learning_rate 0.000364\n",
      "mean reward (100 episodes) 239.373197\n",
      "max reward (100 episodes) 308.923187\n",
      "mean step (100 episodes) 322.310000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 374000\n",
      "learning_rate 0.000364\n",
      "mean reward (100 episodes) 240.783357\n",
      "max reward (100 episodes) 311.209672\n",
      "mean step (100 episodes) 321.400000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 375000\n",
      "learning_rate 0.000364\n",
      "mean reward (100 episodes) 239.602249\n",
      "max reward (100 episodes) 311.209672\n",
      "mean step (100 episodes) 328.580000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 376000\n",
      "learning_rate 0.000363\n",
      "mean reward (100 episodes) 237.813813\n",
      "max reward (100 episodes) 311.209672\n",
      "mean step (100 episodes) 331.200000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 377000\n",
      "learning_rate 0.000363\n",
      "mean reward (100 episodes) 226.622962\n",
      "max reward (100 episodes) 311.209672\n",
      "mean step (100 episodes) 318.200000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 378000\n",
      "learning_rate 0.000363\n",
      "mean reward (100 episodes) 223.978433\n",
      "max reward (100 episodes) 311.209672\n",
      "mean step (100 episodes) 311.500000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 379000\n",
      "learning_rate 0.000363\n",
      "mean reward (100 episodes) 220.084270\n",
      "max reward (100 episodes) 311.209672\n",
      "mean step (100 episodes) 293.910000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_380000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 380000\n",
      "learning_rate 0.000362\n",
      "mean reward (100 episodes) 215.261763\n",
      "max reward (100 episodes) 311.209672\n",
      "mean step (100 episodes) 287.740000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 381000\n",
      "learning_rate 0.000362\n",
      "mean reward (100 episodes) 219.775313\n",
      "max reward (100 episodes) 313.973247\n",
      "mean step (100 episodes) 287.320000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 382000\n",
      "learning_rate 0.000362\n",
      "mean reward (100 episodes) 213.933914\n",
      "max reward (100 episodes) 313.973247\n",
      "mean step (100 episodes) 281.770000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 383000\n",
      "learning_rate 0.000362\n",
      "mean reward (100 episodes) 209.952638\n",
      "max reward (100 episodes) 313.973247\n",
      "mean step (100 episodes) 277.500000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 384000\n",
      "learning_rate 0.000361\n",
      "mean reward (100 episodes) 203.488033\n",
      "max reward (100 episodes) 313.973247\n",
      "mean step (100 episodes) 273.670000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 385000\n",
      "learning_rate 0.000361\n",
      "mean reward (100 episodes) 193.644167\n",
      "max reward (100 episodes) 313.973247\n",
      "mean step (100 episodes) 258.720000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 386000\n",
      "learning_rate 0.000361\n",
      "mean reward (100 episodes) 194.036718\n",
      "max reward (100 episodes) 313.973247\n",
      "mean step (100 episodes) 258.750000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 387000\n",
      "learning_rate 0.000360\n",
      "mean reward (100 episodes) 187.807578\n",
      "max reward (100 episodes) 313.973247\n",
      "mean step (100 episodes) 254.040000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 388000\n",
      "learning_rate 0.000360\n",
      "mean reward (100 episodes) 183.728032\n",
      "max reward (100 episodes) 313.973247\n",
      "mean step (100 episodes) 241.590000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 389000\n",
      "learning_rate 0.000360\n",
      "mean reward (100 episodes) 173.558675\n",
      "max reward (100 episodes) 313.973247\n",
      "mean step (100 episodes) 245.760000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_390000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 390000\n",
      "learning_rate 0.000360\n",
      "mean reward (100 episodes) 169.749783\n",
      "max reward (100 episodes) 313.973247\n",
      "mean step (100 episodes) 239.820000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "timestep 391000\n",
      "learning_rate 0.000359\n",
      "mean reward (100 episodes) 161.124453\n",
      "max reward (100 episodes) 313.973247\n",
      "mean step (100 episodes) 219.590000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 392000\n",
      "learning_rate 0.000359\n",
      "mean reward (100 episodes) 155.327846\n",
      "max reward (100 episodes) 313.973247\n",
      "mean step (100 episodes) 215.410000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 393000\n",
      "learning_rate 0.000359\n",
      "mean reward (100 episodes) 144.323256\n",
      "max reward (100 episodes) 313.973247\n",
      "mean step (100 episodes) 210.480000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 394000\n",
      "learning_rate 0.000359\n",
      "mean reward (100 episodes) 136.760530\n",
      "max reward (100 episodes) 313.973247\n",
      "mean step (100 episodes) 207.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 395000\n",
      "learning_rate 0.000358\n",
      "mean reward (100 episodes) 129.985258\n",
      "max reward (100 episodes) 316.676397\n",
      "mean step (100 episodes) 193.760000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 396000\n",
      "learning_rate 0.000358\n",
      "mean reward (100 episodes) 125.343781\n",
      "max reward (100 episodes) 316.676397\n",
      "mean step (100 episodes) 192.410000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 397000\n",
      "learning_rate 0.000358\n",
      "mean reward (100 episodes) 128.463902\n",
      "max reward (100 episodes) 316.676397\n",
      "mean step (100 episodes) 193.920000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 398000\n",
      "learning_rate 0.000358\n",
      "mean reward (100 episodes) 123.126364\n",
      "max reward (100 episodes) 316.676397\n",
      "mean step (100 episodes) 193.750000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 399000\n",
      "learning_rate 0.000357\n",
      "mean reward (100 episodes) 118.638744\n",
      "max reward (100 episodes) 316.676397\n",
      "mean step (100 episodes) 199.610000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_400000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 400000\n",
      "learning_rate 0.000357\n",
      "mean reward (100 episodes) 117.380428\n",
      "max reward (100 episodes) 316.676397\n",
      "mean step (100 episodes) 198.890000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 401000\n",
      "learning_rate 0.000357\n",
      "mean reward (100 episodes) 110.767184\n",
      "max reward (100 episodes) 316.676397\n",
      "mean step (100 episodes) 195.100000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 402000\n",
      "learning_rate 0.000357\n",
      "mean reward (100 episodes) 114.812100\n",
      "max reward (100 episodes) 316.676397\n",
      "mean step (100 episodes) 188.570000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 403000\n",
      "learning_rate 0.000356\n",
      "mean reward (100 episodes) 112.275227\n",
      "max reward (100 episodes) 316.676397\n",
      "mean step (100 episodes) 194.700000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 404000\n",
      "learning_rate 0.000356\n",
      "mean reward (100 episodes) 106.736244\n",
      "max reward (100 episodes) 316.676397\n",
      "mean step (100 episodes) 192.680000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 405000\n",
      "learning_rate 0.000356\n",
      "mean reward (100 episodes) 114.614125\n",
      "max reward (100 episodes) 316.676397\n",
      "mean step (100 episodes) 207.450000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 406000\n",
      "learning_rate 0.000356\n",
      "mean reward (100 episodes) 110.513238\n",
      "max reward (100 episodes) 316.676397\n",
      "mean step (100 episodes) 214.110000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 407000\n",
      "learning_rate 0.000355\n",
      "mean reward (100 episodes) 108.800496\n",
      "max reward (100 episodes) 316.676397\n",
      "mean step (100 episodes) 214.020000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 408000\n",
      "learning_rate 0.000355\n",
      "mean reward (100 episodes) 111.904661\n",
      "max reward (100 episodes) 316.676397\n",
      "mean step (100 episodes) 213.590000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 409000\n",
      "learning_rate 0.000355\n",
      "mean reward (100 episodes) 118.481174\n",
      "max reward (100 episodes) 316.676397\n",
      "mean step (100 episodes) 214.900000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_410000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 410000\n",
      "learning_rate 0.000355\n",
      "mean reward (100 episodes) 120.370753\n",
      "max reward (100 episodes) 316.676397\n",
      "mean step (100 episodes) 216.790000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 411000\n",
      "learning_rate 0.000354\n",
      "mean reward (100 episodes) 129.528896\n",
      "max reward (100 episodes) 316.676397\n",
      "mean step (100 episodes) 218.910000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 412000\n",
      "learning_rate 0.000354\n",
      "mean reward (100 episodes) 134.839540\n",
      "max reward (100 episodes) 316.676397\n",
      "mean step (100 episodes) 220.180000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 413000\n",
      "learning_rate 0.000354\n",
      "mean reward (100 episodes) 137.771987\n",
      "max reward (100 episodes) 316.676397\n",
      "mean step (100 episodes) 226.270000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 414000\n",
      "learning_rate 0.000354\n",
      "mean reward (100 episodes) 143.866348\n",
      "max reward (100 episodes) 316.676397\n",
      "mean step (100 episodes) 236.500000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 415000\n",
      "learning_rate 0.000353\n",
      "mean reward (100 episodes) 149.360028\n",
      "max reward (100 episodes) 315.363898\n",
      "mean step (100 episodes) 247.370000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 416000\n",
      "learning_rate 0.000353\n",
      "mean reward (100 episodes) 148.766138\n",
      "max reward (100 episodes) 315.363898\n",
      "mean step (100 episodes) 251.310000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 417000\n",
      "learning_rate 0.000353\n",
      "mean reward (100 episodes) 147.484290\n",
      "max reward (100 episodes) 315.363898\n",
      "mean step (100 episodes) 259.860000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 418000\n",
      "learning_rate 0.000353\n",
      "mean reward (100 episodes) 150.230513\n",
      "max reward (100 episodes) 315.363898\n",
      "mean step (100 episodes) 263.080000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 419000\n",
      "learning_rate 0.000352\n",
      "mean reward (100 episodes) 155.663684\n",
      "max reward (100 episodes) 315.363898\n",
      "mean step (100 episodes) 259.090000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_420000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 420000\n",
      "learning_rate 0.000352\n",
      "mean reward (100 episodes) 159.881074\n",
      "max reward (100 episodes) 315.363898\n",
      "mean step (100 episodes) 261.230000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 421000\n",
      "learning_rate 0.000352\n",
      "mean reward (100 episodes) 169.657892\n",
      "max reward (100 episodes) 315.363898\n",
      "mean step (100 episodes) 273.900000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 422000\n",
      "learning_rate 0.000352\n",
      "mean reward (100 episodes) 174.159717\n",
      "max reward (100 episodes) 315.363898\n",
      "mean step (100 episodes) 274.430000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 423000\n",
      "learning_rate 0.000351\n",
      "mean reward (100 episodes) 176.403101\n",
      "max reward (100 episodes) 315.363898\n",
      "mean step (100 episodes) 271.890000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 424000\n",
      "learning_rate 0.000351\n",
      "mean reward (100 episodes) 186.731829\n",
      "max reward (100 episodes) 315.363898\n",
      "mean step (100 episodes) 275.040000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 425000\n",
      "learning_rate 0.000351\n",
      "mean reward (100 episodes) 190.563478\n",
      "max reward (100 episodes) 315.363898\n",
      "mean step (100 episodes) 263.850000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "timestep 426000\n",
      "learning_rate 0.000351\n",
      "mean reward (100 episodes) 187.319568\n",
      "max reward (100 episodes) 315.363898\n",
      "mean step (100 episodes) 254.950000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 427000\n",
      "learning_rate 0.000350\n",
      "mean reward (100 episodes) 194.710146\n",
      "max reward (100 episodes) 315.363898\n",
      "mean step (100 episodes) 270.310000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 428000\n",
      "learning_rate 0.000350\n",
      "mean reward (100 episodes) 196.022051\n",
      "max reward (100 episodes) 315.363898\n",
      "mean step (100 episodes) 280.370000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 429000\n",
      "learning_rate 0.000350\n",
      "mean reward (100 episodes) 199.333047\n",
      "max reward (100 episodes) 315.363898\n",
      "mean step (100 episodes) 276.820000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_430000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 430000\n",
      "learning_rate 0.000350\n",
      "mean reward (100 episodes) 200.214993\n",
      "max reward (100 episodes) 315.363898\n",
      "mean step (100 episodes) 285.010000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 431000\n",
      "learning_rate 0.000349\n",
      "mean reward (100 episodes) 199.094107\n",
      "max reward (100 episodes) 315.363898\n",
      "mean step (100 episodes) 297.170000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 432000\n",
      "learning_rate 0.000349\n",
      "mean reward (100 episodes) 197.832757\n",
      "max reward (100 episodes) 314.568175\n",
      "mean step (100 episodes) 314.450000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 433000\n",
      "learning_rate 0.000349\n",
      "mean reward (100 episodes) 196.206935\n",
      "max reward (100 episodes) 314.568175\n",
      "mean step (100 episodes) 321.230000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 434000\n",
      "learning_rate 0.000349\n",
      "mean reward (100 episodes) 199.514503\n",
      "max reward (100 episodes) 314.568175\n",
      "mean step (100 episodes) 316.890000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 435000\n",
      "learning_rate 0.000348\n",
      "mean reward (100 episodes) 199.723187\n",
      "max reward (100 episodes) 314.568175\n",
      "mean step (100 episodes) 310.690000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 436000\n",
      "learning_rate 0.000348\n",
      "mean reward (100 episodes) 204.593720\n",
      "max reward (100 episodes) 314.568175\n",
      "mean step (100 episodes) 300.600000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 437000\n",
      "learning_rate 0.000348\n",
      "mean reward (100 episodes) 211.879640\n",
      "max reward (100 episodes) 314.568175\n",
      "mean step (100 episodes) 312.640000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 438000\n",
      "learning_rate 0.000348\n",
      "mean reward (100 episodes) 205.247358\n",
      "max reward (100 episodes) 314.568175\n",
      "mean step (100 episodes) 305.020000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 439000\n",
      "learning_rate 0.000347\n",
      "mean reward (100 episodes) 205.097008\n",
      "max reward (100 episodes) 314.568175\n",
      "mean step (100 episodes) 305.020000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_440000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 440000\n",
      "learning_rate 0.000347\n",
      "mean reward (100 episodes) 212.543876\n",
      "max reward (100 episodes) 320.600348\n",
      "mean step (100 episodes) 313.250000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 441000\n",
      "learning_rate 0.000347\n",
      "mean reward (100 episodes) 211.292869\n",
      "max reward (100 episodes) 320.600348\n",
      "mean step (100 episodes) 312.540000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 442000\n",
      "learning_rate 0.000347\n",
      "mean reward (100 episodes) 208.954107\n",
      "max reward (100 episodes) 320.600348\n",
      "mean step (100 episodes) 316.070000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 443000\n",
      "learning_rate 0.000347\n",
      "mean reward (100 episodes) 214.499429\n",
      "max reward (100 episodes) 320.600348\n",
      "mean step (100 episodes) 314.340000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 444000\n",
      "learning_rate 0.000346\n",
      "mean reward (100 episodes) 214.649861\n",
      "max reward (100 episodes) 320.600348\n",
      "mean step (100 episodes) 323.930000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 445000\n",
      "learning_rate 0.000346\n",
      "mean reward (100 episodes) 211.612863\n",
      "max reward (100 episodes) 320.600348\n",
      "mean step (100 episodes) 339.800000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 446000\n",
      "learning_rate 0.000346\n",
      "mean reward (100 episodes) 218.429037\n",
      "max reward (100 episodes) 320.600348\n",
      "mean step (100 episodes) 341.780000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 447000\n",
      "learning_rate 0.000346\n",
      "mean reward (100 episodes) 219.877338\n",
      "max reward (100 episodes) 320.600348\n",
      "mean step (100 episodes) 331.490000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 448000\n",
      "learning_rate 0.000345\n",
      "mean reward (100 episodes) 219.931998\n",
      "max reward (100 episodes) 320.600348\n",
      "mean step (100 episodes) 328.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 449000\n",
      "learning_rate 0.000345\n",
      "mean reward (100 episodes) 217.900735\n",
      "max reward (100 episodes) 320.600348\n",
      "mean step (100 episodes) 338.170000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_450000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 450000\n",
      "learning_rate 0.000345\n",
      "mean reward (100 episodes) 217.899343\n",
      "max reward (100 episodes) 320.600348\n",
      "mean step (100 episodes) 336.320000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 451000\n",
      "learning_rate 0.000345\n",
      "mean reward (100 episodes) 219.832408\n",
      "max reward (100 episodes) 320.600348\n",
      "mean step (100 episodes) 330.890000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 452000\n",
      "learning_rate 0.000344\n",
      "mean reward (100 episodes) 213.462021\n",
      "max reward (100 episodes) 320.600348\n",
      "mean step (100 episodes) 307.130000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 453000\n",
      "learning_rate 0.000344\n",
      "mean reward (100 episodes) 223.530778\n",
      "max reward (100 episodes) 320.600348\n",
      "mean step (100 episodes) 298.920000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 454000\n",
      "learning_rate 0.000344\n",
      "mean reward (100 episodes) 219.861091\n",
      "max reward (100 episodes) 320.600348\n",
      "mean step (100 episodes) 305.570000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 455000\n",
      "learning_rate 0.000344\n",
      "mean reward (100 episodes) 221.018070\n",
      "max reward (100 episodes) 320.600348\n",
      "mean step (100 episodes) 320.430000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 456000\n",
      "learning_rate 0.000343\n",
      "mean reward (100 episodes) 224.202110\n",
      "max reward (100 episodes) 320.600348\n",
      "mean step (100 episodes) 323.470000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 457000\n",
      "learning_rate 0.000343\n",
      "mean reward (100 episodes) 217.407378\n",
      "max reward (100 episodes) 320.600348\n",
      "mean step (100 episodes) 304.390000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 458000\n",
      "learning_rate 0.000343\n",
      "mean reward (100 episodes) 229.549589\n",
      "max reward (100 episodes) 320.600348\n",
      "mean step (100 episodes) 315.330000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 459000\n",
      "learning_rate 0.000343\n",
      "mean reward (100 episodes) 232.890554\n",
      "max reward (100 episodes) 320.600348\n",
      "mean step (100 episodes) 314.590000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_460000.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "timestep 460000\n",
      "learning_rate 0.000342\n",
      "mean reward (100 episodes) 232.421454\n",
      "max reward (100 episodes) 318.740727\n",
      "mean step (100 episodes) 311.450000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 461000\n",
      "learning_rate 0.000342\n",
      "mean reward (100 episodes) 232.227894\n",
      "max reward (100 episodes) 308.222590\n",
      "mean step (100 episodes) 309.740000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 462000\n",
      "learning_rate 0.000342\n",
      "mean reward (100 episodes) 234.873455\n",
      "max reward (100 episodes) 308.222590\n",
      "mean step (100 episodes) 310.710000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 463000\n",
      "learning_rate 0.000342\n",
      "mean reward (100 episodes) 233.629252\n",
      "max reward (100 episodes) 308.222590\n",
      "mean step (100 episodes) 319.720000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 464000\n",
      "learning_rate 0.000342\n",
      "mean reward (100 episodes) 233.203433\n",
      "max reward (100 episodes) 308.222590\n",
      "mean step (100 episodes) 310.280000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 465000\n",
      "learning_rate 0.000341\n",
      "mean reward (100 episodes) 229.472638\n",
      "max reward (100 episodes) 308.222590\n",
      "mean step (100 episodes) 300.930000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 466000\n",
      "learning_rate 0.000341\n",
      "mean reward (100 episodes) 227.635351\n",
      "max reward (100 episodes) 308.222590\n",
      "mean step (100 episodes) 318.920000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 467000\n",
      "learning_rate 0.000341\n",
      "mean reward (100 episodes) 225.886833\n",
      "max reward (100 episodes) 313.244530\n",
      "mean step (100 episodes) 331.890000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 468000\n",
      "learning_rate 0.000341\n",
      "mean reward (100 episodes) 222.856928\n",
      "max reward (100 episodes) 313.244530\n",
      "mean step (100 episodes) 335.010000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 469000\n",
      "learning_rate 0.000340\n",
      "mean reward (100 episodes) 220.493662\n",
      "max reward (100 episodes) 313.244530\n",
      "mean step (100 episodes) 338.560000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_470000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 470000\n",
      "learning_rate 0.000340\n",
      "mean reward (100 episodes) 216.523181\n",
      "max reward (100 episodes) 313.244530\n",
      "mean step (100 episodes) 337.850000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 471000\n",
      "learning_rate 0.000340\n",
      "mean reward (100 episodes) 217.144269\n",
      "max reward (100 episodes) 318.589769\n",
      "mean step (100 episodes) 339.900000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 472000\n",
      "learning_rate 0.000340\n",
      "mean reward (100 episodes) 226.286308\n",
      "max reward (100 episodes) 318.589769\n",
      "mean step (100 episodes) 344.450000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 473000\n",
      "learning_rate 0.000339\n",
      "mean reward (100 episodes) 224.252220\n",
      "max reward (100 episodes) 318.589769\n",
      "mean step (100 episodes) 344.530000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 474000\n",
      "learning_rate 0.000339\n",
      "mean reward (100 episodes) 222.930637\n",
      "max reward (100 episodes) 318.589769\n",
      "mean step (100 episodes) 367.080000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 475000\n",
      "learning_rate 0.000339\n",
      "mean reward (100 episodes) 221.279541\n",
      "max reward (100 episodes) 318.589769\n",
      "mean step (100 episodes) 370.230000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 476000\n",
      "learning_rate 0.000339\n",
      "mean reward (100 episodes) 221.548613\n",
      "max reward (100 episodes) 318.589769\n",
      "mean step (100 episodes) 366.770000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 477000\n",
      "learning_rate 0.000339\n",
      "mean reward (100 episodes) 230.539274\n",
      "max reward (100 episodes) 318.589769\n",
      "mean step (100 episodes) 376.860000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 478000\n",
      "learning_rate 0.000338\n",
      "mean reward (100 episodes) 232.327977\n",
      "max reward (100 episodes) 318.589769\n",
      "mean step (100 episodes) 368.190000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 479000\n",
      "learning_rate 0.000338\n",
      "mean reward (100 episodes) 233.181404\n",
      "max reward (100 episodes) 318.589769\n",
      "mean step (100 episodes) 376.400000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_480000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 480000\n",
      "learning_rate 0.000338\n",
      "mean reward (100 episodes) 233.564978\n",
      "max reward (100 episodes) 321.165755\n",
      "mean step (100 episodes) 379.490000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 481000\n",
      "learning_rate 0.000338\n",
      "mean reward (100 episodes) 234.072102\n",
      "max reward (100 episodes) 321.165755\n",
      "mean step (100 episodes) 373.420000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 482000\n",
      "learning_rate 0.000337\n",
      "mean reward (100 episodes) 231.876780\n",
      "max reward (100 episodes) 321.165755\n",
      "mean step (100 episodes) 368.670000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 483000\n",
      "learning_rate 0.000337\n",
      "mean reward (100 episodes) 232.549272\n",
      "max reward (100 episodes) 321.165755\n",
      "mean step (100 episodes) 358.250000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 484000\n",
      "learning_rate 0.000337\n",
      "mean reward (100 episodes) 231.667053\n",
      "max reward (100 episodes) 321.165755\n",
      "mean step (100 episodes) 367.340000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 485000\n",
      "learning_rate 0.000337\n",
      "mean reward (100 episodes) 237.645502\n",
      "max reward (100 episodes) 321.165755\n",
      "mean step (100 episodes) 360.810000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 486000\n",
      "learning_rate 0.000336\n",
      "mean reward (100 episodes) 237.508082\n",
      "max reward (100 episodes) 321.165755\n",
      "mean step (100 episodes) 340.700000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 487000\n",
      "learning_rate 0.000336\n",
      "mean reward (100 episodes) 235.650509\n",
      "max reward (100 episodes) 321.165755\n",
      "mean step (100 episodes) 332.020000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 488000\n",
      "learning_rate 0.000336\n",
      "mean reward (100 episodes) 238.440024\n",
      "max reward (100 episodes) 321.165755\n",
      "mean step (100 episodes) 329.840000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 489000\n",
      "learning_rate 0.000336\n",
      "mean reward (100 episodes) 237.964598\n",
      "max reward (100 episodes) 321.165755\n",
      "mean step (100 episodes) 323.920000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_490000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 490000\n",
      "learning_rate 0.000336\n",
      "mean reward (100 episodes) 243.167978\n",
      "max reward (100 episodes) 321.165755\n",
      "mean step (100 episodes) 326.310000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 491000\n",
      "learning_rate 0.000335\n",
      "mean reward (100 episodes) 243.449737\n",
      "max reward (100 episodes) 321.165755\n",
      "mean step (100 episodes) 318.170000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 492000\n",
      "learning_rate 0.000335\n",
      "mean reward (100 episodes) 243.872292\n",
      "max reward (100 episodes) 321.165755\n",
      "mean step (100 episodes) 320.880000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 493000\n",
      "learning_rate 0.000335\n",
      "mean reward (100 episodes) 240.964443\n",
      "max reward (100 episodes) 321.165755\n",
      "mean step (100 episodes) 318.060000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 494000\n",
      "learning_rate 0.000335\n",
      "mean reward (100 episodes) 241.675603\n",
      "max reward (100 episodes) 321.165755\n",
      "mean step (100 episodes) 283.940000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "timestep 495000\n",
      "learning_rate 0.000334\n",
      "mean reward (100 episodes) 235.937110\n",
      "max reward (100 episodes) 321.165755\n",
      "mean step (100 episodes) 261.090000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 496000\n",
      "learning_rate 0.000334\n",
      "mean reward (100 episodes) 235.906246\n",
      "max reward (100 episodes) 321.165755\n",
      "mean step (100 episodes) 269.860000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 497000\n",
      "learning_rate 0.000334\n",
      "mean reward (100 episodes) 236.346384\n",
      "max reward (100 episodes) 321.165755\n",
      "mean step (100 episodes) 268.260000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 498000\n",
      "learning_rate 0.000334\n",
      "mean reward (100 episodes) 235.724818\n",
      "max reward (100 episodes) 321.165755\n",
      "mean step (100 episodes) 273.300000\n",
      "max step (100 episodes) 1000.000000\n",
      "------------------------------------------------\n",
      "timestep 499000\n",
      "learning_rate 0.000334\n",
      "mean reward (100 episodes) 232.692319\n",
      "max reward (100 episodes) 321.165755\n",
      "mean step (100 episodes) 263.920000\n",
      "max step (100 episodes) 1000.000000\n",
      "saving model weights at offline/agent/ckpts/dqn_500000.ckpt\n",
      "------------------------------------------------\n",
      "timestep 500000\n",
      "learning_rate 0.000333\n",
      "mean reward (100 episodes) 226.237393\n",
      "max reward (100 episodes) 320.736843\n",
      "mean step (100 episodes) 255.290000\n",
      "max step (100 episodes) 1000.000000\n"
     ]
    }
   ],
   "source": [
    "agent.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABCIAAAHkCAYAAADrWI5dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd3xUVf7/8deUTCpJSK8klARCLwFEmoINRVFXV1bR1V3Lqqvr+rWwroKLugjqsqviomvZn2VhxQILFhALIFKlE0ooAUJ6721mfn8MDMQAhmSSScL7+Xj4MDPnzr0nh5nMvZ/7OZ9jsNvtdkREREREREREWoHR3R0QERERERERkfOHAhEiIiIiIiIi0moUiBARERERERGRVqNAhIiIiIiIiIi0GgUiRERERERERKTVKBAhIiIiIiIiIq1GgQgR6dBuvfVWFi5c6O5uiIiIyHlk6tSpzJkzx93dEGmzFIgQERERERERkVajQISIuJTdbsdms7X6cevq6lr9mCIiItJ2WK3WVj+mzj9EmkaBCJF2ZNy4cbz55ptcffXVDBw4kCeeeIK8vDzuvPNOBg0axO23305xcbFz+61btzJ58mSSk5O55pprWL9+vbPt448/ZsKECQwaNIjx48ezYMECZ9v69esZM2YMb7/9NiNGjGDUqFF8/PHHZ+zXrbfeypw5c5g8eTIDBgzg6NGjlJaW8sQTTzBq1ChGjx7NnDlznCcIF198MTt37gRg8eLF9OzZk/379wOwcOFC7rvvPgC2b9/OTTfdRHJyMqNGjWLGjBnU1NQ4j9uzZ08++OADLrvsMi677DIA1qxZwxVXXMGQIUOYMWMGdru9ucMuIiIiZ3Gu5ycPPvggI0eOZMiQIdxyyy2kpqYCUFNTw6RJk3jvvfcAR2Bh8uTJvPrqq6c97tSpU5k+fTp33XUXAwcOZP369dTU1DBr1iwuuugiLrzwQqZNm0ZVVRUAU6ZMYdmyZQBs2rSJnj17snLlSgB++OEHJk2aBMCRI0e47bbbGD58OMOHD+f//u//KCkpqff7vvHGG87ft66ujpSUFK677joGDRrEQw89RHV1tYtHWaRjUSBCpJ1Zvnw577zzDsuWLePbb7/lrrvu4uGHH2b9+vXYbDbnl3d2djb33HMP9957Lxs2bODxxx/nwQcfpKCgAIDg4GBef/11Nm/ezMyZM5k5cya7du1yHicvL4/S0lJWrVrFc889x4wZM+qdRPzU4sWLeeaZZ9i8eTNRUVE8/vjjmM1mli9fzqJFi1izZo2zVsPQoUPZsGED4DgRiI2NdT7euHEjw4YNA8BoNPKnP/2JdevWsWDBAtauXct//vOfesddsWIFH374IZ9//jkFBQU88MADPPTQQ6xbt44uXbqwefNmF428iIiInEljz08AxowZw7Jly1i7di29e/fmkUceAcBisfDCCy/w8ssvc+DAAd544w1sNhv33nvvGY+7dOlSfve737F582aGDBnCCy+8wKFDh1i0aBHLly8nJyeHuXPnAj9//jF06FDAkd15zz33sHr1ar744guysrJ45ZVX6h33s88+44033mDTpk3YbDbuv/9+Jk2axIYNG7jiiitYvny56wZXpANSIEKknZkyZQohISGEh4eTnJxM//796d27NxaLhUsvvZSUlBTAERgYM2YMY8eOxWg0MnLkSPr27euM/F900UV06dIFg8HAsGHDGDlyJJs2bXIex2w2c//99+Ph4cHYsWPx8fHh0KFDZ+zXddddR0JCAmazmeLiYlatWsUTTzyBj48PwcHB3H777Xz22WdAwxOBe+65h40bNwL1TwT69u3LwIEDMZvNxMTEcNNNNzm3O+Huu+8mMDAQLy8vVq1aRY8ePbjiiivw8PDg17/+NSEhIS4aeRERETmTxp6fANxwww34+flhsVh44IEH2LNnD6WlpQAkJiZy7733cv/99/P2228ze/ZsTCbTGY87fvx4hgwZgtFoxGKxsHDhQp544gkCAwPx8/PjnnvucZ5/DBs2rF7g4afnHyduhMTFxTFy5EgsFgtBQUHccccdDc4/br31ViIjI/Hy8mLbtm3U1tby61//Gg8PD6644gr69evnusEV6YDM7u6AiJybUy+sPT096z328vKioqICgIyMDL788ku+/fZbZ3tdXR3Dhw8HYOXKlcydO5e0tDRsNhtVVVUkJiY6tw0MDMRsPvknwtvb27nv04mMjHT+nJGRQV1dHaNGjXI+Z7PZnNsMGzaM2bNnk5ubi81mY8KECbz66qukp6dTWlpKUlISAIcOHeL5559n586dVFZWYrVa6dOnzxmPm5OTQ0REhPOxwWCo1y4iIiIto7HnJ1arlTlz5vDll19SUFCA0ei4L1pYWEinTp0AuPbaa5kzZw6XXXYZ8fHxZz3uqd/zBQUFVFZWcv311zufO7V21cCBA0lLSyMvL489e/bwz3/+k5dffpmCggK2b99OcnIyAPn5+Tz77LNs2rSJ8vJy7HY7/v7+ZzxuTk4O4eHhGAwG53NRUVE/P2gi5zEFIkQ6qMjISCZNmsSzzz7boK2mpoYHH3yQWbNmMX78eDw8PLjvvvuaVU/h1C/fiIgILBYL69atqxfMOCEuLg4vLy/ee+89kpOT8fPzIyQkhA8//NB5VwPg6aefpnfv3rz00kv4+fnx73//2zm383THDQ0NJSsry/nYbreTmZnZ5N9JREREXGvJkiV8/fXXvPPOO8TExFBaWsrQoUPrnYP85S9/4eKLL+b7779n06ZNzgDBz+ncuTNeXl589tlnhIeHN2j39vamT58+vPvuuyQkJGCxWBg0aBD//ve/6dKlC0FBQQC89NJLGAwG/ve//9G5c2dWrFjBjBkz6u3rp+cf2dnZ2O125/MZGRnExsae8/iInC80NUOkg7rmmmv49ttvWb16NVarlerqatavX09WVhY1NTXU1NQQFBSE2Wxm5cqVrFmzxmXHDgsLY+TIkTz//POUlZVhs9k4cuSIMx0SHFkR77//vnMaxk8fA5SXl+Pr64uvry8HDhxg/vz5Zz3u2LFjSU1NZfny5dTV1fHuu++Sl5fnst9LREREmqe8vByLxULnzp2prKzkb3/7W732RYsWsWvXLmbOnMmTTz7J1KlTKS8vb9S+jUYjN954I3/961/Jz88HHDWzVq9e7dzmp+cbw4cPP+35h4+PD/7+/mRnZ/Pmm2+e9bgnppG+++671NXVsXz5cnbs2NGoPoucrxSIEOmgIiMjee2113j99dcZMWIEY8eO5a233sJms+Hn58eTTz7JQw89xNChQ1m6dCnjxo1z6fFnz55NbW0tV155JUOHDuXBBx8kNzfX2T506FDKy8vrBSJOfQzw+OOPs3TpUgYPHsxTTz3FlVdeedZjBgUF8Y9//IOXXnqJ4cOHc/jwYQYPHuzS30tERESa7tprryUqKorRo0dz1VVXMXDgQGdbRkYGM2fOZNasWfj6+nL11VfTt29fZs6c2ej9P/roo8TFxfHLX/6SwYMHc/vtt9ercfXT84+fPgb4/e9/T0pKCsnJydx9993OlbnOxGKx8Morr/Dpp58ydOhQPv/8cy699NJG91nkfGSwa207EREREREREWklyogQERERERERkVajQISIiIiIiIiItBoFIkRERERERESk1SgQISIiIiIiIiKtRoEIEREREREREWk1Znd3oLkKC8ux2Zq38EdwsB/5+WUu6tH5TWPpWhpP19J4uo7G0rVcOZ5Go4HOnX1dsi9pvOaej+gz5VoaT9fSeLqOxtK1NJ6u1ZrnI+0+EGGz2ZsdiDixH3ENjaVraTxdS+PpOhpL19J4tm+uOB/Re8C1NJ6upfF0HY2la2k8Xau1xlNTM0RERERERESk1SgQISIiIiIiIiKtRoEIEREREREREWk1CkSIiIiIiIiISKtRIEJEREREREREWk27XzVDRFqG3W5n39Ei6qx2esUFYjIqbikiItKaMvPLOZLdvKX0PC0m+ncPxmgwuKhXIiLNp0CEiJzWa5/u5Md9uQD4eXswdmAUEy+Mx9PD5NzGbrdTZ7WxeV8e0SG+RIf6YtCJjoiIiEu8vngXR3KaF4gAeGLKEHrEBLigR9Jcn31/kPU7M5u1Dy+LiVsu7YmPly7l3K2kvIbP1x2m1mpr1n4GJ4bSJz6oSa/9YWcmH357AOxNX3bTYDTQNcKfh6cMafI+zpXevSJyWieCEMm9wjiaU8Znaw/z2drDxIT6UlZZS0JMIFkFFRw9zQnSmAGRTB6fgJdFf2JEREQaY++RQvKKq+o9l1tcxbCkMCaN6tqkfR7NKWPe4l1UVNe5ooutau3OLP77TSpNv7QCg8HArZf1ZEjPUJf1q7kWrTpAaXkNQf5eTXp9bZ2NrIIKispqiI/sxA1ju+smkBttP5DP8o1H8fUyN/nfobK6jm83H+P5ey4grLPPabepqKpjw55srNaGn4h1u7KorbMxvHd4k44PkFNYQVFZNdU1Vkw/v7lL6CpBRBqorbNiAK4cEccvxnYH4JNVB1n6QxrpueUAbNyTg6+XmZ6xgUQG+/Dd1gzn61dty6SgtJruUQEMSgihS3gn7HY7n687zM6DBXhZTFTWWLloUBQDuofg7en4U5SZX05aZik1dVY27c2lvLKWSaO6MqBHSKuPgYiISGuprbPy4oKtWG0NLzK6RfoTGezbxP3a6v2/PUk9VkxVjZWR/SKbvI/vth7jUGZJmwpEVFbXMTQpnNsu79mk19fUWnnpv1tJzy1j9+FCLkuOJcDP08W9bJv2HC5sEFTzzyqjpKSy0fuICPIhKqRpn6fTqapx9GfmPSPw8/Zo0j6W/pDGJ6sO8u2WY9w0LuG026xLyeL95fvOuI/BiaFNfk+dKjTYl9zc0mbvpzEUiJDzVlllLTW11iZHpDuyNTuysAM9ok+mcV4/phvXje6KHceUjIy8CsI6ezunaky5rCcYwGgw8OE3+/lywxF2Hixg8feHiA3zI7eokqoaa73j7DtahMEA3hbzae/W+Pt48I+PtgPQJdyPO6/qTXpeGanpxSR16Uxyr7Cf/V1sdjtfrDtMeVUdowfHEBng+Pc+lFnCzPc3c+PF3RnZNwIfr6Z9eYiISOsrqajh5Y+2U3mGO/1ms5G6Rlx8B/haCD5+HjC8dzh9uwW7tJ9nklVQwfvL9zr7WGezY7XZufHi7gzpefK7zQgEBzT9PMXD7KjvVGu1/syWbU9NrRV/Xwu3NuPial1KltuDMLvTCuplupRX1uFlafo9Z4uHiT9NGcK6XVm8sSSFiuq68yIQcSy3jNnzt7hkX5cNjT3n18RFdKL3aaZOFJfXANSbunyuJl4Yz/KNR6k5y3u1vLIWgJfuH4nJ1DDzwq8dnscqECHnpWN55Tz15nrn42B/T0b3j+JwdikZ+RU8+It+BPp5snZXFl+uP0JtnY1ZvxuBpRl/ZNqL0ooavtp0lGB/zwaZCAaDAYPjB2LD/Oq1GY0n/yj+clwPrrigC1tT8/j3F3s4mlNGYkwAwQFe/HJcAum5ZXSN8CclrYBDmSWUVNSwZkcW3p4mEmIC6RLeicGJIUQF+/K7l1YCcCS7jGlvb3Ae49vNx3jg+n4MSgzFZrefsQjXttQ8Pl55EIAv1x8hOtSXY8ezOgDmr0hlz+FCHvhF/wavLauspbyylvCg06fJnWrdriy+23KM/5s8EA9zx3+fiIi4U1Z+BQczSkiMDcTf19Kg3dPTTPXPTEeoqq4ju7CC3KIqisurKSqrxmA0UFvbvAvX2DC/BsGDorLqehejm/fmkpJWSGJMAEajAYvRQL9uwQztFUZIgHezjn+qE4GIrPwK0rJKGvWasEDvcwrOW202FqzYT2llTZP6eEJ8hD9XDO/ifFxTa232eZfZZKTWauPlj7ZzLK95tTY6+3nyyK8GYTY1vnh3dY2Vl/67DdtP5u6HNiO4dILX8WzSfy7addrARtdIf351yenvrrcFx3LLWPB16mmzgE6nvMrxeb776t71Mho6d/alsLD8TC+rZ9v+PL7ccISVWzPgHGZRVNecPZDnYTZiPk1w4FyYTYYGwdO8okrSshzZCWlZpXiYjXTu1HGCTgpEyHnFbreTW1zF+8v2Ao5iP54WE/kl1Sz6/pBzuz//a32D1z4+by2TRnVlSM9QOvk0POnpCOx2O4/9cy3VtVbuvrp3s/bl72NhzIAoLuwbQU5hZb0vjQBfR0Q5uVeYM6vht1ed/nhzfj8SHy8zuw8XcjCjBB9PM+FBPnz47X5e+WQHAJ07efLXuy/AZrPj6WHiUGYJWQUVVNVY+eCr+mlsJ4IQ/r4WesYGsnFPDltS8/jN898w4YIufLHuCN6e5np32UxGA8/cORxvi4myylqiQ+sHYWw2O28sSQHg45UHmTy+7X7xS+uy2+2s+DGdgxklDO8dTm2djUEJIed0IisiDZ24eLl2VFd6xXVu0B4a2umc0ov/9uFWdh4sYFdaoUv6d+pcbbvdzobdOQ228bKYeOyWwS26moWPpxmDAf63Jo3/rUlr1Gt6xgby+C2DG32MrPwKvt6cToCfpcm1obILKtiwO4cfdmZxYpGu3KJKws8wX76xPMxGKqvr2Lo/j7jwTkSFNG1/ucVV7EsvprC0mtBAb2x2O5+tPcyOg/n8tIhFZU2d8+61ze7IzLz5kgQGJTimh4SG+mGtrm3W7wXQLcqfQQkhVNc2vEjOPl7Dq60EImrrrOSXVNd77oddWew6HoyjEZ8Bb08zgxNDGZwYWi9AFRraiVxL475Tu4R34uqR515vpbC0mq37885YDDI8yKfZdTrMJiN1Pyl4+c4Xe9h9+OTfpLDOrgtStgUKRMh5Zenaw3y6ynF3vFuUP0/elgzAtLc2kJ5bRu/4zkSH+PHVpqPO1zx5WzJzPtxKcXkN7y7by7pdWUxtxYqyrWnzvjyqa61ckhzDBX0iXLJPs8nYrLl4J9IN+3cPoX/3kxkaibGBPP/BZorKqiksrebe45kTp3P1hfFcN6YbJk8PaqtqqK2zOVPoflFYwdTX1wHwxbojAA1Sfa02O0+8sc75+M3HLq6XAfLmZynOn5dvPEqfrkH0a6X03jPJKazgWG45O9MKSIgOaPDFLS2nusaKyWQgp7CSv773o3Pa0fqUbABuGteDy4d1OdsuRORn2I4HIk79W9wcoYGOE3xPi4lHbhp42tTnxti0J5cf9+WSllk/+yAiyIchPUPpGRvofC44wKvFl9T08fLgyduSKS5rXLbC1z8eJS2rlG+3HKNv1yDnuJzNiXTyX1/Ri4FNrOmUmV/OJysP1rs7HtTJi0GJzasR5WEycuj4v8XYgVFcNCi6SfvZkprLK+k7WLT6EP6+Huw/VsyBY479JsV1rncd7e3pRbdIf+dzHmYTF/SJcNYPCA7wJje3+cVD/X0sp83mBPh45QE+X3cYu93eJgpZ/nPRLseF/E/4epnbxTl1506eXNzE905jeZiN1P2kEGV5ZS29ugRy8yWJAAR2oGwIUCBCziN5RZV8uuogvl5mEmICufHi7s62abcnc+BYMT27OO6q3DS+B0eyS4kM8sXTYmLOA6Ow2uy8v3wvG3bnUFtn7ZDp91v3O1bK+OXFPdzck5/n7WnmL78Zhs1uZ97iXWza47jb5OtlxmQ0cPXIrqRlltC/RwhDEh13IYL8vcitrq03jy+ssw/Tbk9m3a5sjuWVc2GfCEb0dQRhrDYbJqOR95bv5dvNx5yveW/5Xi4aGE1suB8bUrJZtyub7tH+XJocy7zFu5jz4Tbm/nGMswhna6uoqnUGV8AxjWX8kBhuuTTRLf05n2zdn8fLH20nwM9S78R/QPdgth3IB2B/ejGj+tc6M4WaM69UpL0pq6zlk5UHqG7m9IcTgYKmBgx+6lfjExg3KJpOPpbTTvVorPgIf264qPvPb9iKukb6N3rb7MIKdqUV8t7xzNGrRsQB4ONjoaKiYTAjrLM3YSeCOOamZ3pFBvty//X9mvz6M4kK8WVLah4mo6FZN0ViQv0I8LWw+fiKYnbs+Pta+MtvhhHQjPdLS7GYjdjtjhspzZkyUF5Vy1/e2Uh5VfMyOCqrrSTGBnLRwKh6zzdm6uv5wmwykplfwdc/pjufO5JTRv/uwcT8ZDp0R6FAhLRbNrud4rIaDAZH+l6P6IAGUd+0rBLmLdpFTtHJaro3XNSdsQPrRzXNJqMzCAGOgovxEf712s0muLBvJGt2ZPHN5mMd5o5mTmEFf31/M96eZrILKrigd3i7Shs3Ggzcd23fZu0jPsK/3r/3Cabj+aFTLk3kkiEx7DiQz4Jv9rNyawYrt2bQq0sg2YWO99bk8Ql0jwpgx4F81uzM4v45q/jF2G5cNSK+WX07VWZ+OZ18LD9blXlL6sm7Dj1iAtifXszG3dncfElCm7gz0hZU11jZf6yYAD8L//06lfTccq68II4RfSMaVfXabrez+PtD7DlcSGKXzoQGetG3azD/78s9APWCEC/ceyFB/p78sDOLFT+m8+O+XOfyuADP3TWc0NBOrv8lRdqg1KNFfLc1g0A/S5O/a4rLa5wFCE0uyogwm4wNpt2djy4bGsuIPhF89N0BZ50scGTO/zQr3Wa3Y7fDtaMdqe4ebTCo+vvr+1FntWMw0Kxzm9BAb+Y8MMqFPWtZJ26W1dRaG/UZOdO5QXZBJXnFVQxKCGly7RI7dkorarloYFS9c22pLzTQm837chtMKd5+/CZGR6RAhLQ7VpuNu2Z/d9q2yeMTKK2oYfnGow2qJPeICaBbpH+DIMS5SDo+D/W/3+zn0qGxLZ5S2dJq62zOO+clx6v+aqnMhgwGA5HBvkQG+9LZ34tFqw9SUl7DniNFANxxZS+6RzlWGPnNVUl4e5lZsSmdTXtyXRaIOJRZwjP/bxMJMQH86WfSGNOySvH0MDH3j2MwGg2s3pbBO8eLhnYJ1wUvwCufbCflJ3PB53+dyvyvU3l76rizvrbOauPpdzaSkeeoN7Ivvbhe+40Xd2fllgzGDIziygvinM+P7BdJTKgff/n3Rnp1CcTLYmbr/jw+XXWQ/r1cMxVKpK2rO556//BNA4lp4oX/yx9td6Z5t/fv4bbGYDDg72vhN1cl8ZurkpzPn67mxtbUPF7+eDuLVjtqbHXyaXtV+w0GAx7m8+89cqJ45e//vvpntzUZDVw1Iu6005xyj99smTA8jh4xAQ3axXXuu7YvZadmntjhoVe+x9er416ud9zfTDqsz9Yervc4uVeYMy1/wdepDbb/3aQ+DEsKb/B8U13YN4IfdmZRVFrdrpf+tNntLPx2v/PxU79OJruggqGNWBLzfDa0VxhDe4VRWV3Hf1bsw4CB4ae8vwwGAzdfkkhaVin704vJL646p6XXDmaUYPEwEhPqR2V1HY/PW0tZ5ckvptT0Yl7+aDsP3uCYF5pdWMGhjBJWb89k9+FCZ7GjhOOV2AH6d3fUq/hm8zFun9DLFcPQru0/VuwMQvTrFoyftweXD4vl6Xc2AjD7P5u58eIeznRmm83O3qNFxIb54eftwcbdOWTklRPgZ+FX4xOICvHl4+8OUF1rJTTQm0uTY5kwPO60x46L6FQv0PHyR9vZtDeXQxnF+Hm0n0yktuy+++4jPT0do9GIj48PTz31FElJSRw6dIipU6dSVFREYGAgs2bNIj4+HuCsbeJaVmvzMxnMp0wBMLWjDL6Opn+PYP586xBq62z4eJmbXVhSXCe5VxjlVbUNag781JHsUrak5p21kKm3p4nQDlYksS0yGg34/6QY/kM39iciuOlTito6BSKkXbDb7WQVVBAZ7OtMUZp6y2ASTyn6tD+9mCM5pZRV1BIb7keXsE7U1FmJdPEHeMTxQMS6lGyuGNaF95bv5Uh2GdeO7ur2AoXn4tWPdzjvKL3x6EWYTcZzmkd6vvP2NJ9xpQ+ACcO78Er6Dr5cf4SxA6MI8vd0LoeWV1RJgJ8Fk8nIh9/sp6ismimXOdZJf/bdTQC8PXUc32xOrxeEOGHr/jwe/MdqPD1M5JdU1Ws7UXG5W9TJf8sAP08CfC2s2pbBVSPiGlV8rCOprrGyP6OY3nGd+frHdP6zwhGwvGpEHL8Ye3Iu9+uPXMSSHw6x9IfDPPP/NnHLpYmMHxLD9Hc2cCy3HH9fC/dc3ZvN+3LxtJh44d4Lnam+f7hxQJP6dv2Ybmzdn8few4UM6dF+/n60ZbNmzaJTJ0fmz4oVK3jiiSf49NNPmT59OjfffDOTJk1i8eLFTJs2jXfffRfgrG3iWicujJqTJu9xymtdNTVDzp3RYKB7tO6St0V+3h6Nzsi02e0NVv6ox6DMI3c5tUh7R6RAhLQL61Ky+deSFIb3DudgRgmXDImpF4QAx9SL1kgb63K8YMxH3x3go+8OOJ+f8+E27prY21nosC3LKap0BiGeuHVIu6oJ0V4MSgjF29PM15vT+Xqzo/DQ64+MZdpbG5x1JU7106Xdvt1yjI9XHnS+rqbOhtVmZ2tqHv/+Yg9llbWUVdYyql8kXaP86RbpT2yYH3bs7E8vrheIALj18p68+skOXlywhRm/GU5FdV2HWov6BJvNTkpaARYPE4mxgWQXVrBiU3q94k8nXD+mW73HHmYj14/pTlJcEC/M38IHX+0jNNDLueRrSXkNLyzYCsDFg6Jd8rmJCfNj5j0X0CM+mNLihu8LOXcnghAAZWVlGAwG8vPzSUlJ4Z133gFg4sSJPPPMMxQUFGC328/YFhQU5JbfoSOz2hzB0mYFIk5JtVcgQqR5jAYD6GMkbqBAhLQLqUcdc/FPLH/nzjv3nXws/PnWIXx6vE5AaKA3v76iFw+98j3/WpriDERs2ZfL6u2Z/HJcDyIaWRXYZrNTVlVLJ2+PFisqmFVQ4VyK8qEb+9NDdzNazFO/TuaTlQfYtNdRmPCeF08uMTpmQCQb9+TQOy6I0QMiWZ+SzY6DBc4MiFMrlnuYTc7CU8OSwvhi/RF+Nb7HGSLlhtMWgxqcGMqghBC2pOZx798c/fhpVlF7V1Jew2P//MG5lNzZOJZbO/1nLCmuM3dM6MU7X+zh7wu3A/Dbq5L4fN1hMvMr6BkbyLghMS7rd3hnH7wsZkp/fu62Q/AAACAASURBVFNppD//+c+sWbMGu93Om2++SWZmJuHh4ZhMjs+RyWQiLCyMzMxM7Hb7GdvOJRARHNz8QofnQ9FSb29H6nFYaKcmL0UX4H8yqys8rBPBZyiidz6MZ2vSeLqOxtK1NJ6u1VrjqUCEtAv7jzmKwZlNBoI6eZHs5joG3aMDeGTyoNO2/fX9H9l/SvG6iGCfRi+H+dZnKazd5Qi2/Pm2IS3yh2DH8aktQxJD6duOppK0RxFBPtx3XT9q62zc8+J3zuefvXM4USG+3D7hZCGwU4MKf/vvVnYeKiAprjOj+kfW26eXxczMuy9oUn9uu6IXW1K/dz5en5LdrgMRldV1mE0GXvlkBzsPFtCrS6AzCOHtaaKy2urcNjLYh/uu7YvRaOAv72xkaNLZ/4aMHhBFUXkNn65yZKUkxATw3F1NG3dpfc899xwAixYtYvbs2fzhD39o8WPm55dhs519PvbZnK4YYEdUdDzzp7ionNqqhstBNsYFvUKpq60jwMeCtbqW3Ny6BtucL+PZWjSerqOxdC2Np2u5cjyNRsNZg/QKREibdmK+e3ZhJRcNiubWyxLb7PKDU28ZzPMfbK4XhAD4cv0RBvYIYePuHCJDfLh4UDSlFbX8a8kuxg+JZWDCyQvQE0EIgOfe/ZExg7K4/fKeLu1nWlYJAX6WFlmvW07Pw2zk+XsuwGanUdkxf/zlAGx2u3P5UFcJ8LXw6K8G8cL8LYBj+sfIfpENpnG0ZR+vPEB+cRV9uwXx1tLd9aa17jlSRCcfD+Y8MMo5n3XOh9vYcTCf60Z3cy7N9+ofxzQqLfzqC+PpFuVPgK+FMBVha5euvfZapk2bRkREBNnZ2VitVkwmE1arlZycHCIjI7Hb7WdsOx/Z7HbKT1Ob5lyYTUZsdjvT3trQYF/W48Ga5hSZjAz25caLGhfgFxGRtsklgYjCwkIee+wxjhw5gsViIS4ujhkzZhAUFMTWrVuZNm0a1dXVREdH88ILLxAc7LgLe7Y2EZvdztTX11JQUg1AQnRAmw1CACTGBvL3B0exfX8+/XsE4+9jISWtgH98tJ3nP9js3K6m1kZZZS270grZlVZIJx8P7ru2r/NCp1+3YMKDvFmxKZ1VW45xw5hu+Hm7Zkksm93O7sOFzqUmpfWcy4WswWDA1ELv9aS4zs5CmO8v38cbS3bx/D0jWuRYrlZRVedcNWddSna9tlsvS+RobrljtZBTxu7BG/pRUl5brx7GucxN7xOvGgHtSXl5OSUlJc4gwjfffENAQADBwcEkJSWxdOlSJk2axNKlS0lKSnJOvThb2/nm7c9288POrGbtwwDcND6BwtJqhiSGNqi4HxrojaeHqVnHEBGR9s0lgQiDwcCdd97J8OHDAUfF6hdffJHnnnuORx99lJkzZ5KcnMxrr73Giy++yMyZM7Hb7Wdsk/NbTmEFIYHeFBRXOYMQQf6eDEps+5Vj/X0s9VLpe8cHccNF3Zm/IhUDjqLEK7ceq1essLSilln/2eJ8fNnQWPp0DWJEnwie+X+bePAfq3n4lwNcMo3icFYpRWU1DEkMbfa+pH27aFA0uw4VsCU1j4KSqja5FO2R7FK8LCZyiirpGunPAz9ZD91iNvLwTQNJzy3jokHRpw1UmozGDlmUU06vsrKSP/zhD1RWVmI0GgkICGDevHkYDAaefvpppk6dymuvvYa/vz+zZs1yvu5sbeeb7MIKIoJ8GN/EOiiV1XV8suoghzJLABg3JIakuIZ1a0RE5PzmkkBEYGCgMwgBMHDgQObPn8+OHTvw9PQkOTkZgMmTJzN+/Hhmzpx51jY5f20/kMffF253XrSDY1WHblH+7XbpoEuTYxk7IIryqjrmf53Kpj0nV0d4e+o4dh7K52//3eZ8LirEsdxofMTJ+hB/+3AbM34zjJiw5hVD23EgHwPQp9v5eadPTjIaDFw1Ip4tqXks33iUyeMT3N0lp+paK/e+tPKM7VMuS2TVtgwuH9aFxNjAdl3nQlwrJCSEDz/88LRt3bt3Z+HChefcdr6prrE1KxBRW2flk1UH2ZrqWJnJy6LMBxERacjlNSJsNhvz589n3LhxZGZmEhUV5WwLCgrCZrNRVFR01rbAwMafVLqiSjWo2qorNWcs046nXZ8673tQ7wi8LB2jnMmEyjpnIOKPvxpEaGgnLg7txAUDYti6L5fIEF/iT1kR5C93jWD6v9YCMO3tDfzykkRuPaXA4bmoqbWy6PtDhAX50D3u/J0Cpc/6SaGhnYgO3c3BrNImjUtLjOWabRk8/+7GM7Y/+7sLGZAQyk2XN+1z0JbpvSnuZrXZSM8tIzrUt8n78DCbuGpEHJn5Ffh4mYlpxr5ERKTjcvnV3TPPPIOPjw9Tpkzhq6++cvXuG2hulWpQtVVXau5Y7j6YT9dIf35zZS+eemsD3p4mSosrO8yydqGdHMuWjR0YRb+4zvXGqkeEI6h26nODe4Xx9tRx/PuLPazalsGHK/ZxRXLT7lL9a8kuAHrFBpy373d91hsa1iuMT1cf4h//+ZHJ4xMwGhuXedQSY1lWWVsvCPHwTQOc2UJB/p48dVsyAX6eHfLfsDWrVIucycbdjkB5c+s3/GJsd1d0R0REOjCXBiJmzZrF4cOHmTdvHkajkcjISDIyMpztBQUFGAwGAgMDz9om5yebzU5aVimj+kUSHerH21PHubtLLufn7ajo7+9zbsUnb5/Qi+paK+tTssnML+doThmJsYEE+jVu7ntaVglrd2XTuZMnUy5z7Soc0r4N6ekIRKz4MZ3hfcLdUsi0usbKvMU72XZ8adnxg2OYNLorft4evD11HFkFFYQEeJ1TkUkROXflVY5lMCeOiHNzT0REpKNz2VndnDlz2LlzJ3PnzsVicdz17du3L1VVVWzatAmABQsWMGHChJ9tk/NTZn451bVW4iM7dnpygK+lSat/TLwwHoD/9+Ve5i3excOvruG1RTtZtPogNpudsrMst/bpqkMAPDJ5oC7mpJ6oEF/m/H4kALP/s4WqmrpW78PGPTnOIATAzZcm1FspJiLIR+9bkVZwYslsHy/XrNQkIiJyJi7JiEhNTWXevHnEx8czefJkAGJiYpg7dy6zZ89m+vTp9ZboBDAajWdsk/PTweMVtrtF+f/MluenqGAfAnwt7Dta5HzuRL2J/61JA2BEn3DuurpPvdfVWW2kphfh7WkmMlhzdaWhAD9PhiSG8uO+XN5bto+7ru7dqsfftDcHfx8P4iP9GZ4U3qaX6RXpyKzHp7qaTfoMiohIy3JJICIhIYG9e/eetm3w4MEsWbLknNvk/JOWWYq3p4nwIB93d6VNMhgM9OwSyIbjc3h/e1USq7dlsC+92LnNxj253D7Biof55PzeL9YdpqrGyu8m9WmwT5ET7r2uL3fO+pa1u7K4c2JSqwUDKqvr2HEwnwv7RPDbia0bABGR+k5kRJgUiBARkRamXFdpE+x2O2t3ZREf0X6X6WwN14/pBsAdV/ZiZL9Ipk4ZwqOTB/KPB0fx0I39qbPauOfFlfy4NxdwLIP46WrHtIxBCaFu67e0fUaDgSsvcMwLz8ivaLXjfrflGHY7DO8d3mrHFJHTs1odGRH6HhYRkZbWMdZElHatzmrjyX+tp6rGqmkZPyOssw9vPnZxvZUNkuKDHP+P6+x8bu6nOxjaK4zoEMdUjDsm9MLDrLijnN3Fg6L5fN1hvt50lNuu6NXix0vPLWPhdwcATckSaQvqbDbMJoOmR4mISIvTlYm4VWV1HXe/8B05RZV4e5qcd2TlzM60vKKH2cTcP45h5t0XAI4CgBv25BAb5sfoAVGt2UVpp4IDvOgS7sd3WzPOWvzUVZatPwJAdKiviuOJtAE5BZWAghAiItLyFIgQt3rwH6udP//9gVF4eypJpzm8Pc2EB/k4V9jIyCtnSKKmZEjj3TC2OwBvLU1p0eNk5pezZmcWgX4Wnvnt8BY9log0TkFplbNOhIiISEtSIOI8tW5XFqu3Z7DvaBF2u90tfVi7M8tZofvVh8bUK7AozTM8Kcz585VaD17OQZ+uQfh6mTmSU9aifxtSjxdZffiXA1vsGCJybqxWe71pfiIiIi1Ft5/PQ9sP5PPGkoZ3O2f/bgQhgd6t0ge73c6/jt9xnX77UHy89FZ0pehQPx66sT8RQT6YTYo3SuMZDAZ+MbY77y7by76jRfTs4vqLkqyCCv79xR58vcxEh2pJWZHWVlhazVebjjqLU56QV1xFlD6TIiLSCnSF0gFl5JXz1cajp72bWVhazd8Xbjvt6x6bt7ZV5oUDFJRUAxAS4EVcRKdWOeb5pn/3EMI6aylUOXd9uzkKoL7+v10tsv9PVh0EoH/3YBXFE3GDH/fm8OX6I6zensH3O07+ZwcSogPc3T0RETkP6DZ0B/Tesr3sPVrEzkMFBPhaGDMwih7HTyyWbXAUh7t4UDS3Xt6TFZuO8r81ac4AxJI1afzqkoQW65vNbuf1xbvwsjimYdx3Xd8WO5aINE1IgDeRwT5k5ldQVFZNoJ+nS/efkVdOlzA/fntVb5fuV0Qap+54JsRL949UbSYREXELZUR0QPuPOeZe7ziYz/c7Mvnrez9SWV1HXlElKzalMyghhFsv7wnAJcmxvPyH0Twy2TFPe196EYWl1S3Wt/krUtm4J4fV2zMxADGhfi12LBFpujsnOoIEu9MKm70vu93O5n255BVX8uPeXDLyyhnWO/yMK8CISMuy2hwFKU36DIqIiJsoDN7BVNdYnQUgT3X/nFXOn68d3a1Be+/4IK4d1ZVF3x/i/+au4e5retMt0p/P1x0muWcYfbsFN7tvBzNK+PrHdOfjC/tFqH6BSBsVF9EJXy8zu48UMqJvRLP29fm6w3y88mC95/p3b/7fFBFpmhPnCSaTAhEiIuIeCkR0MAcyHNkQ143uSo+YQLpF+XPvSyud7Z4WEzFnKEQ14YIuLPr+EACb9+ay8NsDFJZWk5lf0exARFFZNX/771b8fS3cOTGJrPwKxg2OadY+RaTlGA0GenXpTEpaAXa7vVm1HJZvPFrv8YQLuigbSsSNThSpNKpGi4iIuIkCER3MvqNFGAyOKRcn5n3OvncE2YWVrN2ZRXLPsDNeUHiYTfz17gv423+3sv1gPjW1Nny9zKSmF/Pj3lyG9Axtcr92Hy6korqOh64ZQN+uwfTtqruhIm1dn25B/Lgvl3W7spucFbHzYD6lFbVc0Duc267oSWZ+BfEqUCviVlabHZPRoGKxIiLiNsqL7yDyiiqx2ez8b00aEUE+9YpPhQR40yc+iDsn9mZgQshZ9xMR5MMFfcKpqXXMH514YTwAcz/dwZfrj5BfXHXOfbPZ7Bw8VoLFbKRPV61PLtJejO4fiZ+3B1tSc5v0+pzCCv72oWOVniuGd8HLYqZrpL8ufkTczHY8ECEiIuIuCkR0AOt2ZfHYvLXcOftboPmpll0j/J0/jxsc7fz5w2/387cPtzZqHzmFFSxZc4g6q437/76Krzen07mTJyaj3nIi7YXJaKRft2A27c11Frc7F1NfX+f8OTZMUzFE2oo6m031IURExK00NaMD+GbzsXqP//jLAc3a34AeIVw3uiudfC14mE3M/eMY3lu+l3W7ssnMr6C6xorn8eU3z+Stz3aTml5MaUUt1TVWALpG+Z/1NSLS9nQJ92PtLvjHwu3cf30/PD3O/tk/oaDkZPbUbVf0VBaEtIrCwkIee+wxjhw5gsViIS4ujhkzZhAUFETPnj1JTEzEeDwgPnv2bHr2dKwg9c033zB79mysVit9+vRh5syZeHt7u/NXaVG5hZUY0GdSRETcR7en2zmbzU56bhmDEkKYestg/vl/Ywny92rWPo1GA1eP7MpFAx3ZEN6eZu6+ug9/uKE/AGlZJT+7j5yiSgBW/JiOyWjgV+MTuGFs92b1S0Ra3/De4QDsPFTAvS+t5IedmY163fqUbACSe4Yysm9ki/VP5FQGg4E777yTZcuWsWTJEmJjY3nxxRed7QsWLGDx4sUsXrzYGYQoLy/nqaeeYt68eXz11Vf4+vry1ltvuetXcDm73c6R7FJS04uc/6XnlmG1N1xhS0REpLUoENHO7TlSSFWNlcGJoSTGBjb6bmVTxB0vMHcku+ys25VV1lJcVuN8HB/RiUuHxjY7QCIirS/Qz5MxA04GEt79ci+Z+eU/+7p1KdnEhPpx33X98DDrq0ZaR2BgIMOHD3c+HjhwIBkZGWd9zapVq+jbty/x8fEATJ48mS+++KIlu9mqDhwr4el3NjLz/c3O//JLqrngeJBRRETEHTQ1ox2rqKrjxQWOmg3NWdGisQJ8LQDM/zqVxd8f4tU/jqGorJqHX10DwGVDY3lg8mA273MUtrv7mt5UVltJilOBSpH2bPL4BEwmIyH+Xiz87gB//td6XntsHF5niC8sWn2QozllXDY0tnU7KnIKm83G/PnzGTdunPO5W2+9FavVypgxY3jggQewWCxkZmYSFRXl3CYqKorMzMZl/pwqOLj5dVBCQ12/okxariNwePe1/Yg5XqvFYIDELp3x8fJw+fHakpYYz/OZxtN1NJaupfF0rdYaTwUi2rEH/r4KAF8vM16Wlv+nNBgMXNAnnHW7sqmoruOdz3ezevvJk7XlG4/SLSaQ/36zn9gwP4YnhWteuEgH4GUxc+tljjT2sspavlh/hCfnreH5e0ZgNBgwnlJ9/4edmfxvTRoAV46Ic0d3RQB45pln8PHxYcqUKQB89913REZGUlZWxqOPPsrcuXP54x//6LLj5eeXYbM1fbpDaGgncnNLXdafE4qOT5UMD/AkJuhk3Yvy0irKS899Jaz2oqXG83yl8XQdjaVraTxdy5XjaTQazhqkVyCindqdVsCJ050Zvx1+1m1d6a6JvZk8LoGHXvm+XhDihou689F3B5j36Q4ArhoRpyCESAd01Yh40rJK2X24kLtf+I4gf08uH9qFrzYdZVBCKLsPFwJw7aiu+PtY3NxbOV/NmjWLw4cPM2/ePGdxyshIxxQjPz8/brzxRt555x3n8+vXr3e+NiMjw7mtO5WU1zDt7Q1UVNU2az91VsfZQnNX1BIREXElBSLaqW+3Oua8PnfXcDp38my14xoMBvx9T15cDEsK444JSXhaTOw5UsjOgwX4eXuQ3Cus1fokIq3Hx8vM76/vx/1zHBlZBSXVzP86FYCvNh0F4IphXbhmVFe39VHOb3PmzGHnzp288cYbWCyO76vi4mI8PT3x8vKirq6OZcuWkZSUBMDo0aN55plnSEtLIz4+ngULFjBhwgR3/goAFJVVU1Jew5DEUMKDfJq0j+0H8knPddR1OjVzSURExN1cFoiYNWsWy5Yt49ixYyxZsoTExEQADh06xNSpUykqKiIwMJBZs2Y5C0KdrU3OzG63s+9oESP6hBMZ7OuWPvz17gv4ZnM6k8clOE9uescFsfNgAZcmx+jOi0gH5u1p5t5f9Mdos7Pwu/3kFFbWax+uInjiJqmpqcybN4/4+HgmT54MQExMDHfeeSfTpk3DYDBQV1fHoEGD+MMf/gA4MiRmzJjBPffcg81mIykpiT//+c/u/DUAOLGoxYV9IxiU2LQ6UOVVtScDEfpaFhGRNsRlgYjx48dz2223ccstt9R7fvr06dx8881MmjSJxYsXM23aNN59992fbZOGqmutzF+Riq+XmZLyGnp1cV8RyIggH26+JLHec2MGRBES7MuA+EA39UpEWsuVF3YlN7eU8M7ezF20k7uv7k2gnyflVbXEhDa/aJ9IUyQkJLB3797Tti1ZsuSMr7vkkku45JJLWqpbbnNqFoSmS4qISFvisjXVkpOTG8ypzM/PJyUlhYkTJwIwceJEUlJSKCgoOGubnN5/v05l1bYMvlh/BICBCSFu7lF9Pl5mJoyIx8PcckuIikjbEhPmx8y7L6BrpD+dO3kqCCHias2IH5yanaipGSIi0pa0aI2IzMxMwsPDMZkcF6Ymk4mwsDAyMzOx2+1nbAsKCmr0MVyxXBa0/WVfNqZk8d3W+muhd4sLdlNvzq6tj2V7o/F0LY2n62gsXUvjKa5mOiX4oDiEiIi0Je2+WGVzl8uC9rHsy9cbDgMwdmAUkcG+jBkQ2Sb73B7Gsj3ReLqWxtN1NJau1ZrLZUn7YD++NpahGSkR9TIiNDVDRETakBYNRERGRpKdnY3VasVkMmG1WsnJySEyMhK73X7GNqnPbreTklZIcq8wfn1FL3d3R0RERFqYvXn3WAAwnDIBVzUiRESkLXFZjYjTCQ4OJikpiaVLlwKwdOlSkpKSCAoKOmub1Hcsr5zC0mr6xLuvOKWIiIi4QTPiB/WmZmhuhoiItCEuy4h49tlnWb58OXl5edxxxx0EBgby2Wef8fTTTzN16lRee+01/P39mTVrlvM1Z2uTk9buzMJkNDAwoWnLd4mIiEj71JzwQf2pGc3vi4iIiKu4LBDx5JNP8uSTTzZ4vnv37ixcuPC0rzlbmzjUWW18s/kYXSP9CfC1uLs7IiIi0k5o+U4REWmrWnRqhjTfJysPUl1rxcer3dcVFRERkUY6USOiOfEDLd8pIiJtlQIRbdzGPdkATLww3r0dERERkXbFqOU7RUSkjVIgog2rqqmjoKSaiRfG0yM6wN3dERERkVZyYvnO5lSJCPL3BMDb04TFw+SCXomIiLiG8v3bsG3787EDPaL93d0VERERaWcu6B1B367BeJiNmE269yQiIm2HAhFt2LpdWfh4mukdryVNRUREzisuqBEB4Oft0fy+iIiIuJjC422U1WYj5XAhyb3CdBdDRETkPGP/+U1ERETaLWVEtEG70wp4YcFWAHrGBrq5NyIiIuIuqjEpIiIdkW61t0EnghAAsWF+buyJiIiIuIVSIkREpANTRkQbUWe18f7yvSTFnawHMW5wNNGhvm7slYiIiLiVUiJERKQDUiCijdhxIJ9V2zJZtS0TgAd/0Z+BCSFu7pWIiIi4w4nlOw2KRIiISAekqRltRHpeufPnvt2C6NtNK2WIiIiIiIhIx6OMiDZiw+5sokN9eea3w93dFREREXEz+4kaEUqIEBGRDkgZEW3A7rQCjuWWMzwp3N1dEREREREREWlRCkS0AT/sygJgUGKom3siIiLSfhUWFnLXXXdx+eWXc/XVV/P73/+egoICALZu3co111zD5Zdfzm9+8xvy8/Odrztbm7spIUJERDoiBSLc6It1h3n6nQ2s2ZFF92h/okO0QoaIiEhTGQwG7rzzTpYtW8aSJUuIjY3lxRdfxG638+ijjzJt2jSWLVtGcnIyL774IsBZ29zJbtf6nSIi0nEpEOEmuUWVLPzuAEeyywDwMOmfQkREpDkCAwMZPvxkraWBAweSkZHBjh078PT0JDk5GYDJkyfz5ZdfApy1rS1QRoSIiHREKlbpJocyS+o9vnNibzf1REREpOOx2WzMnz+fcePGkZmZSVRUlLMtKCgIm81GUVHRWdsCAwMbfbzgYL9m9zk0tJPz56ySagACAn3qPS+Np3FzLY2n62gsXUvj6VqtNZ4KRLjJR98dAOCNRy/CrGwIERERl3rmmWfw8fFhypQpfPXVVy1+vPz8Mmy2pk+nCA3tRG5uqfNxcVGF4//FlfWel8b56XhK82g8XUdj6VoaT9dy5XgajYazBukViHCDnYfyySuuAlAQQkRExMVmzZrF4cOHmTdvHkajkcjISDIyMpztBQUFGAwGAgMDz9rmTioRISIiHZmugltZRVUt//5iDwB/vnWIm3sjIiLSscyZM4edO3cyd+5cLBYLAH379qWqqopNmzYBsGDBAiZMmPCzbW2BakSIiEhHpIyIVvbOF3soKq3hiSlD6B4d4O7uiIiIdBipqanMmzeP+Ph4Jk+eDEBMTAxz585l9uzZTJ8+nerqaqKjo3nhhRcAMBqNZ2xzpxMJEQZFIkREpANyeyDi0KFDTJ061VkUatasWcTHx7u7Wy2iptbK5r25XD6sCz1iFIQQERFxpYSEBPbu3XvatsGDB7NkyZJzbhMRERHXc/vUjOnTp3PzzTezbNkybr75ZqZNm+buLrWYrIIK7EDXKH93d0VERETaMhWJEBGRDsytgYj8/HxSUlKYOHEiABMnTiQlJYWCggJ3dqvFZOSVAxAV7OPmnoiIiEhbpjCEiIh0ZG6dmpGZmUl4eDgmkwkAk8lEWFgYmZmZBAUFNWofrli3G1pnvdTCiqOYjAb6JIbjYXZ7MkqL0Vq+rqXxdC2Np+toLF1L4ymnY1CRCBER6YDcXiOiuZq7bje03vqzqYcLCevsTVFheYsfy120lq9raTxdS+PpOhpL12rNdbulfVBGhIiIdGRuvS0fGRlJdnY2VqsVAKvVSk5ODpGRke7sVovYcTCfbfvzSIrr7O6uiIiIiIiIiLiNWwMRwcHBJCUlsXTpUgCWLl1KUlJSo6dltCertmUQ2MmTGy/u4e6uiIiISFunlAgREenA3D414+mnn2bq1Km89tpr+Pv7M2vWLHd3yeUqqupISSukd3xnPD1M7u6OiIiItBMqESEiIh2R2wMR3bt3Z+HChe7uRovakppLZXUdlybHursrIiIi0g7YlRIhIiIdWMdduqEN+XbLMUICvOgRHeDuroiIiEg7YkApESIi0vEoENHCSipqOJhRwsh+kRiNOpkQERGRRjiREKFTBxER6YAUiGhh7325F0CrZYiIiEijaWKGiIh0ZG6vEdFR7TtaxPMfbAZgaK8wEmI0LUNERETOjRIiRESkI1JGRAs5EYQAuOGi7hhU9lpEREQaya6UCBER6cAUiGgBJeU1zp9n/W4EoYHebuyNiIiItFu6jyEiIh2QAhEtYMWPRwGYestgBSFERESkCZQSISIiHZcCES0gu6ASQHUhREREpFm0fKeIiHRECkS4mNVmY9ehAgYnhqouhIiIiDSJakSIiEhHpkCEi81boY1wdgAAIABJREFUtIuK6jqSe4W6uysiIiLSTp2IQ+iehoiIdEQKRLjYj/tyAegdF+TmnoiIiIiIiIi0PQpEuJDteB7lkJ6h+Pta3NwbERERabc0NUNERDows7s70JHkF1cB0KersiFERETcYdasWSxbtoxjx46xZMkSEhMTARg3bhwWiwVPT08AHnnkEUaPHg3A1q1bmTZtGtXV1URHR/PCCy8QHBzstt/hVJqaISIiHZEyIlzoYEYJAF0j/N3cExERkfPT+PHj+eCDD4iOjm7Q9vLLL7N48WIWL17sDELY7XYeffRRpk2bxrJly0hOTubFF19s7W43YFdKhIiIdGAKRLjQgWPFWDyMxIT5ursrIiIi56Xk5GQiIyMbvf2OHTvw9PQkOTkZgMmTJ/Pll1+2VPfOmZbvFBGRjkhTM1xo79Eiukb4YzIqviMiItLWPPLII9jtdoYMGcLDDz+Mv78/mZmZREVFObcJCgrCZrNRVFREYGBgo/cdHOzX7P6FhnZy/uyfXQZAYGefes9L42ncXEvj6ToaS9fSeLpWa42nAhEuciS7lKM5ZUwa1dXdXREREZGf+OCDD4iMjKSmpobnnnuOGTNmuHQKRn5+GTZb06dThIZ2Ije31Pm4pLgSgKLCCnI9Tc3u3/nmp+MpzaPxdB2NpWtpPF3LleNpNBrOGqTXrXsX2bwvFwMwbnDDOakiIiLiXiema1gsFm6++WY2b97sfD4jI8O5XUFBAQaD4ZyyIVqCKkSIiEhHpkCEi+QWVRLk70knHy3bKSIi0pZUVFRQWuq4w2O32/n8889JSkoCoG/fvlRVVbFp0yYAFixYwIQJE9zW1xOOrwiuVTNERKRD0tQMF8ktriI4wNvd3RARETmvPfvssyxfvpy8vDzuuOMOAgMDmTdvHg888ABWqxWbzUb37t2ZPn06AEajkdmzZzN9+vR6y3eKiIhIy2l2IGLx4sW8+eabHDhwgCeeeIIpU6Y42yorK/nTn/7Erl27MJlMPP7441x88cU/29Ye5RVV0ic+yN3dEPn/7N15YFT1vf//1yyZyU4WEpggSg1KY6kKRKhVUIMUrCx2sSCtrbWt2lqLtviVeimgtdqAvS5VtP3V5V5Li+WqIKhgtbgrgoqiKAgCglmZJJBtZjIz5/fHJAOB7DnJLHk+/srMZ+bMO2+P5Jz3fD7vDwAMaAsXLtTChQuPe3716tXtvmfs2LFau3ZtX4bVAyzOAADEr14XIgoKCnTXXXfpr3/963FjDz30kFJSUvTvf/9be/fu1fe//309//zzSklJ6XAs1jR4/Kqp8yk3KznSoQAAAAAAENV63SPi1FNP1ciRI2VtY8vK5557TnPmzJEkjRgxQqNHj9Yrr7zS6VisOVAZ2mLrpCFsHQMAAHrvSI8ImkQAAOJPnzarLCkp0bBhR3aRcLlcKisr63Qs1pQcrJckDRsce7M5AABA9KIMAQCIR50uzfjWt77Valuro73xxhuy2SK7t3VHe5N2R05Oz2czVDc0Kclp06j8wXxzod7lEscjn+Yin+Yhl+YinwAAYKDotBDx1FNP9fjgeXl5+uKLL5SVFWriWFpaqgkTJnQ61h1ud52Cwd41dMrJSVNlZW2P37/r82oNzUrWwYN1vYojHvQ2l2iNfJqLfJqHXJrLzHxarRbTivSIAny/AQCIQ326NGPatGl6/PHHJUl79+7Vtm3bNHHixE7HYk1lTaNyM2lUCQAAzMGeGQCAeNbrQsS6des0adIkrV+/Xvfcc48mTZqkXbt2SZJ+8pOf6PDhw5oyZYquvvpq3XrrrUpNTe10LJYYhqFD9T5lpDoiHQoAAIgTRnO3SiZEAADiUa+375w+fbqmT5/e5lhycrLuvffebo/FkkZvQE3+oAalOCMdCgAAAAAAUa9Pl2YMBIfqvZKkQcyIAAAAZqMJNgAgDlGI6KXq2lAhIjOVGREAAAAAAHSGQkQvhQsRaRQiAACAOZpbRNAjAgAQlyhE9FJVcyEigxkRAAAAAAB0ikJEL2399KCGZCbJ6bBFOhQAABAnjOYNPGkRAQCIRxQieqHB49fe0sM6q2BIpEMBAAAAACAmUIjohY/3VcuQNOrEjEiHAgAA4okR6QAAAOg7FCJ64b1PK5WalKBRwylEAAAAcxiGoUZfQJJkYW0GACAO2SMdQKwKGoa2febWl0/MkN1GPQcAAJjjxXcO6B8vfCpJslspRAAA4g+FiB4qr2pQbUOTCkZkRToUAAAQR6rrvLJaLLpm1lc0OCMp0uEAAGA6vsrvoTc+LJPVYtHoL1GIAAAA5rJaLSr8cm6kwwAAoE9QiOihvaWHNTw3VTl8UwEAAMxksG0nACC+UYjoAcMwtK+8TicNTY10KAAA4CjFxcUqKirSqFGjtHPnzvDze/bs0ezZszV16lTNnj1be/fu7dJYJLBhBgAg3lGI6IGXtpaorrFJJw5Ji3QoAADgKJMnT9aKFSs0bNiwVs8vXrxYc+fO1YYNGzR37lwtWrSoS2MRYUhMiAAAxDMKET3w5odlksTaTQAAokxhYaFcLler59xut7Zv367p06dLkqZPn67t27erqqqqw7GIohIBAIhj7JrRTVt3HdSuLw7pogknKj3ZEelwAABAJ0pLSzVkyBDZbDZJks1mU25urkpLS2UYRrtjWVldb0idnd375Zo5OaGZlolJCbJaLOHH6BnyZy7yaR5yaS7yaa7+yieFiG4IGoaeeHm3hmQl61uTTo50OAAAIEq43XUKBnve3SEnJ02VlbWSpIYGnwxD4cfovqPzid4jn+Yhl+Yin+YyM59Wq6XDIj2FiG54ZWuJvqis11UzT5PdxqoWAABigcvlUnl5uQKBgGw2mwKBgCoqKuRyuWQYRrtjEcXSDABAHONuuouCQUPPvrVPJ+ela3zBkEiHAwAAuig7O1sFBQVat26dJGndunUqKChQVlZWh2ORRB0CABDPmBHRRe/urNTBQx7NLhopK5t7AwAQlW677TY9//zzOnjwoH784x8rIyNDzzzzjJYsWaIFCxZo+fLlSk9PV3Fxcfg9HY1FgmFIXGoAAOIZhYguCBqG1r25V7kZSRpzSk6kwwEAAO1YuHChFi5ceNzz+fn5WrVqVZvv6WgsEgz1vNcEAACxoNdLM2655RZNmzZNM2fO1Jw5c7Rt27bw2MGDB3XllVdq6tSpmjlzpt5///0ujUWbF7cc0OfldZp17pdktfIVBQAA6GtcbwAA4levCxGTJk3S2rVr9fTTT+vqq6/WDTfcEB7705/+pMLCQm3YsEGLFi3S/PnzZRhGp2PRpLyqQY//Z5fOHDlYE75CbwgAANDHDMoQAID41utCxAUXXKCEhARJ0plnnqmysjIFg0FJ0vr16zVnzhxJUmFhoZxOZ3jGREdj0eSND8skST+aNoreEAAAoM8ZokcEACC+mdojYsWKFTr//PNltVpVXV0twzBadZ12uVwqKyvT8OHD2x07/fTTu/WZHe1N2h05OWltPv/pF4d0yokZGvmlwaZ8zkDQXi7RM+TTXOTTPOTSXOQTYdE3QRQAAFN1Woj41re+pZKSkjbH3njjDdlsNknSM888o7Vr12rFihXmRtgJt7tOwWDv/mLn5KSpsrL2uOc9Pr8+3V+jqeNPbHMcx2svl+gZ8mku8mkecmkuM/NptVpMK9IDAAD0hU4LEU899VSnB/n3v/+tu+66S48++qgGDw7NHMjMzJQkVVVVhWc+lJaWaujQoR2ORZNdBw4pEDT05ZMyIh0KAAAYIAwZsrA2AwAQx3rdI2Ljxo2644479NBDD+mEE05oNTZt2jStXLlSkrRlyxZ5PB6NHj2607Fo8cnnNbJZLRo5bFCkQwEAAAMEKzMAAPGu1z0ifvvb3yohIUG/+tWvws89+uijyszM1G9+8xvdeOONWr16tZxOp5YuXSqrNVT76GgsWuz4vFpfcqUr0WFqKw0AAID2UYkAAMS5Xt9hv/XWW+2O5eTk6NFHH+32WDQIBIPaV16norHDIh0KAAAYYFiZAQCIZ9E1BSGKlFc1yh8IanguDb8AAED/MSRRhwAAxDMKEe3YX1EnSRQiAABA/zJYmwEAiG8UItpxoLJONqtFruyUSIcCAAAGEENibQYAIK5RiGhHycF6DclKVoKdFAEAgP5FGQIAEM+4y25Hg8ev1KSESIcBAAAGGIMmEQCAOEchoh2epoASHbZIhwEAAAYcekQAAOIbhYh2eHwUIgAAQP8zDCZEAADiG4WIdtQ3NinZaY90GAAAYACy0KwSABDHKES0wesLqK6xSekpjkiHAgAABhgWZgAA4h2FiDYcqKyTJA3LSY1wJAAAYMChEgEAiHMUItrgaQpIkgYxIwIAAPQzQ4ZYmQEAiGc0QWiD1xcqRDgTaFYJAEC8KCoqksPhkNPplCTNnz9fEydO1NatW7Vo0SJ5vV4NGzZMy5YtU3Z2dkRjpQ4BAIhnFCLa4G2eEeFIYMIIAADx5N5779Wpp54afmwYhm688UbdcccdKiws1PLly3XnnXfqjjvuiFyQhkQpAgAQz7jTbsOa1/ZIklKTEiIcCQAA6Evbtm2T0+lUYWGhJGnOnDlav359RGOiRQQAIN4xI+IYjV6/KqobJUkpFCIAAIgr8+fPl2EYGjdunH7961+rtLRUeXl54fGsrCwFg0HV1NQoIyOjy8fNzu59g+ucnDRJktNpl81uDT9Gz5A/c5FP85BLc5FPc/VXPilEHMPnD0qSThySKiudogAAiBsrVqyQy+WSz+fTH/7wB916662aMmWKKcd2u+sUDPZ8LkNOTpoqK2slSR6PX8FAMPwY3Xd0PtF75NM85NJc5NNcZubTarV0WKRnacYxmpr7Q0wee0KEIwEAAGZyuVySJIfDoblz5+rdd9+Vy+VSSUlJ+DVVVVWyWCzdmg1hPnbNAADENwoRx2gKhGZEJNCoEgCAuNHQ0KDa2tC3PIZh6Nlnn1VBQYFGjx4tj8ejLVu2SJJWrlypiy66KJKh0iMCABD3WJpxjEZv844ZdrbuBAAgXrjdbl133XUKBAIKBoPKz8/X4sWLZbVatXTpUi1evLjV9p0RZUgWds0AAMQxChHH2F8R+rYkNzMpwpEAAACzDB8+XKtXr25zbOzYsVq7dm0/R9QJ6hAAgDjG+oNjuA97ZbFIruzkSIcCAAAGIEPUIQAA8a3XhYgHHnhAM2bM0CWXXKJZs2bp2WefDY81Njbq+uuv15QpUzRt2jRt3LixS2ORVF3rUUaqUzYrNRoAAND/DIMuEQCA+NbrpRk/+MEP9POf/1ySVF5erosuukjnnHOOBg0apIceekgpKSn697//rb179+r73/++nn/+eaWkpHQ4FknVtV5lpTkjGgMAABjg2DYDABDHev21f1paWvjnhoYGWSwWBYOhnSeee+45zZkzR5I0YsQIjR49Wq+88kqnY5FUXetVJoUIAAAQQZQhAADxzJRmlf/85z/1P//zPyorK9Ptt9+uzMxMSVJJSYmGDRsWfp3L5VJZWVmnY92RnZ3ay+hDcnJCBZWaOq/OOm1o+DG6j9yZi3yai3yah1yai3yihWEwIQIAEN86LUR861vfUklJSZtjb7zxhmw2my677DJddtll2rFjh+bPn6+zzz47XIzoa253nYLB3q2lzMlJU2VlrRq9fjV6A3LaLaqsrDUpwoGlJZcwB/k0F/k0D7k0l5n5tFotphXpERl0iAAAxLtOCxFPPfVUlw82atQo5ebm6u2339bUqVOVl5enL774QllZWZKk0tJSTZgwQZI6HIuUqlqvJLE0AwAARA7NKgEAca7XPSJ2794d/nn//v36+OOPNXLkSEnStGnT9Pjjj0uS9u7dq23btmnixImdjkXKxncPSJJSkxIiGgcAABjYLKzNAADEsV73iLj33nu1a9cu2e122Ww2LVy4UPn5+ZKkn/zkJ1qwYIGmTJkiq9WqW2+9VampqZ2ORYI/ENR/3v1CkuSw2yIWBwAAGNiYDwEAiHe9LkTcc8897Y4lJyfr3nvv7fZYJNisR755cCT0eqIIAABAzxjsmgEAiG/ccTc7egokMyIAAECkGBKVCABAXKMQ0QaHnbQAAIDIoQ4BAIhn3HG3wZHAjAgAABAZBrtmAADiHIWINiQwIwIAAEQUcyIAAPGLO+420KwSAABEimFI7N4JAIhn3HG3wWYlLQAAoP81+QPauutgpMMAAKBP9Xr7znhyzayvaPMnFZEOAwAADFD+gKH8vHSdemJGpEMBAKDPUIg4yviCIRpfMCTSYQAAgAEqyWnXf/2wMNJhAADQp1iDAAAAAAAA+g2FCAAAMODt2bNHs2fP1tSpUzV79mzt3bs30iEBABC3KEQAAIABb/HixZo7d642bNiguXPnatGiRZEOCQCAuEUhAgAADGhut1vbt2/X9OnTJUnTp0/X9u3bVVVVFeHIAACITxQiAADAgFZaWqohQ4bIZrNJkmw2m3Jzc1VaWhrhyAAAiE/smgEAANBL2dmpvT5GTk6aCZGgBfk0F/k0D7k0F/k0V3/lM+YLEVarJaqOA3JpNvJpLvJpHnJpLv6eRY7L5VJ5ebkCgYBsNpsCgYAqKirkcrm6fIzq6noFg0aPY8jOTpXbXdfj96M18mku8mkecmku8mkuM/NptVqUmZnS7rjFMIye/9UEAACIA5dffrm++93vatasWVqzZo3+7//+T4899likwwIAIC5RiAAAAAPe7t27tWDBAh0+fFjp6ekqLi7WySefHOmwAACISxQiAAAAAABAv2HXDAAAAAAA0G8oRAAAAAAAgH5DIQIAAAAAAPQbChEAAAAAAKDfUIgAAAAAAAD9hkIEAAAAAADoNxQiAAAAAABAvxnQhYg9e/Zo9uzZmjp1qmbPnq29e/dGOqSoV1RUpGnTpmnWrFmaNWuWXn31VUnS1q1bNXPmTE2dOlVXXnml3G53+D0djQ0kxcXFKioq0qhRo7Rz587w8x2dhz0dGwjay2d756jEedqe6upq/exnP9PUqVM1Y8YM/fKXv1RVVZWknueMfLadz1GjRmnGjBnh83PHjh3h9/3nP//RtGnTNGXKFF1//fVqbGzs0hhi30D/97y7uBbpHa5HzMX1iHm4HjFX1F+PGAPY5ZdfbqxevdowDMNYvXq1cfnll0c4ouh3wQUXGDt27Gj1XDAYNC688EJj8+bNhmEYxv33328sWLCg07GBZvPmzUZJSclxOezoPOzp2EDQXj7bOkcNg/O0I9XV1cZbb70VfvzHP/7R+O1vf9vjnJHPtvNpGIZx6qmnGnV1dce9p66uzvj6179u7NmzxzAMw7j55puNP//5z52OIT4M9H/Pu4trkd7hesRcXI+Yh+sRc0X79ciALUQcPHjQGDdunOH3+w3DMAy/32+MGzfOcLvdEY4surX1j+r7779vXHzxxeHHbrfbOPPMMzsdG6iOzmFH52FPxwaarv7h5zztuvXr1xs/+tGPepwz8tlaSz4No/0//M8++6xx1VVXhR9/8MEHxje/+c1OxxD7+Pe8+7gWMQfXI+biesR8XI+YK9quR+w9n0sR20pLSzVkyBDZbDZJks1mU25urkpLS5WVlRXh6KLb/PnzZRiGxo0bp1//+tcqLS1VXl5eeDwrK0vBYFA1NTUdjmVkZEQi/KjS0XloGEaPxjh/jz9H09PTOU+7KBgM6p///KeKiop6nDPyecTR+Wxx+eWXKxAIaNKkSbruuuvkcDiOy1leXp5KS0slqcMxxD6uR3qGaxFzcT3SN7ge6TmuR8wVjdcjA7pHBLpvxYoVevrpp/XEE0/IMAzdeuutkQ4JaIVztHd+//vfKzk5WT/4wQ8iHUpcODafL730kp588kmtWLFCu3bt0v333x/hCIHYw7/ziAWcp73D9Yi5ovF6ZMAWIlwul8rLyxUIBCRJgUBAFRUVcrlcEY4surXkx+FwaO7cuXr33XflcrlUUlISfk1VVZUsFosyMjI6HEPH52FPxwa6ts7Rluc5TztWXFysffv26e6775bVau1xzshnyLH5lI6cn6mpqbr00kvbPT9LSkrCr+1oDLGPf8+7j2sR83E9Yj6uR3qO6xFzRev1yIAtRGRnZ6ugoEDr1q2TJK1bt04FBQVMI+tAQ0ODamtrJUmGYejZZ59VQUGBRo8eLY/Hoy1btkiSVq5cqYsuukiSOhxDx+dhT8cGsvbOUanjc5HzVLrrrrv04Ycf6v7775fD4ZDU85yRz7bzeejQIXk8HkmS3+/Xhg0bwufnxIkTtW3btnC3+aNz1tEYYh//nncP1yJ9g+sRc3E90nNcj5grmq9HLIZhGD1+d4zbvXu3FixYoMOHDys9PV3FxcU6+eSTIx1W1Nq/f7+uu+46BQIBBYNB5efna+HChcrNzdW7776rxYsXy+v1atiwYVq2bJkGDx4sSR2ODSS33Xabnn/+eR08eFCZmZnKyMjQM8880+F52NOxgaCtfD744IPtnqNSx+fiQD5PP/30U02fPl0jRoxQYmKiJOmEE07Q/fff3+Ockc/j8/nTn/5UixYtksVikd/v15gxY3TzzTcrJSVFkvTCCy9o2bJlCgaDKigo0B//+EclJyd3OobYN9D/Pe8OrkV6j+sRc3E9Yh6uR8wV7dcjA7oQAQAAAAAA+teAXZoBAAAAAAD6H4UIAAAAAADQbyhEAAAAAACAfkMhAgAAAAAA9BsKEQAAAAAAoN9QiAAAAAAAAP2GQgSAiHnyySd12WWXRToMAAAwgGzatEmTJk2KdBjAgEYhAgAAAAAA9BsKEUAcKSoq0t/+9jfNmDFDZ555pm6++WYdPHhQP/3pTzVmzBhdccUVOnToUPj1W7du1Zw5c1RYWKiZM2dq06ZN4bEnnnhCF110kcaMGaPJkydr5cqV4bGWbxIefvhhnX322Tr33HP1xBNPtBvXk08+qcmTJ2vMmDEqKirS008/rd27d2vx4sXaunWrxowZo8LCQkmSz+dTcXGxzj//fH3961/XokWL5PF4Wn3ugw8+qAkTJoSPBQAAold3r09+9atf6ZxzztG4ceP0/e9/X59++qmk0DXCrFmz9Nhjj0mSAoGA5syZo/vuu6/Nz3355Zf1zW9+U2PGjNHEiRP10EMPqaGhQT/72c9UUVGhMWPGaMyYMSovL1cwGNRf//pXXXjhhZowYYLmzZunmpoaSdKBAwc0atQoPf744zr33HN17rnn6uGHH+7jrAFxzgAQNy644ALj0ksvNSorK42ysjLja1/7mnHJJZcYH330keH1eo3LL7/c+POf/2wYhmGUlZUZ48ePN1566SUjEAgYr732mjF+/HjD7XYbhmEYGzduNPbt22cEg0Fj06ZNxumnn258+OGHhmEYxltvvWUUFBQYd999t+Hz+YyXXnrJOP30042amprjYqqvrzfGjBlj7N692zAMwygvLzd27txpGIZhPPHEE8acOXNavf62224zrr76aqO6utqora01rr76auPOO+9s9bm333674fV6jU2bNhlnnHFG+NgAACD6dOf6xDAMY9WqVUZtba3h9XqN2267zZg5c2Z4bMeOHUZhYaGxa9cuY/ny5call15q+P3+Nj/3nHPOMTZv3mwYhmHU1NS0uo6ZOHFiq9c+8sgjxqWXXmqUlpYaXq/X+N3vfmfccMMNhmEYxv79+41TTz3VuOGGG4z6+nrjk08+MSZMmGC8/vrrpuYJGEiYEQHEmR/84AcaPHiwhgwZosLCQp1++uk67bTT5HA4NGXKFG3fvl2StGbNGk2aNEnnnXeerFarzjnnHI0ePVovv/yyJOn888/XiSeeKIvFovHjx+ucc87Rli1bwp9jt9t17bXXKiEhQeedd56Sk5O1Z8+eNmOyWq369NNP5fF4lJubq1NOOaXN1xmGoVWrVunmm29WRkaGUlNTdfXVV+uZZ55p9bp58+bJ4XBo/PjxOu+88/Tcc8+ZkToAANBHunp9Iknf/e53lZqaKofDoeuuu06ffPKJamtrJUmnnnqqfv7zn+vaa6/Vww8/rKVLl8pms7X5mXa7Xbt27VJdXZ0GDRqkr3zlK+3G9/jjj+uGG27Q0KFD5XA49Mtf/lIbNmyQ3+8Pv+baa69VcnKyRo0apW9/+9tat26dSdkBBh57pAMAYK7BgweHf3Y6na0eJyYmqqGhQZJUUlKi9evXa+PGjeFxv9+vCRMmSApNZ7z//vu1d+9eBYNBeTwenXrqqeHXZmRkyG4/8k9IUlJS+NhHS05O1l133aWHH35Y//Vf/6WxY8fqpptuUn5+/nGvraqqUmNjo7797W+HnzMMQ8FgMPw4PT1dycnJ4cd5eXmqqKjoWnIAAEBEdPX6JBAI6K677tL69etVVVUlqzX0vWl1dbXS0tIkSZdcconuuusufeMb39CIESPa/cx7771XDzzwgP70pz9p1KhR+s1vfqMxY8a0+dqSkhJde+214c+TQl+kuN3u8GOXyxX+ediwYdq5c2c3MgDgaBQigAHK5XJp1qxZuu22244b8/l8+tWvfqXi4mJNnjxZCQkJ+sUvfiHDMHr0WRMnTtTEiRPl8Xh0991363e/+53+8Y9/yGKxtHpdZmamEhMT9cwzz2jIkCFtHuvw4cNqaGgIFyNKS0vbnWEBAABiy9q1a/Xiiy/qkUce0QknnKDa2lqdddZZra5BbrnlFl1wwQV67bXXtGXLlnCfqWOdfvrpeuCBB9TU1KQVK1bo+uuv18svv3zc9YckDR06VLfffrvGjRt33NiBAwckha45Wr5IKSkpUW5urhm/MjAgsTQDGKBmzpypjRs36tVXX1UgEJDX69WmTZtUVlYmn88nn8+nrKws2e12vfzyy3r99dd79DkHDx7Uiy++qIaGBjkcDiUnJ4enUGZnZ6u8vFw+n09S6JuHSy+9VLfffnv4G4jy8nK9+uqrrY755z//WT6fT1t/Qd1DAAAgAElEQVS2bNFLL72kadOm9SITAAAgWtTX18vhcCgzM1ONjY367//+71bjq1ev1kcffaQ77rhDCxcu1IIFC1RfX3/ccXw+n55++mnV1tYqISFBKSkpra4/ampqwss9JOmyyy7T3XffrS+++EJSaJbmCy+80OqYy5cvV2Njoz799FM9+eST+uY3v2n2rw8MGBQigAHK5XJp+fLl+stf/qKzzz5b5513nh566CEFg0GlpqZq4cKFuv7663XWWWdp3bp1Kioq6tHnBINBPfLII5o4caLGjx+vzZs3a/HixZKkr33taxo5cqTOPffc8JKQG2+8USeddJK+973vaezYsbriiita9Z4YPHiw0tPTNXHiRM2fP19Llixpc5kHAACIPZdccony8vI0ceJEXXzxxTrzzDPDYyUlJbrjjjtUXFyslJQUzZgxQ6NHj9Ydd9zR5rHWrFmjoqIijR07VitXrtTSpUslSfn5+br44ot14YUXqrCwUOXl5frhD3+ooqIiXXnllRozZoy+973v6YMPPmh1vPHjx2vKlCm64oordOWVV+rcc8/tu0QAcc5i9HSuNQD0s02bNunGG2/UK6+8EulQAADAAHHgwAFNnjxZH330Uav+WAB6jhkRAAAAAACg31CIAAAAAAAA/YalGQAAAAAAoN8wIwIAAAAAAPQbChEAAAAAAKDfUIgAAAAAAAD9Jub3n6murlcw2Ls2F9nZqXK760yKaGAjl+Yin+Yin+Yhl+YyM59Wq0WZmSmmHAtd19vrEf6fMhf5NBf5NA+5NBf5NFd/Xo/EfCEiGDR6XYhoOQ7MQS7NRT7NRT7NQy7NRT5jmxnXI5wD5iKf5iKf5iGX5iKf5uqvfLI0AwAAAAAA9BsKEQAAAAAAoN9QiAAAADGluLhYRUVFGjVqlHbu3Bl+fs+ePZo9e7amTp2q2bNna+/evb0eAwAA5qMQAQAAYsrkyZO1YsUKDRs2rNXzixcv1ty5c7VhwwbNnTtXixYt6vUYAAAwX8w3q0R0qT7skWEYslgskQ4FABCnCgsLj3vO7XZr+/bteuSRRyRJ06dP1+9//3tVVVXJMIwejWVlZfXfL3UUwzB08FDo7yl6xm+xqqq6IdJhxA3yaR5yaS7yaZ4Eu005OWn99nkUImCaLZ9UaPnqD/XDqaN0/phhnb8BAACTlJaWasiQIbLZbJIkm82m3NxclZaWyjCMHo1FqhDx7837tfI/uyLy2QCAgcki6c55k5SZ1D8lAgoR6JZAMCibte0VPeXN1ciyKqqSAICBJTs7tdfHaPkmyi+LrFaL5s0e0+tjAgDQFUlOm/KHDZLN1j/dGyhEoMs+2O3W3ave15hTBuv0/Gydd2brWQ/1jX5JUoC9fAEA/czlcqm8vFyBQEA2m02BQEAVFRVyuVwyDKNHY93hdtf1au/1nJw0VVbWSpIaGnyyWqSvnpTR4+MNdEfnE71HPs1DLs1FPs1ls1lNy6fVaumwSE+zSnTZpu1lkqT3Pj2o/1m/Q5u2l+vDz9zh8cMNPknSi+8ckD8QbPVefyDIWlcAQJ/Jzs5WQUGB1q1bJ0lat26dCgoKlJWV1eMxAADQNyhEoEsMw9CbH5W3eu4vT3+k//7X++HHFTWN4Z9f2HIg/LM/ENRVy17Sk6981veBAgDi3m233aZJkyaprKxMP/7xj3XxxRdLkpYsWaK///3vmjp1qv7+97/rlltuCb+np2ORYIjCPQAgvrE0A13y4jsHOhz3NgW068Ch8OOaOm/45wZvaMnGhrf36zvn5fdNgACAAWPhwoVauHDhcc/n5+dr1apVbb6np2MAAMB8FCLQJf944dN2xxo8fu0rD60lslktCgQNNXj84fHG5kJE4JjlGgAAoD1sgw0AiF8szTDRwUONevvj8s5fGGOO7u3wk4sLNOmMvFbj2/dWqeRgvSTpzl9N0om5qeF+EdKRQgQTTQEAAAAAzIgw0V/XbteuA4fk9QU08Zib9VjmbQqEfz7nqy6d81WXfjRtlD4vr9Mtj27W8tUfauY5IyRJJ7nSlZ7iUO1RhYijZ0cAAIBOULkHAMQ5ZkSYaE/JYUnSlh2VEY7EXI3eUCHiO+edHH7OYrEoOfFIHevp1/fK6bApwW5VWnKCahuajno/hQgAAAAAQAiFCJMYhqFA8/7hHl983Xi3FBIGD0pq9Xx2emKrx6nNhYnUJEerQsQXzcs2WuzcX6OfFm/U4XqfAADA8Sy0iAAAxDEKESY5evmCxxfo4JWxp6UQkeS0tXrearVo3Kk54cctM0nTkhPkbQro433VuvKP/9HqV/eEX+MPBLXh7c8VNAx9etQuGwAAAACAgYFChEl27j9yU13qbmhVmIh1RwoRx7cUuXrWV8I/Vx0ObdmZlpwgSXpu077jXl/b0MRSDQAAAAAYwChEmOSR5z6WJE06I0/+QFBvfFgW4YjM09g8w6OtQoTdZlWio/VMibRkh6QjPTOOVtfYpE8+r2l+RDcuAACOxV9HAEC8oxBhkkN1oX4HLbtHPLZhR3hLy1gXnhHhaHuTlVt/Ml6SdONlYyRJqUmhGRH1beyWUXfUbhrxtoQFAACz0CICABDPKESYxGa1KD8vXZlpzvBzVbWeCEZkno6WZkihJpYPLyhSwUmZko4szZCkBHvoFEtufm95TaMyUkMzJl7YcqDPYgYAAAAARCcKESZo2THjS3npshzV5vrgofgqRCQe06yyPS1LMyRpxNA0SVJ6ikNpyQl648MyNW8uon3lteYGCgAAAACIehQiTPD+LrekIzfgf7vpAuVkJGrzxxWRDMs0DV6/Eh02Wbu4l1jL0gxJmnDaEFkkjRuVo7O/MlS7DxxqtW2nYbASFgCAVvjTCACIc6YVIrxerxYvXqxvfOMbmjFjhn73u99Jkvbs2aPZs2dr6tSpmj17tvbu3Rt+T0djsWR/Reib/QvHnSBJslosOv3kwfp4X7X8gWAkQzOFxxtod1lGe8YX5EqSRg4bpL/ceL6+c16+TshJPe7aattnbpOiBAAAAADEAtMKEcuWLZPT6dSGDRu0du1azZs3T5K0ePFizZ07Vxs2bNDcuXO1aNGi8Hs6GoslO/bXKDPN2epm3dMUWs7wP899EqmwTNPo9Yd7PHTVFRd9WT+bfpqG56bKbgudZuNG5YTHp399hCSputZrWpwAAMQNulUCAOKYKYWI+vp6rV69WvPmzQv3SBg8eLDcbre2b9+u6dOnS5KmT5+u7du3q6qqqsOxWFNZ06iThqS1eq5obGh2hLcptneGeOqVz/TOzsou94dokeiw6+zRQ1v1zDi6UHPBmGGSQtt5AgAAAAAGju59zd2O/fv3KyMjQ/fdd582bdqklJQUzZs3T4mJiRoyZIhsttBNrM1mU25urkpLS2UYRrtjWVlZXf7s7OxUM34F5eSkdf6idnibgsrLTW11jJycNGWkbtPgrJReHTvS1r6xV5KUkZbY5d+jo9c57Fb5/EHlj8iW1WrRS1tLdMXMr5oRatyK5fMnGpFP85BLc5FPtDBoEgEAiHOmFCL8fr/279+v0047TTfddJPef/99XXPNNbrnnnvMOHyH3O46BYO9+4Odk5Omysqe7+DQ4GmSgsZxx3AkWFV9qLFXx460JKdNjd6AxozM7tLv0Vkul1w5Xl5fQFXN/93chzx6/d39OnV4hplhx43enptojXyah1yay8x8Wq0W04r0AAAAfcGUQkReXp7sdnt4mcUZZ5yhzMxMJSYmqry8XIFAQDabTYFAQBUVFXK5XDIMo92xWNLkD8gfMJTUxtKFJIc9vPVlrBqWk6rahiZ9fbQ5/12GZiUf91xNHX0iAAA4moUmEQCAOGZKj4isrCxNmDBBr7/+uqTQbhhut1sjRoxQQUGB1q1bJ0lat26dCgoKlJWVpezs7HbHolllTaMONxzZfrLRG+oBkeg4vqaT6LDJ44vtHhG7DhxSZqoj0mEAAAAAAOKEKTMiJOmWW27RzTffrOLiYtntdi1dulTp6elasmSJFixYoOXLlys9PV3FxcXh93Q0Fq1uevBNJdit+t0PC3X/6g/13fNOlqS2Z0Q47ao67OnvEE1TUdMoSfrk85o+Of6PL/qyHnnuEzX5Y3+LUwAAzGLQIgIAEOdMK0QMHz5cjz322HHP5+fna9WqVW2+p6OxaNbkD2rRw29Lku5/6kNJoWUYx0p02tToi92lGU3NO3447Kbt8trKmFNz9Mhzn8R0sQYAAAAA0D19c4cZp/yB9r+5P3pryhaJDntML81oif3nl4zuk+MnN+ds5/6+mXEBAEDMokUEACCOUYjohnpP+7Mb2ipEJDls4R4SscjTPCOird/NDFarRUMyk/TR3mrt+Ly6Tz4DAAAAABBdKER0Q+1RTSol6TvN/SGk0DKMYyU67fIHgh3OpIhmnnAjzuN/N7NkpjklScX/eC9m8wQAAAAA6DoKEd1QW3+kEHHKCYN08dkjwo/b7BHRfAMfq8sz/r+1H0nq20LE0d779GC/fA4AAAAAIHIoRHTDspVbJUm3Xjlev/3BuFZjbd2stxQnGr2x17DSfcgjX/NuFol9tDRDks75qiv886PPfdxnnwMAQCyhRQQAIJ5RiOiB1OSE8M8/nDpKk87IkyOhjaUZMTwj4kBlnSTprC/nKj3Z0Wefc9aXc5WbmSRJavQGtL+irs8+CwAAAAAQeRQiusg4alPv1KQjhYjzxwzTFRd9uc33tDR5jMUZEfWeJknSt4/qg9EXHAk2/fHqs/W9C0ZKYgcNAAAAAIh3FCK6qGVWQ2aaU3Zb19LW0sAyFmdEtOwQkpKY0MkrzTHxjNASDfchT798HgAA0eqo7z4AAIhLFCK6qGWGwCXnfqnL70ls7hHh8cXejIg3tpVJkpL7sD/E0VISE5Se4ojJXAEAYDYLTSIAAHGMQkQX1Tc2zxBI6voMgaTmHhGxtjTDHwhqX3mtJMlq7b8roSSnXQ0xlisAAAAAQPdQiOiisqoGSVJKYtdnCLT0iIi1pRlVtV5JkrWfv45JdtrV4KEQAQAAAADxjEJEF/3jhZ2SjhQXusIZozMi6hpCy1B++e2v9uvnJicyIwIAAEM0iQAAxDcKEV1UcFKmJGl4bmqX32O1WOR02GJuRkRdY6gQkdqNZShmSGJGBAAAzWgSAQCIXxQiuihoSK7sZFm6uVwhyWGLuQaMOz6vliSlJPVPo8oWyfSIAAAAAIC4RyGiixo9Td1altEi0WFXoze2ZkQ8t+lzSVJasqNfPzc50R5zy1gAAAAAAN1DIaKLGn2BHhUikpyxtzSjRX9t3dkiyWlXkz+oJn+wXz8XAICoQosIAECcoxDRRY1ef89nRMTY0owW/bl1p3Sk8MGsCADAQEeHCABAPKMQ0UUNXr+SnbZuvy/RYZMnhm6sDSP0NUx/N6qUQrNHJAoRAAAAABDPKER0kccbUKKjJ0sz7DG1NMPXFFoWcdHXTuz3z26ZcULDSgAAAACIXxQiuiAQDMrbFOhRz4REhy2mvuGvqfdKklIS+39GRDKFCABAL23cuFGXXHKJZs2apRkzZuj555+XJO3Zs0ezZ8/W1KlTNXv2bO3duzf8no7GIoEWEQCAeEchogtadr3oWbPK0IyIliUP0e5ARZ0k6cQhqf3+2S35bfRQiAAAdJ9hGPp//+//aenSpVqzZo2WLVumm266ScFgUIsXL9bcuXO1YcMGzZ07V4sWLQq/r6MxAABgPgoRXdAyoyGxhz0iAkFD/kBs7ARxqN4nScpMdfb7Z9OsEgDQW1arVbW1tZKk2tpa5ebmqrq6Wtu3b9f06dMlSdOnT9f27dtVVVUlt9vd7lgkWehWCQCIY/27P2OMarkx7tnSjJab64AS7N0vZPS3mjqfLBYpLdnR75+dlEghAgDQcxaLRXfffbd+8YtfKDk5WfX19frLX/6i0tJSDRkyRDZb6O+wzWZTbm6uSktLZRhGu2NZWVmR/HUAAIhbFCK6oOXGuGfbd4YubD6vqNXoL2WbGpfZgkFDz7y5V8lOe79v3SlJSQ56RAAAes7v9+svf/mLli9frnHjxumdd97RDTfcoKVLl/b5Z2dn935JY05OmiQpKTFBFosl/Bg9Q/7MRT7NQy7NRT7N1V/5pBDRBb3pEeFtCr33iZc/i/pCxMefV8swpK+dNjQin2+1WuR02NToDWhfWa2cDpuGZiVHJBYAQOz5+OOPVVFRoXHjxkmSxo0bp6SkJDmdTpWXlysQCMhmsykQCKiiokIul0uGYbQ71h1ud52CwZ73g8rJSVNlZWhJSWNjkwzDCD9G9x2dT/Qe+TQPuTQX+TSXmfm0Wi0dFunpEdEFjb6ez4g456uhC5m87BRTY+oLe0oOS5K+e35+xGJIdtrV6PXrlkc36+a/vhWxOAAAsWfo0KEqKyvTZ599JknavXu3Dh48qJNOOkkFBQVat26dJGndunUqKChQVlaWsrOz2x0DAAB9gxkRXdCbpRnOhNC3+iXuerPDMl2D1y+7zSqnI3K9LJKcdtV7msKPv6is07Cc/t/BAwAQe3JycrRkyRLNmzdPluZuj3fccYcyMjK0ZMkSLViwQMuXL1d6erqKi4vD7+toDAAAmI9CRBeECxE9vEFv8gdU19jU+QsjrNHrV3JiZE+JZKddVYe94cf7KUQAALph5syZmjlz5nHP5+fna9WqVW2+p6OxSDAUG1t+AwDQU6bddRYVFcnhcMjpDG37OH/+fE2cOFFbt27VokWL5PV6NWzYMC1btkzZ2aFeCR2NRZMGr182q0UJ9p6tZBl9crY2bS83OSrzNXj8PdoZxFQWaV/5kXVJ9Y00rgQAAACAeGJqj4h7771Xa9as0Zo1azRx4kQZhqEbb7xRixYt0oYNG1RYWKg777xTkjocizYeb0BJTnt4mmd3pSU75PEFZBjR/Q1Ho9ffo+UnZnIf8rR6vGN/TYQiAQAgcnp6zQEAQCzo02aV27Ztk9PpVGFhoSRpzpw5Wr9+fadj0SZ0g97zvgktO2EeqIzuPhENUbA0Y8Y5IyRJt/10giRpyycVEYwGAAAAAGA2U+8658+fL8MwNG7cOP36179WaWmp8vLywuNZWVkKBoOqqanpcCwjI6PLn2nGvt1Sx/ul+g0pLcXZ4z1Vx4/O09Ov75U1wRbV+9z6/EG5chJ7HWNv3n/plC9rxqSRSnTa9ZWTs3Wgojaqc9YfBvrvbzbyaR5yaS7yCQAABgrTChErVqyQy+WSz+fTH/7wB916662aMmWKWYdvV2/37ZY63y/1cK1HDpulx3uqBppCfQ7KKmpVmZnUo2P0hwMVdTrZld6rvWPN2nu2VlJeVrJ2H6gZ0HsDszeyucinecilufpz325Ev+heyAkAQO+ZtjTD5XJJkhwOh+bOnat3331XLpdLJSUl4ddUVVXJYrEoIyOjw7Fo0+ANKNHR85pNy24bjd6AWSGZrrR5e1FHDxty9oXkRLs8voACwWCkQwEAAAAAmMSUu86GhgbV1oa+yTEMQ88++6wKCgo0evRoeTwebdmyRZK0cuVKXXTRRZLU4Vi08fh61yMisbkBZKMveneAaNmp4tzTXRGO5IiWHTyiuYADAAAAAOgeU5ZmuN1uXXfddQoEAgoGg8rPz9fixYtltVq1dOlSLV68uNUWnZI6HIs2Hl9Azl7MiEgMz4iI3kJEZU1otwpXdnKEIzmipXFmg9ev1KSECEcDAAAAADCDKYWI4cOHa/Xq1W2OjR07VmvXru32WDTxNQWUmNDzGRF2m1UOu1WeKP5mv9Hjl8NuVYK957+n2cIzIjzRW8ABAMB0NIkAAMS56GkIEKWCQUM+f1BOR+9u0BOd9qhemtHgbVJShLfuPFZ4RoSnKcKRAADQvyyWSEcAAEDfoRDRCW9TaBaDsxczIiQpyWmP6qUZ9R5/eAZCtEhqjmfZyq264c+vRTgaAAAAAIAZouvOMwqFCxG9nBGR5LDJ44vepRnv7KiMdAjHSUk80hfiUL1Ph+p9GpTiiGBEAAAAAIDeYkZEJ7zNxYPe9IiQontGRNCIzsWoyccsFSmvaohQJAAA9J/o/KsMAIB5KER0omUWQ697RDhsUbsNZUuxZda5X4pwJK0dm/N6ekUAAAYIWkQAAOIZhYhOmNkjwhOlzSobmnelyEiNrmUPVotF359yqn42/TRJR+IEAAAAAMQuekR0wrweEdG7NKPEXS9JGpyRFOFIjjd53AnhmRD1jcyIAAAAAIBYx4yITpjVIyLRGVqaYURhP4Y9pYclSSPzBkU4krYlOe2yKLSzBwAAcS8KrxUAADAThYhOmNUjItlpV9Aw5PMHzQjLVOve2Cep979jX7FaLEpOtNMjAgAAAADiAIWITpjVIyLRGVoF44my5Rm+poD8gegrjhwrOdFOjwgAwMBhoV0lACB+UYjohHk9IkLvb/RF184ZZc1bYp5/Zl6EI+lYerJDNXXeSIcBAAAAAOglChGd8PgCskhy2HuXqpYZEdHWsPLgIY8kaVKUFyJcg1NU4m6IdBgAAPQ5OkQAAOIdhYhOeH0BOR02WXo5RbJlRkS0Lc2oa96JIj05urbuPNagFIfqG5uistknAAAAAKDrKER0wtsU6HV/CCm084MkNXija2lGbYNPkpSSlBDhSDqWlpSgQNBQQ5QVcgAA6At0iAAAxDMKEZ3wNgVM2U0iWpdm1DU2yWG3mlJs6UupyaFCyf7yOgWZFQEAAAAAMYtCRCe8voASTbhJT27ZNcMXZYWIhqbwTX40S2teOrL0n+/p2Tf3RTgaAAAAAEBPUYjohMfnl8OMGRFRumtGVa1XmanOSIfRqbSjiiUb3v48gpEAANC3mPgHAIh3FCI64W0KmjIjwm6zKsFujbpmlWVVDcrJSIp0GJ3KOKpYUu/xq8kfXQUdAABMRZMIAEAcoxDRCbN6REihnTOiaUbEoTqvqmu9GjE0LdKhdCrjmFkbdY3RVdABAAAAAHQNhYhOeH0BOezmFCISnfaomhGxv6JOknRSDBQijtWy7SgAAAAAILZQiOiEz2/mjAi76jzRcwNdXeeVJGWmJ0Y4kq65bPIp4Z+3762KYCQAAPQlmkQAAOIbhYhO+JqCctjNSVPe4GR9UVlvyrHMUNcQKoqkJUX/rhmSNOWs4br/hkmSaOQFAIhvtIgAAMQzChEdMAxDvqaAHCY0q5SkQSlO1UfRkoLahiYl2K3hHT1iQcvslA1vfy4jBqsRhmHoqVc+08GaxkiHAgAAAAARQSGiA/5AUIYkZ4I5aUpKtMvnD6rJHzTleL1V2+BTWnKCLJbY+d7F2hzroXqf3tlRGeFouq+sqkFr39irB9Z8GOlQAAAAACAiKER0wNsUKhiY1awyJdEuSWqMkoaVtY1NSktyRDqMHjt4yBPpELqk0evXfU9u02clhxUIhGZxlFcxIwIA0LYYnPAHAEC3UIjogK8ptNWmw6QZEcnOUCGiPgoaVnp8fn2w262q2ti4me8pfyAob1NAH+w+KG+Etk596tXP9O7OSq3auEue5hgavH7t+uKQvE3Rs50rACB6xNJsRQAAusse6QCima95CYVZPSKSE0NNIRuiYEbEnpLDkkJ9ImLN5LEn6MV3D8hq7fgizR8I6rq7Xw3f7E8pHK7LLjylw/f0hera0O4kaSkONXiP5Pv2x97R104boqtmfqXfYwIAAACASGFGRAfCMyJMWpqR3Lw0o8ET+UKEzRa7/+m/V5Qv6ch/n/Ycrve1mnFQ6o7MjiUtsyC2fFKhQ3W+VmOfHjgUiZAAAAAAIGJMvxu97777NGrUKO3cuVOStHXrVs2cOVNTp07VlVdeKbfbHX5tR2PRwNfcI8KsZpUpUVSI8PhCMfzy21+NcCTdl2C3yWqx6PUPy/TOjkoF21lMe+zME38gMk1Cj+4JsvaNva3G3Ic9emdHpZ7btC/83wQAMLDRIgIAEO9MLUR89NFH2rp1q/Ly8iSFtiq88cYbtWjRIm3YsEGFhYW68847Ox2LFl5/S48Ic2ZEZKQ6ZbNatKf0sCnH642a5m/mT8xNjXAkPRM0DJVXNej+p7bpkWc/bvM1xxZ8ahua5A8E+70g0eDxh/uMtNVg8/6ntmnVxt36xX+/on/8e6cCwejYVQUAAAAA+oJphQifz6dbb71VixcvDjdY2rZtm5xOpwoLCyVJc+bM0fr16zsdixZmN6tMctr1JVe6Pi+vNeV4vVHT3LcgI80Z4Uh67/VtZXr0uU+Oe/7Y3Uma/EFdtewl3fzXt/oslkavX8+8uVcHKusUDBrh53IyksKvmXRGnh74zXn6w88mHPf+F945oC8qI7OEBAAAAAD6g2nNKu+55x7NnDlTw4cPDz9XWloanh0hSVlZWQoGg6qpqelwLCMjo8ufm51tzjf6OTlpxz2X2Lx+f2huepvjPTEozalDdV7TjtdTq1/bI0lyDR1k+rEj8bu98n6J5l9e2KrLuP3zmlavqagJbZl58JCnz2K8Z+V7emHz53ri5c/0nQtG6kcXn6Z6j19fHpEVLjCcO2aYTsjL0Al5bR/DZ7TOYaTPlXhDPs1DLs1FPs3h9Xp1++23680335TT6dSZZ56p3//+99qzZ48WLFgQvs4oLi7WiBEjJKnDMQAAYD5TChHvvfeetm3bpvnz55txuG5xu49889xTOTlpqqw8fpbCwebmhvW1HlWaNHfEKqmuoanNz+svR28fanYc7eXSbK7sZJW6G1o99/mBmnBDUEla9eLOdt9fUXG4T7ZGKz1YF/753U/KVXRmnvyBoIZkJIafT7RZOszRrn3VGjk0dEPSX/kcKMineciluczMp9VqMa1IH4uWLVsmp9OpDRs2yGKx6ODBg5KkxYsXa+7cuZo1a5bWrFmjRYsW6X//9387HYsImkQAAOKcKbfXmzdv1meffabJkyerqKhIZWVl+slPfqJ9+/appKQk/LqqqipZLBZlZGk7tCgAACAASURBVGTI5XK1OxYtjmzfaV4rjUSHLeJNCd1t9CmINQt/WKjvXTBScyafonGjciRJG987oM/La+Xx+WUYRniHij9ec7Z+96PCVu+//bF3VHXY/Dxs31sV/rmyxqMP94QeDx50ZGlGsvNIscSVnazs9ER957yTj3pfo+lxAcBAUF9fr9WrV2vevHnhYvPgwYPldru1fft2TZ8+XZI0ffp0bd++XVVVVR2OAQCAvmHKjIirrrpKV111VfhxUVGRHnzwQY0cOVL/+te/tGXLFhUWFmrlypW66KKLJEmjR4+Wx+NpcyxaHOkRYU6zSklKdNjD2zlGyqF6X+cvinJJTrumTThRkpSV5tQ7Oyr1xMuf6YmXP5MkXXp+vhIdNo06MVe5GUlSRpKWXnO2tu2p0mMbdmh3yWF9sNut88cMa/P4Oz6vVmZ6Yui93WC1WBRo3sWjrrFJD6z+UJKUmpyg0/Oz9cFut9JTHOHX/+FnX5MU+m/y0nslch/2aON7X2h20cjwebflkwqdcsIgDUqN/X4eANCX9u/fr4yMDN13333atGmTUlJSNG/ePCUmJmrIkCGy2UL/rtpsNuXm5qq0tFSGYbQ7lpWV1eXPNmMWSsvynMTEBNlsVpbr9BL5Mxf5NA+5NBf5NFd/5dO0HhFtsVqtWrp0qRYvXiyv16thw4Zp2bJlnY5FC29zISLBbu6MCK8vIMMw+mRpQFfsaO6dsOTHZ0Xk882W5Dz+NF710m5J0mlfOnIROTgjSUMzjxQW2pv5+sm+ai3953s6cUiqlvx4fLdiyUxztrkzxqAUh3424zRJkt12/Pk0KMWhZb/4uu761/va9plb7sMeubJT9EVlnZav/lDjC3J1zazR3YplIHni5d3atL1cxdecHbH/rwBEnt/v1/79+3Xaaafppptu0vvvv69rrrlG99xzT59/dm+Xih69PMfjaVIwGGT5Uy+wfMxc5NM85NJc5NNc/blUtE8KEf/5z3/CP48dO1Zr165t83UdjUUDnz8oh90qq4k3NolOmwyFihyJjj6tA7XruU37JElDs5Ij8vlmO2lo+1W71MSEVo/zhx1pzrn543JdcNSMiGDQkNVqUWlzb5D95XXqrkavXxeMHaahWcl6/MVdCjbPjhgxNK1LN8iTxw3Tts/c4a1HW5aPVFSzXKMjz7wZOqc3f1Kh8QVDIhwNgEjJy8uT3W4PL7M444wzlJmZqcTERJWXlysQCMhmsykQCKiiokIul0uGYbQ7FikGTSIAAHHOvK/645CvKWDqsgxJ4eJDJJdnnHJChpKcNtN/t0hJTTpSbJh5zohWj4/+WQotsym+5mxJkvOo3z8QDOqG+17TEy/vVl1jqJlnd2fCNHr9qvf4ley0a0rhcP3tpgv0t5su0EM3XdDlb+lTk0LLNl55P9Q/pb45lr1lVHo7MnhQqBnoh59Vacfn1br5r2+Fd0kB+tKDaz7U85v3RzoMNMvKytKECRP0+uuvSwrthuF2uzVixAgVFBRo3bp1kqR169apoKBAWVlZys7ObncMAAD0jch8JR8jfE1BUxtVSqGlGVJkCxG+pkCrmQHx5JKJJ+s/734RfnxsIUKScjKSlJ+Xrvd3u3Xv/32g6jqvkhw21TY06Zk39+kbZ4W2oG3yBxU0jC7PiLn/qW2SpMBRU3O7O5tmhCtNdptFjd7QjIg/PPJ2eKw7sQw0/kCosexr20r12rZSSdKCB9/U6fnZ+vklo1sVnYDeqq716sV3DuirJ2fp7Y8r9PbHFbpw3AmyWvn/Mxrccsstuvnmm1VcXCy73a6lS5cqPT1dS5Ys0YIFC7R8+XKlp6eruLg4/J6OxiKFswkAEM8oRHTA5w/IYTd7RkRLISJyO2c0eP3KzexeE8Zo9yVXmkoOhrbzPPpePSmx7VO8tiE002DrroOtnrdaLOEZEYYkjzfQakvQjuzcf0iSlNiLm16rxaITh6Sp0euX95hi1cFDnm43zxwIfE0B1dS13YD1g91u/WvjLl3+jVH9HBXi2eZPKvTsW/v07Fv7ws99uMet0/MHRzAqtBg+fLgee+yx457Pz8/XqlWr2nxPR2MAAMB8LM3ogK8p1CPCTOGlGd7IzYho8PiVknj8TIFYtuD743TPr/7/9u48MKryXAP4M0tmkpmsk30hbIEQCBAWQdyQuIBUwC4qtVLvRXHp1brfS9VCq10MaG2rWGytWi2V2qooiKAWUJBFEMK+Q8KShWSyTJLJTGY5948zczJJZibbmZlk8vz+mpxvlsOXk+Gc97zf+14FAFLw6PpJWRgzxHtqrdnqPRDkFARsP1Qh/fz3z4/7/EyzxY4/rz2MFR8eRF2jVborP70go0f/BjdTUwsOl9Tisz1iurfKdZe12RLatq+CIEAQ+t665bXbSzpsG54Ri9f/dwYAYPPeizhw2hjkvaJwZbU5YLbYOmzfur88BHtDRERE1D8xEOGHze6QtWMGEPqlGYIgwGyxd/kuf38RoVZKNS/umzsGo7LjcVthTqe/v8U/mojE2Eif4zsPV3rd7nQKePJP27HzcCW+PV6Fx175WhrrbZvN22bkAAA+/EpsRXrVOLFgWiizaADgrU+P4e6izW222R1OOJxOv6+rb2rBsdLagO1Xi038/MvHtBapTEvUQalUQK0SgzhfFl/0+lqi7ti87yIeePFLfPx1ibQtJSEKM6cMwt4TVSirbsK/tpzC8XOBO95pgOh7MV8iIiJZMRDhh80hBDAQEZqLSkuLA05BCLuMCE85WXH43zsmem2T6eauAzEoJRoPfX8sJucm479nj2rznBkTM73WmLDZHbhn2WapjoOn3mZDAMDkUSltfjbEiIGNUNYVAYCtB8Q7vu5OIIIg4Gev7UDRqn1+X/fK+wew7N19qK6Xv3jk+p2l+HzPeSgVCiy6eTSm5IlzNyo7AQCQZtADAJpCnE1C4eGdjR0zpCJUSsyYmAWVSolnXt+FT3eew4Zd50KwdxR+WCWCiIjCV3jdFpeZze6EXubMgRid2BWhut4i6/t21c4j4h3+cMuI6K7Z0wbjuklZiNKqkZ0ag598dyxOX6yXxh+5dTxOXaxDk8XWoUikeylASnxUm84Mi24e3eauvFwSYsSMjZUfH8biOyb6bVcaDF/uu4j9p40wmiwwmqwwmqw+n2syt+B0mQkAUNfYgqQ4+WpcCIKAf285DUAMjigUCtw/Lx9zrmxCRqLYmnbBzJH47d/3Ilavke1zaWBqvyzp/+6YgMraZowdloiEGC3yBifg4BlxCRCLVhIRERH5x4wIP+wOp9+76j0RHRWB7NRoHDoT/DXrTqcg3dFLjPO9HGEgUCoUiNK2DcZkp0ZLjwelREMfGQFBaFvPo7LGjHXbxQJ1v73vclyZnyaN5WTFdblNZ2c8i1ImxIoZEdYWB3751m6pFkWovPPZCRw4bcTFqiZpm6/aEcUnW4uB/uadb+F0ypdv7Fmg0jMTJTNJL/0eRmTFIzslGjZbaLNJqP9rsbf+3d07ZzRysxNwzfgMJLgyljyDu0cCuBSJiIiIKBwwEOGHze6UfWkGAOQOSkBJRYOU4h4sDc2tBdbSDbqgfnZ/EKFW4Y3FhXjtielIiNFKFxZNHoXpTrmyJr4zbTAUCgXuvnm0NNY+sNEbY4cnSo+HtMuAOHG+TrbPkctfPzmKylpzh+0VNW233bNsM74svojfvPMtjPUWmMwtsNmdEAQB5cYmvL3hWJvghT9NruP5/nljcNesUT6fF62LQF1TCxY+vwkfbD7ZjX8VUSuza3nPpJHJmDq6Y+aTzuPv39rigM0e2oAh9W8sEUFEROFuYOfndyIQGREAkBQfiRa7E03NNmmpRjCYmlrvILtrVVBHEa6uGwmuopM1JguSXRkK7rafM6dkd3idTsZAxPzrcjAkLQazrhoGU13bi/l/bTmNpf/lvRtIoHgeO95sP1SB7YcqcP+8MZgwIhkA8NanR3GmvAGxughkJOlx7JwYQPnbBjEr5/lV38JosmJybjJysxOw6vMTAIAtxWX485PXdvjba2y2QR+plrId6s3iPsV28jcUo9PgSIl4h3r15ydwtUcWC1FXuWvCTB6V4jXzaXpBBi7VNSMhWottB8tR22BBSgIDvtRzMiXYERER9UnMiPAjUBkRUe4WnkEuPljf1LqWX8tARKfSXFkj7rv6Z8tNeG/zKQBt07B/cO1wjB2WKOu6cJVSiSvHpiNSI154/3LhFNw1KxcjsuJQGoJsmg3fiMX3po1JxQ2TxUKfKfFReOj7Y2GIbe0SsvKjw3j05W34cOsZ7DhcicoaM6K0avz0B+M6vKe7tsSe41VSEMKttKKhw88//cNWLH5tBxpcAYhLrt9LSoL/uhMxHgVHvRUYJeoK97HjK/MpOzUGj99egIm5YiCusZnHGhEREZEvzIjww+5wIiIAGRFK11ueulAv3WkPBneBzGX3T4NKyRhUZwxxkYhQK6VAxPqdpdKYZ/HK2ZcPxuzLBwd0XwalRGNQSjSarQ6cvFAPa4tD1qUgnTl9sR4js+KwaM4YAMAPrx8hjY3IisdP/7BV+tlstWP/KXF5hVajwqyp2dBGeA98pSfqUG5szfi4tiADW4rLUFlrxvDMOGm7+9itqrNg7fYS3HH9SJTXmKGJUEpr9H3JSon2O07UFWZXIKKzQr/uLjdl1U0YlhEb8P0iIiIi6o94NepHoDIi3Msxik91bS28XC5WNUGjVsIwwAtVdpVSoUBGol66O9/+Ln0otLZ/DVw2TWOzDeXGJhw4LR6fpqYWmMw26L20MgUAfaQa103KwpihrctFyo1m5A1OwKuPXoPpBZlQKBRY+l+XSeN3zcrFs3dPwbyrhkrb/vjw1ZgxMQsA8Pq6o20+wzOTwb08pry6CemJ+k4LhMboWvd7KC8MqYc6y4hwy0gSW8bWNoSmMxKFhyAnvREREQUdMyJ8EAQBNocTarX8izTdF2yphuBlQ5yrbMB/vr0AoO3dfPIvI0mPkxfqUNtgle7KL5ozupNXBY47GNBgbuk0E6AnPtt9Hqv/01rQcdkD07B45U44BQHD0r1fxCsUCvzohpFosTlw/4tfStsbzC1tggSD02Lw0++Pgy5SjZGD4gEAWcnRmDwqBQ6HExFqFVp8dLcwuZZjpCREwWyxw+kUUFrZiPEeRT198ezUYWlxwO5wwuEQuDwpTJVWNMDmcCLHI6OmN156bz9qTBZcrBa7xHRWC0atUkKjVqI5yEvviIiIiPoTZkT44HAKEAQEZmmGQoEYXURQ1xCfv9QIANIFIHWNLlKN6noLHl/xNQBg1pRsTBsTumKHqa56CJW1zbK/tyAIbYIQgFj9312PorM0c02ECk/dOQnpiWJtjcJJWR2eUzAiqcMxqFQopAKhhtjWbB2jK/BzpsyEM2UmxOk1GJIWg5IKE6pNFjQ22zCsCxebQ9LE/U5NiEKzxY431x/FA7/7ElZeKIYVQRDQbLXjl2/txu/+Wdzr99v4zTm8/P4BHDxjlIIQeYMTEKv3nhnkKVKrRo2JGRFEREREvjAQ4YPdIbZeUwdgaQYAREdFoNGjnWaguVP5H7glP2ifGQ7ap2FflpcSoj0RudenB6Loorf3PFpaKz2ePKrzf3tOVhxGDxEzfrJTYjp5tnf5royhNz89itKKBvzq7T3Ye6IK+qgITB2digazDR9vOwug844ZAJAYF4k3FhdiYm4y6hqt2HG4EgDwwO++RF2jtZNXU3+xed9F/M9LXwEQv+9OXajHf769gEdf2daj3/M/N53CPo9WstcWZODJH07oUn0dp1PAN0cvSbVSiIiIiKgtBiJ8cPeAD0RGBCCm2DcFNRDhKrSmZTp6d3imYWclR2Ooj+UJweIOjLz16TG/zxMEAdsOlEu/966oa+zYovMfX4gZEj+emYs4fddazd42IwcPfW9sjwv1PXLreFw5Ng3nKhtRXtMkbY9QKzF2mLgUY/uhCgBt6z905upxGR22bdl3sUf72J9YWxw4XVYf6t0IuHOVYtaXu67Pb/7+LVZ9fgL1jS04cNrY6/efc+XQzp/kYnUtMTp8tgYCF/tTj/C4ISKi8MZAhA92h3gSEKiMiJioCFTVyZ9e78v7X54BACkFnrrv3rmhqw3h5m792pm9J6rwxvqjHZZa+FPf1BqI+NENI6XHc64Ygmn5XV+OEqFWYsLI5C4/vz2lUoE4vRbNVjtMTa3ButKKBqhVSnz3mmHSNl8FNL1JM+hw33fHAgBuvGwQhmXE4khJbSevCiy7wwlTU8cA0HN/240Pvjojy2d8uqsUv377Wxw/F9p/a6DZ7A4kxUXilqs6Bgy6GwywetQqyR9qwIpHr+lWTRZ3wPCLby/g7qLNQW+3S+GB5ZyIiCicMRDhg80unogGKiNCrVKiut7S5oQ3UNztJ6n7slL0rY+TQ98GUqlUYMaETOg7aSG46+glAMBX+8u7/N71TWL6+rQxaSicmCltv+XqoT7bbwZKlFYFh1PA+h0l0rYfz8wFIK7Td+tqlobbzVcNw8rHp+P2whykG3SorDVLy7CCzdJixwMvfolHXt6GNVvP4HBJDZqtdlTWmHG2vAHrtpd0eI3d4WxTfNOXcmMT6l3LEZqt4nfMN65jIlw1Wx3QadVe22uaLd1byvTz13dJj0cOiu92q9zLR6e2+Zn1IoiIiIjaYiDCB5srIyIQ7TsBIDtVvKhtMHe8Gyq3c5WhbzvZX+UPTcTLj1yNPz02PdS7ItFHqWG22nG4pAbPvrXb64WpoQcdNdxdVe68cSQUCgXmXTUUMyZkdtoeMxBys8Vgg8ncmhHhzsrIdLVHjNKqEN2NjAg3TYQKCoUC+qgINJhteO5ve2TY4+45fbEeL723Hw7X7+7jr0vw4upi/M9LX6HU4++1fZDkmdd34Z5lm/3+TR8rrcXTf9mFR1/5Ght2nZNq0ew/XR3WywSarXZEatUoGNExG6epm4EId4ec6yZmYXpBxyU9nbmtMAdJHm2S3cEgIiIiIhIxEOGD3VUjQh2gjIg0g9hZ4LxrXXMgBaKw4UCij4zoU60eo7RqCALw4upilFQ04J5lm1Hcriiee9mPStn1IEJtg1V6fwCYd9VQLHBlIQTboJTW7JM7rh+B1/93hpSVEaVV49HbxmPJf13Wq89wZwq5O8oEy6VaM379zrc4ecF73YaVHx2WHp8pM0mPbXYHLrm6pXy665yUtdWeZ2HGT3aUoMzV8aHGZJV+x/2N3eHs9HusucUOnVaNOL0Gv7n3cvx4Vi5um5EDbYQKTZbu1+OZXpCBH904EjFdKIjanlKhwBUey5mWvvENyo1Nfl5B1Fb4hgyJiIhEDET4YHPdiQxURoS7TeGFqsBcBHne+XTfjXvhJ1cE5LMouLylif/x3wdgdzjx8bazaGy2SResDqfg9wJu094LKKkwob7RihqTFQU5SQHb7+7QePzdTS/IgLJdQGXssESkJuh69RmOEC3J2HpAXC4zIiuuzd+kt6Dn86v2Sn/L5cbWJVa7jlTiT2sOd3g+gDadHposdpRWNkhFVyv74TKtihoz7l2+ReqI4U2NyYKyarO0ZCnNoMO1BZmYNTUbGUk6HDpjhCAIMFtseOTlbfj467M+36u6Xvzb6W0eUPv/O57+yy4cLqnp5bsSERERhQcGInywBTgjYkhaDFRKBSwBqBGxfmcp7i7aDIfTCbPFho9cJ93xPUjXp77HEBPZ5mf3MXrv8i1Ys+0s3lx/FJYWh5QNsezdfV7fRxAE/P2zE3j2rT1SF4pgFlD1R6FQYFhGLCbnJgeswOr4EAVdGswtiIvW4Gd3TpICkkDbQKFnDZAPvjqDxmZbh84Pxaeqce/yzXjm9V0wW+ww1luwee8FHDjTsUOESiUeC8tXF/vMpOirth4okx5X1noPpBw8Y4Td4fRaVHV8ThKMJivsDic+3XUOpqYWrP26pM1zbHYHPvjqDA6frUF1nbgsw9sSj+4YnNqxfe2Lq4tDVpOE+h9Fr8NhREREfRcDET7YA5wRoVAoEKvXeK2Y31vuIneVNc146PdbYW0RLzyULMEdFvKHGpCaEIWCnCTE6jUoun9am/F9J6thNFmkVpelFW3rCdjsYsHD3cdaixd+sqMUALBoTug7g7g98+PJ+Imry0UgXDcpC1e6Lly7UgCyN+wOJ/695TQ+330eX+0vR71Hq9T75o7B/OtGIFavwf3zxmD25YPx8iPXSJ1LPtlRit/+/VuvXTTsDgFl1U344/sHsG5HCd757ASsLQ5EqJVY/sAVeHx+AYZlxOKx2wqk18jRyjKYIj06xfzstZ0dxitqzPj3ltMA4LW9rruOiNnqwAXXMpyhGbGobbBKAefDJbVYt70EH3x1GsWnqqEAkJ7Yu4yb/GGJeO6eqR22tw+CEBEREQ1E3SsFPoC4a0QEqmsGAMTqNG3aE8rFfXJdUmGS1pkunJ0n++dQaCiVCvz2vrbBh+snZeELV7FJt6T4SEwYkYR9J6vhcDqhUorH8n0vbOnwnmbX8o1sL3dxw5VCoUCWqxaFpcXhtduCXE6er8P6naVex6Z6dFiYkpeKKXniz1Ha1kwQz2UZV41LxzbX8o6CnCQUn6rGifN1OHG+TnqOze5EYlwkEuMiMWaIAQDw3auH4sOtZ0NSfLQ3Pm03b1V1zTh1sR7TxqTBWG/BM3/ZJbXH9FbLxd3y1mK145wrEFFe3YTHV3wNAEhNiJI6sdSYrDCaLEg16JAcH9Xrfc9M0uPpBZPw63e+FfdFq5ZqdhD5xSIRREQU5hiI8MFdI0IdoIwIANBFqmG2yhuIcAqCVIn/9XVHAQBP/3gShnm5U0jhI0bXsXuEAgrkDzVg38lqXKptRnqiXrpgI5G73kaz1R7QQIRn9w+ga3fbC3KSkBIfhUvtlsssnJ2HGRMyER+tRUKMFoIg4Gev7cSlumaolArcXpjTptin29TRqfhw61lYWvpX8VpBELMaZl8+GO9tPoWif+xFjcmKpmYb/vHFSel5V+anec36inQFdJosdqlYp2cXjcraZlS6aqrUN7XAbLF32h63O4ZnxuGNxYWwO5wo+sdeNPez+SciIiIKBC7N8MEmZUQE7u5hpEYFS4u867Xbd+FITYjC8Iy4fncXlLpnxsSsDtsUita6IB9uFeuEWP0cb/nDDIHZuT4sPlrsiBCozhlOp4DKGjNWbzrZZvvTCyZ3+lpdZASeb7fs5jvTBgMQlyAkuH63CoVCqneRP9SA6ycPktqfenIvcehPrSQFQUCL3YFrJ2RAEyH+d1VjEoMJO49USs/785PX4u6bvS8rchfqvOSlvkROZlyHbUdLa6HvQVvYzqhVSkRp1P1q/inE+N82ERGFMdlu+/zkJz/BhQsXoFQqodPp8POf/xx5eXk4e/YsFi9ejLq6OsTHx6OoqAhDhgwBAL9jodbaNSNwbRsjNWo0NsubEdG+C4f7Th+Ft+ioCPzw+hH4ZEepVHdk1OAE5A8Vgwt7jl3Cm+uPtrkT7GniyOQ+VR8iWDKS9AAAk9l3rZYakwVNFrvXLANPTqfgKkTZWhT2xX8W42hpbYfndif7ouj+adBqVIj100bSfQf/srwUn89xL/XoTxkRLXYnBEFcXjF5VAr+/tkJacyztam/osLurJc/rz0CABiVHY9j58RlLE/+sACLX9uJ2gYrFv9oIp5ftRdA4JYoRWrVMJosAXlvIiIiov5EtkBEUVERYmLEk7cvvvgCTz31FD788EMsXboUd9xxB+bNm4ePPvoIS5Yswdtvvw0AfsdCzS51zQjcLYlUQxR2HG6Bydzi9yKjO9xr/f/7plF489Njsrwn9Q83TB6EGyYPAgCYLa1LDVITomA0WaW2kQBw/7wxiFArkZGoxz83ncLsywdDGxG4oFtf5b5bbnYFaOobrVi/8xxunTFcurh94tXtUCiAv/5fod/3ev/L0/h01zn84adXIcb199w+CLH8gSu8tl/1pyu1CgonZSEjSY+Jub47PahVSrFTj8xZWIFkcX2fRfoJxHS2jKJ9AGl8TpIUiIhQq/Di/1wJQRDadLOI08vzfdxelEblt50uERER0UAhWyDCHYQAgMbGRigUChiNRhw5cgRvvvkmAODmm2/Gc889h5qaGgiC4HPMYAh9irgtwF0zACAjUbwbW9dglS0Q0eTKsLhibBp0kRHIStbL8r7Uv3jecZ8wMhkbdp2Tfh6cFiMVRASAn/5gXFD3rS+J1KoRpVXj/S9P4+rx6Xjlw4M4fdGESbnJGDkoXro4FQQx2ygr2XdWxLcnqgAADWabFIhwFwsFxDoeiXGRPl/fG9FREZg8ync2BCAu4YjWRfSZFq1d0ewKmkS2C948f9/lOFNmQmZyNFIT/AdqFAqxCaIAYPGPJmJEVhwi1Mo2wQaFQtEmq8IQG5hWx1FatfRvIvKH1XyIiCjcyVqd7emnn8bXX38NQRDw+uuvo7y8HKmpqVCpxDutKpUKKSkpKC8vhyAIPse6E4hITPSfLt1VycltU3G1WnGNcHpanN+0397Is4unGjVNNkxKlicVuMpkRXqSHmmpcZiV2nH9czC0n0vqnd7OpyGu7YXa0Iy4Af07av9v/96MHKzacAw7jlbh9EUx3f/5VXvx8O0TcJlHR4slf/0G//z1bOgiW+sHrN9+FnF6LRLjInHJtQxq7Y5S7DpcIT0nI0mPqrpm3DI9J+TzPjE3BftOVMm2H4H+95woF1vPpiZFIzk5Bvd/bxy+3HsBY0amYszI1E5e3WpweixKyk3ITI9DSkosbp/pv3jv1HGZbZbYyCUxQQdriwOGxGiolB2z7UJ9fFDfwhIRREQUzmQNRPz6178GAKxZswbLli3Dww8/LOfbe2U0NsLp7N29g+TkGFRVNbTZVmdqhkIB1BgbA1boMUIQ77ZerDR1+PyeOlZSg5GD4mV7v+7yNpfUc3LM56isMXrpLgAAGSNJREFU1oBUYmwkpuQmD9jfkbf5nDE+Has2HMM/NrZdyvSHf+7D4Ha1Ao6eqpLqBwiCgD+9f6DDZ3gGIQAgIUaLX90zFYIghHzedRoV6hqsKK+oR2WNGZl+Mjw6E4y/9XfWi3UdVK65mzIyCVNGJnX7cx+9dRy+OXoJUSp06bUtzS2oavZdN6SnHDYxG+LCxboOdULknE+lUiFbkJ6IiIgoEALSr+6WW27BkiVLkJaWhsrKSjgcDqhUKjgcDly6dAnp6ekQBMHnWF9gtwuIUCkD2m0iQq2EWqWQ6jr0Vn2jFbUNVgxN4101apWVEo03FvuvbzCQKRUKZCbrcbGqqcNYaWUDslOjccvVw/DHfx+QakkAYiFFTyqlQmqd62aI1WL+dSMAoE90rqlvFC+uf/X2HpyrbMTvHrwS8QG48y8Xu90JfaQag3v5nRaj0+C6SR07ywSbZ8HQQLaLJSIiIurrZFlz0NTUhPLy1kJ4mzZtQlxcHBITE5GXl4d169YBANatW4e8vDwYDAa/Y32Bze4M2JIMN4VCAV1kRJuLm94oM4rt6TI7qe5PRG3dcf1I6fH988bg6nHpmF+YAwBYMDNXavNZVd+Myloz6hqt+O0737Z5jwe/Nxa3Xju8zbbbZuQgM6nv1GlxF7M852rz29cLJzqcAsYNTwra591540ip4GsguAuVsk4EdUYQWCWCiIjCmyy3ZJqbm/Hwww+jubkZSqUScXFxWLlyJRQKBX7xi19g8eLFePXVVxEbG4uioiLpdf7GQs3mcAa0UKVblEYl3aXsrWpXEbrkABXEIwpXOo9iiGkGnVTM88Yp2QBa/7beXO+9E40hVouxwxJh88iS0KiVyMkMTZ0WX8YOMyDNoENFjRi0bLE5O3lF6JyrbEB1vQUTR0Z0/mSZFE4MbNZEpEY8zix9PABEfUQfyKIiIiIKFFkCEUlJSXjvvfe8jg0fPhz/+te/uj0WasHIiACAxmYbik9V9/p9thRfxNsbjgMADLEMRBB1R5pBhzFDEpBm0Hdo9wgASfFRyE6NljIJ3K7IT8Nds0ZJQcvxOa1373+5cEqf+1tUKZW4f94Y/OLN3QCA2kYrBqNvLuVy7+OwDP+FJfsT99IMk1n++hNERERE/Ungr7T7KXuQMiLGDBWXolT3sqWeOwgRqVEFJYBCFE60GhUenz8BP7pxpM9aDt+fLi67yPRoiRulVbf5nohQK6VuCPqo4N3J747s1Bg8f9/lUKuU2HWkMtS749VrHx+WHl/WSVvS/iTd1bK5pHxgFoslIiIicuMVqw/Byoi4aepgAMBKjxPvnnBf/Lz62PRe7xMRdTRmiAHfmTYYi24ejQxX3YfLR3dsIVl0/zQ8Mb8A0X00EAEAKQk6TB+fgT3HLqGx2Rbq3WmjtKJBCpDceu3wPlHkUy7RURFIiY/CmbJ61DZYQ707RERERCHDQIQPRpMF8TGagH9OdqqYBn6mzNTj97hY3QSHU8Co7Hi5douI2lEqFfj+9OHITo3Bc3dPwRuLCzHcSw0IQ2wkRg/pG0V3/Zk6JhUOp4D3Np8K6X6cLquHsd4CU5O4XKHGZJHGYvWB/w4OtvE5SThcUovHV3wd8rmnvi18QnBEREQdsX+YF3aHE2XVTRg7LDHgn6VQKDAlLwWlFT1P1V2/oxQAEKFWybVbRORHONylz8mMwzXj0/HV/nJcMy4DOVnBLaxpabHjlQ8O4khJrbTtjcWFaG5pLeToWXMjXMTqWzNlNuw6B6dTwLyrhoZwj4iIiIiCjxkRXlQYzXA4BWSlBKftnk6r7nEbvdoGK3YcrgAA3Dd3jJy7RURh7rvXDIcmQokviy8G/bN3HalsE4RwO3G+DgDw0PfG9unlLT0VpW0b//9s93ls3hf8+SciIiIKJQYivHBXNE+I1gbl86K0apitPesrv8V1AjsqOx66SCa4EFHXxek1GJQSjZoQ1CvYdaQSGUl6TBvTWmejxebATtf2CSOTg75PweCtCHIDu2hQO4IQ6j0gIiIKLF65emG2iNkJ+sjg3I2L0qphdzhhszu6vLzi5IU6fLW/DA6nAJVSgYdvHR/gvSSicKSPjEBdY/ACESZzCx754zYAwOTcZCyaMwaJcZFYt70Uu49dQovNiSvHpgVtf4LN2wWmpaVngWgKb2GwAoyIiMgnZkR44c6IiNYFLxABoFtZEa+uOYSvD1Zg5+FKJMRooY1gfQgi6r5IjSqoF8L/3ny69bNd333XFmQCAN7eKLYhjgvDIpXtXTk2DT+4VmwJe+J8HQTeApfdK6+8gtzcXJw4cQIAUFxcjLlz52LmzJlYuHAhjEaj9Fx/Y0RERCQ/BiK8OFtuQoRaGbSK7e4lFd2pE2GIiZQeV9db/DyTiMi3SI0al2qbe1Uwt6u+2l+GbQfLpZ9jdeJ3rCE2EklxkbDZnQCAOH1wlsWFgiFW/LelJ+ox+/LBuPGyQSg3mlHHdp6yOnz4MIqLi5GRkQEAEAQBTz75JJYsWYKNGzdi8uTJeOGFFzodIyIiosBgIMKLY6W1GDc8Ecog5UW6MyK6E4hQKsQilwBw42WDArJfRBT+8oeKrUZ/+dZuVNc1B/Sz3vr0WJufb7o8W3qcZtBJj8M5IyJ/aCKemF+AWVPEf3ve4AQAQGWtOZS7FVZaWlrw7LPPYunSpVKHm4MHD0Kr1WLy5MkAgPnz52PDhg2djoUK82OIiCjcsUaEFy12J2J0wTsR1klLM7oeiLC0ODBqcAIe/N7YQO0WEQ0Ak0elYH5hDlZvOoUPt57BojnB6b6z7IFpberwaDyWl8XHhG9GBACMHmKQHifGitlt5yoakDjM4Osl1A1/+MMfMHfuXAwa1BqkLy8vl7IjAMBgMMDpdKKurs7vWHx8fJc/NzExutf7npwcAwDQatVQqZTSz9QznD95cT7lw7mUF+dTXsGaTwYivLA7nFCrglclSsqIsHQtEGGzO3Cxugk5WXGB3C0iGiBunJINo8mKz/ecx+xpQ5CZJH/r4s/3nJceTx2diqS4qDbjd83Khd3hxNhhiWHZttOXzGQ9Fs0ZjcvyUmG32kK9O/3evn37cPDgQTzxxBNB/2yjsRFOZ89zGZKTY1BVJS6RslrtcDic0s/UfZ7zSb3H+ZQP51JenE95yTmfSqXCb5CeSzO8sNmdXlusBUqUVrwT+OqaQ9IaaX8+3HoWAJASH9XJM4mIuqZwolgw8lhpbUDe/90vTgIQL7wX3JjbYTxGp8Ejt47HdZOyAvL5fZVCocC0MWlIiI3s/MnUqd27d+PMmTO47rrrUFhYiIqKCtx9990oLS1FWVmZ9LyamhooFArEx8cjPT3d5xgREREFBgMR7TgFAXaHgAhV8KbGs/DkyQt1nT7f1CR29bgiP3xb3BFRcKUkRCFOr8Gqz0/g+Dl5gxGNzeKd/qvHpePZhVOkAr1Ecrv33nuxbds2bNq0CZs2bUJaWhr++te/4p577oHFYsGePXsAAKtXr8ZNN90EAMjPz/c5RkRERIHBs8F27K6MhGBmRCiVCiyYmYt3Nh5HcxdaeCqVCiTEaBEXHd7rqIkoeBQKBeBakVb0j3346//NkAr99VatqyPE6CEG2d6TqDuUSiWWLVuGpUuXwmq1IjMzE8uXL+90LGTYzpWIiMIcAxHtNJjFO3fBXqM8xlW5/kJVIyblJvt97rHSWmg9CrsREcnBs1NQRY0Z6Yny1IqwtIj1b/TMhKAg27Rpk/R44sSJWLt2rdfn+RsLFQbtiIgonHFpRjvFp6oBoEMhtUCLc3XpOFcpFgfZe6IKZosYFDFb7Cg3NgEAjpTUoLreItWVICKSy6js1jXxR0rkW55x8IwRABCpYSCCiIiIiBiI6KDCKPZyHzkouEWqtBoVEmMjse9kNarqmvHKBwex8qPDAICif+zF03/ZBadTwAuriwEAc68cGtT9I6Lwd+eNufjOtMEAgAZziyzvaWmxY932UgDAoNTetzckIiIiov6PgYh2mlvsSIyNDGqNCLdUg5iF8eqaQwCAQ2drAADnLzUCAI6fby1kmRDD+hBEJK8orRrfnz4cWo0KlpbO69V0RXW9BQAw98ohXFJG1EWsEEFEROGOgYh2mq32kC17uGZ8BgCgtKK1d+ufXEEJAKhvtEqPWaiSiAJFp1Wjqq651+9zttyEs+UmAMDwzLhevx/RQMIKEUREFM64YLcdU1MLYlz1GoLN2/rp3ccudXj887smI04fmn0kovCXmayXMhl6qrSiAc/9bY/0c6SG2RBEREREJGJGRDt1jS2ID1G2QXJ8pPR41pRs/PdNo9qMn7pYDwBIM+iCul9ENLDEREWg2Wrv0WutLQ5crG5CmavArltKAr+3iIiIiEjEjIh27A4nNBGhic8kx7d26oiP0WJafhoi1EqUGc1Yt70EDWYbVEoForT8tRFR4ERq1D2uEfGnjw7hwGkj7rh+hLRtxoRMZnERdQeLRBARUZhjRkQ7DqcAlTI0KzPVqtZfR6w+AmqVEpePScN1EzOl7Q4nz06IKLAykvRobLbhdFl9t1972FVkt8zVgQgAphdkyLZvRAMGi0QQEVEYYyCiHbvDCZUydNOSlawHABhiWpdpeBamvJYn9EQUYFfkp0EbocJL/9wPQeg8+Gm1OfD1wXIcOmuUgqVb9l2ENkKFpxdMQnZqTKB3mYiIiIj6Eeb4t+NwClCpQncb4on5E3DorBE5Wd4rzP941iiv24mI5BKlVcNqE5dmfLm/DNcWZPp9/o5DFXh74/EO24semIbYEBX/JSIiIqK+i4GIduwOJ9QhDETE6jW4Ij+9w/YfXjcCma5sCSKiYPnsm/OYPj4DCoXv78X2ORPpiTrcNHUwgxBEPcRFmEREFO4YiPDgFAQIAkK6NMOXGy4bFOpdIKIBqKLGjLXbSzD3yqE+n+PusPGnx6ZDyzadRLJgiQgiIgpnslxx19bWYtGiRZg5cybmzJmDBx98EDU1YsGy4uJizJ07FzNnzsTChQthNBql1/kbCwWHQ7wHEapilUREfcWTP5yAmVMGYfzwRHy++zzsDqfP5566UI/oqIiQdRwiIiIiov5FlrNGhUKBe+65Bxs3bsTatWsxaNAgvPDCCxAEAU8++SSWLFmCjRs3YvLkyXjhhRcAwO9YqLjXRGvUPJkmooEtb3ACbi8cgavHZ6DJYsfpi2IHjSaLDfVNLW2eW3yqGuOHJ/pdvkFERERE5CbLFXd8fDymTp0q/VxQUICysjIcPHgQWq0WkydPBgDMnz8fGzZsAAC/Y6Gyee8FAAA7ZBIRidIMOgBAXaMYfPjFG7vx6MvbsG3/RQBAdX0zAMDRhe4aRNQ1XelWQ0RE1J/JXiPC6XTi3XffRWFhIcrLy5GR0dpu0mAwwOl0oq6uzu9YfHx8lz8vMTFalv1OTo5BbGwUAGBaQSaSk9lurqc4d/LifMqL89k9So3434RKo8ZH20thNFkAAEVv78Fri69DdaMNADBtXAbntpc4f9QWM4yIiCh8yR6IeO6556DT6XDnnXfi888/l/vtOzAaG+HsZQpDcnIMqqoa4LSLSzNgs6OqqkGGvRt43HNJ8uB8yovz2X1SG88953C4pBYAkJmkR0WNGfc9/x/peVEqJee2F+Q8NpVKhWxBeiIiIqJAkDUQUVRUhNLSUqxcuRJKpRLp6ekoKyuTxmtqaqBQKBAfH+93LFTcAQ0Fi1USEQEAtBEqJMRopSAEAOQPM0CjUeFsmUnaFqlltwwiIiIi6hrZqjK+9NJLOHToEFasWAGNRuwdn5+fD4vFgj179gAAVq9ejZtuuqnTsVBxByKULLhGRCTx/EpMTYjCbTNypO9LjVqJB27JR2aSPkR7R0RERET9jSwZESdPnsTKlSsxZMgQzJ8/HwCQlZWFFStWYNmyZVi6dCmsVisyMzOxfPlyAIBSqfQ5FipOge07iYh8yR0Uj0VzRkOhUOBSrRkAMGpwAi4blRLiPSMKP7wnQkRE4UyWQMSIESNw/Phxr2MTJ07E2rVruz0WCsyIICLqyGZ3AgCuGZ8BQ2wkAGDZQ9fg/MU65GaHbjkdEREREfVPsi3NCAfujAglMyKIiCQ/uSUfUVo1Rg1OkLYNSY/FqMEJUDBwS0RERETdJHvXjP7M4c6IYHiGiEiSm52AFY9eE+rdICIiIqIwwUtuD1yaQURERKEm9K4rORERUZ/HQIQHpyAWh2KqMREREYUSz0SIiCicMRDhwekUmA1BREREREREFEAMRHhYv7NUqhNBREREFGxOp4DDJTXg2QgREYUzBiLaUauYEUFEREShYbbaYbM7kRQXGepdISIiChh2zfDwxuJCqWAlERERUbBFR0Vg5ePToVbxXhEREYUvBiLaUSqZEUFERESho4lQhXoXiIiIAorhdiIiIiIiIiIKGgYiiIiIiIiIiChoGIggIiIiIiIioqBhIIKIiIiIiIiIgoaBCCIiIiIiIiIKmn7fNUOuLhfsliEfzqW8OJ/y4nzKh3MpL/5/1r/JMe/83cmL8ykvzqd8OJfy4nzKK1jnIwpBEARZPomIiIiIiIiIqBNcmkFEREREREREQcNABBEREREREREFDQMRRERERERERBQ0DEQQERERERERUdAwEEFEREREREREQcNABBEREREREREFDQMRRERERERERBQ0DEQQERERERERUdAwEEFEREREREREQcNABBEREREREREFzYAORJw9exa33347Zs6cidtvvx0lJSWh3qU+r7CwELNmzcK8efMwb948bN26FQBQXFyMuXPnYubMmVi4cCGMRqP0Gn9jA0lRUREKCwuRm5uLEydOSNv9HYc9HRsIfM2nr2MU4HHqS21tLRYtWoSZM2dizpw5ePDBB1FTUwOg53PG+fQ+n7m5uZgzZ450fB4/flx63aZNmzBr1izccMMNeOSRR9Dc3NylMer/Bvr3eXfxXKR3eD4iL56PyIfnI/Lq8+cjwgC2YMECYc2aNYIgCMKaNWuEBQsWhHiP+r4ZM2YIx48fb7PN6XQK119/vbB7925BEARhxYoVwuLFizsdG2h2794tlJWVdZhDf8dhT8cGAl/z6e0YFQQep/7U1tYKO3fulH5+/vnnhZ/97Gc9njPOp/f5FARBGDlypNDY2NjhNY2NjcIVV1whnD17VhAEQXjqqaeEl19+udMxCg8D/fu8u3gu0js8H5EXz0fkw/MRefX185EBG4iorq4WJk2aJNjtdkEQBMFutwuTJk0SjEZjiPesb/P2pbp//37hO9/5jvSz0WgUCgoKOh0bqDzn0N9x2NOxgaar//HzOO26DRs2CHfddVeP54zz2ZZ7PgXB93/869evF+69917p5wMHDgizZ8/udIz6P36fdx/PReTB8xF58XxEfjwfkVdfOx9R9zyXon8rLy9HamoqVCoVAEClUiElJQXl5eUwGAwh3ru+7YknnoAgCJg0aRIee+wxlJeXIyMjQxo3GAxwOp2oq6vzOxYfHx+K3e9T/B2HgiD0aIzHb8djNDY2lsdpFzmdTrz77rsoLCzs8ZxxPlt5zqfbggUL4HA4cM011+Chhx6CRqPpMGcZGRkoLy8HAL9j1P/xfKRneC4iL56PBAbPR3qO5yPy6ovnIwO6RgR136pVq/Dxxx/j/fffhyAIePbZZ0O9S0Rt8Bjtneeeew46nQ533nlnqHclLLSfzy1btuCDDz7AqlWrcOrUKaxYsSLEe0jU//B7nvoDHqe9w/MRefXF85EBG4hIT09HZWUlHA4HAMDhcODSpUtIT08P8Z71be750Wg0uOOOO7B3716kp6ejrKxMek5NTQ0UCgXi4+P9jpH/47CnYwOdt2PUvZ3HqX9FRUUoLS3F73//eyiVyh7PGedT1H4+gdbjMzo6GrfeeqvP47OsrEx6rr8x6v/4fd59PBeRH89H5MfzkZ7j+Yi8+ur5yIANRCQmJiIvLw/r1q0DAKxbtw55eXlMI/PDbDajoaEBACAIAtavX4+8vDzk5+fDYrFgz549AIDVq1fjpptuAgC/Y+T/OOzp2EDm6xgF/B+LPE6Bl156CYcOHcKKFSug0WgA9HzOOJ/e57O+vh4WiwUAYLfbsXHjRun4vPrqq3Hw4EGp2rznnPkbo/6P3+fdw3ORwOD5iLx4PtJzPB+RV18+H1EIgiD0+NX93OnTp7F48WKYTCbExsaiqKgIw4YNC/Vu9Vnnz5/HQw89BIfDAafTieHDh+OZZ55BSkoK9u7di6VLl8JqtSIzMxPLly9HUlISAPgdG0h+9atf4bPPPkN1dTUSEhIQHx+PTz75xO9x2NOxgcDbfK5cudLnMQr4PxYH8nF68uRJ3HzzzRgyZAgiIyMBAFlZWVixYkWP54zz2XE+77nnHixZsgQKhQJ2ux0TJkzAU089Bb1eDwD44osvsHz5cjidTuTl5eH555+HTqfrdIz6v4H+fd4dPBfpPZ6PyIvnI/Lh+Yi8+vr5yIAORBARERERERFRcA3YpRlEREREREREFHwMRBARERERERFR0DAQQURERERERERBw0AEEREREREREQUNAxFEREREREREFDQMRBARERERERFR0DAQQURERERERERB8//Tvv42xRvvXwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1296x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rewards = pd.Series(agent.eval_episode_rewards)\n",
    "steps = pd.Series(agent.eval_episode_steps)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 8))\n",
    "\n",
    "axes[0][0].plot(rewards.rolling(100, min_periods=20).mean())\n",
    "axes[0][0].set_title('mean reward')\n",
    "axes[0][1].plot(rewards.rolling(100, min_periods=20).max())\n",
    "axes[0][1].set_title('max reward')\n",
    "axes[1][0].plot(steps.rolling(100, min_periods=20).mean())\n",
    "axes[1][0].set_title('mean step')\n",
    "axes[1][1].plot(steps.rolling(100, min_periods=20).max())\n",
    "axes[1][1].set_title('max step')\n",
    "\n",
    "plt.savefig('offline/figs/qr_dqn_offline.png', dpi=200, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
